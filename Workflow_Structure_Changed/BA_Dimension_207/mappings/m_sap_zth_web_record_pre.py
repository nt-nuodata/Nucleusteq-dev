# Databricks notebook source
# MAGIC %run "./udf_informatica"

# COMMAND ----------


from pyspark.sql.types import *

spark.sql("use DELTA_TRAINING")
spark.sql("set spark.sql.legacy.timeParserPolicy = LEGACY")

# COMMAND ----------
%run ./MappingUtility

# COMMAND ----------
mainWorkflowId = dbutils.widgets.get("mainWorkflowId")
mainWorkflowRunId = dbutils.widgets.get("mainWorkflowRunId")
parentName = dbutils.widgets.get("parentName")
preVariableAssignment = dbutils.widgets.get("preVariableAssignment")
postVariableAssignment = dbutils.widgets.get("postVariableAssignment")
truncTargetTableOptions = dbutils.widgets.get("truncTargetTableOptions")
variablesTableName = dbutils.widgets.get("variablesTableName")

# COMMAND ----------
#Truncate Target Tables
truncateTargetTables(truncTargetTableOptions)

# COMMAND ----------
#Pre presession variable updation
updateVariable(preVariableAssignment, variablesTableName, mainWorkflowId, parentName, "m_sap_zth_web_record_pre")

# COMMAND ----------
fetchAndCreateVariables(parentName,"m_sap_zth_web_record_pre", variablesTableName, mainWorkflowId)

# COMMAND ----------
# DBTITLE 1, Shortcut_to_ZTH_WEB_RECORD1_0


query_0 = f"""SELECT
  MANDT AS MANDT,
  RECORD_ID AS RECORD_ID,
  AVAIL_ON_WEB AS AVAIL_ON_WEB,
  LIFNR AS LIFNR,
  IDNLF AS IDNLF,
  BRAND AS BRAND,
  BUYER AS BUYER,
  PUR_GRP AS PUR_GRP,
  ART_TYP AS ART_TYP,
  ART_CAT AS ART_CAT,
  SHIPPER AS SHIPPER,
  CORP_BRAND AS CORP_BRAND,
  PACK_TYPE AS PACK_TYPE,
  COUNTRY_OF_ORIGI AS COUNTRY_OF_ORIGI,
  CODE_DATE_IND AS CODE_DATE_IND,
  EXP_MONTH AS EXP_MONTH,
  US_LOC AS US_LOC,
  SITE_SPECIFIC_C AS SITE_SPECIFIC_C,
  COST AS COST,
  CURR_UNIT AS CURR_UNIT,
  COST_PER AS COST_PER,
  ORDER_UNIT AS ORDER_UNIT,
  LEAD_TIME AS LEAD_TIME,
  DIRECT_STORE AS DIRECT_STORE,
  TAX_CLASS AS TAX_CLASS,
  SADDLE AS SADDLE,
  HAZARDOUS AS HAZARDOUS,
  AEROSOL AS AEROSOL,
  DATE_AVAILABLE AS DATE_AVAILABLE,
  IMPORT AS IMPORT,
  NET_CONTENTS AS NET_CONTENTS,
  CONTENT_UNIT AS CONTENT_UNIT,
  SP_HANDLE AS SP_HANDLE,
  LEGAL_IN_CA AS LEGAL_IN_CA,
  CA_STUFFED AS CA_STUFFED,
  INGREDIENTS AS INGREDIENTS,
  EPA AS EPA,
  ALL_STATES AS ALL_STATES,
  MATNR AS MATNR,
  EMAIL AS EMAIL,
  CHANGE_REC AS CHANGE_REC,
  CHANGE_FLAGS AS CHANGE_FLAGS,
  INNER_PACK_TYPE AS INNER_PACK_TYPE,
  ARTILCE_SUB_CAT AS ARTILCE_SUB_CAT,
  DATE_AVAIL AS DATE_AVAIL,
  CREATED_BY AS CREATED_BY,
  CREATED_ON AS CREATED_ON,
  CREATE_TIME AS CREATE_TIME,
  LAST_CHANGED_BY AS LAST_CHANGED_BY,
  LAST_CHANGED_ON AS LAST_CHANGED_ON,
  LAST_CHANGE_TIME AS LAST_CHANGE_TIME,
  DATBI AS DATBI,
  SUB_DATE AS SUB_DATE,
  RTV AS RTV,
  NESTLE_EDI AS NESTLE_EDI
FROM
  ZTH_WEB_RECORD"""

df_0 = spark.sql(query_0)

df_0.createOrReplaceTempView("Shortcut_to_ZTH_WEB_RECORD1_0")

# COMMAND ----------
# DBTITLE 1, SQ_Shortcut_to_ZTH_WEB_RECORD1_1


query_1 = f"""SELECT
  MANDT AS MANDT,
  RECORD_ID AS RECORD_ID,
  AVAIL_ON_WEB AS AVAIL_ON_WEB,
  LIFNR AS LIFNR,
  IDNLF AS IDNLF,
  BRAND AS BRAND,
  BUYER AS BUYER,
  PUR_GRP AS PUR_GRP,
  ART_TYP AS ART_TYP,
  ART_CAT AS ART_CAT,
  SHIPPER AS SHIPPER,
  CORP_BRAND AS CORP_BRAND,
  PACK_TYPE AS PACK_TYPE,
  COUNTRY_OF_ORIGI AS COUNTRY_OF_ORIGI,
  CODE_DATE_IND AS CODE_DATE_IND,
  EXP_MONTH AS EXP_MONTH,
  US_LOC AS US_LOC,
  SITE_SPECIFIC_C AS SITE_SPECIFIC_C,
  COST AS COST,
  CURR_UNIT AS CURR_UNIT,
  COST_PER AS COST_PER,
  ORDER_UNIT AS ORDER_UNIT,
  LEAD_TIME AS LEAD_TIME,
  DIRECT_STORE AS DIRECT_STORE,
  TAX_CLASS AS TAX_CLASS,
  SADDLE AS SADDLE,
  HAZARDOUS AS HAZARDOUS,
  AEROSOL AS AEROSOL,
  DATE_AVAILABLE AS DATE_AVAILABLE,
  IMPORT AS IMPORT,
  NET_CONTENTS AS NET_CONTENTS,
  CONTENT_UNIT AS CONTENT_UNIT,
  SP_HANDLE AS SP_HANDLE,
  LEGAL_IN_CA AS LEGAL_IN_CA,
  CA_STUFFED AS CA_STUFFED,
  INGREDIENTS AS INGREDIENTS,
  EPA AS EPA,
  ALL_STATES AS ALL_STATES,
  MATNR AS MATNR,
  EMAIL AS EMAIL,
  CHANGE_REC AS CHANGE_REC,
  CHANGE_FLAGS AS CHANGE_FLAGS,
  INNER_PACK_TYPE AS INNER_PACK_TYPE,
  ARTILCE_SUB_CAT AS ARTILCE_SUB_CAT,
  DATE_AVAIL AS DATE_AVAIL,
  CREATED_BY AS CREATED_BY,
  CREATED_ON AS CREATED_ON,
  CREATE_TIME AS CREATE_TIME,
  LAST_CHANGED_BY AS LAST_CHANGED_BY,
  LAST_CHANGED_ON AS LAST_CHANGED_ON,
  LAST_CHANGE_TIME AS LAST_CHANGE_TIME,
  DATBI AS DATBI,
  SUB_DATE AS SUB_DATE,
  RTV AS RTV,
  NESTLE_EDI AS NESTLE_EDI,
  monotonically_increasing_id() AS Monotonically_Increasing_Id
FROM
  Shortcut_to_ZTH_WEB_RECORD1_0"""

df_1 = spark.sql(query_1)

df_1.createOrReplaceTempView("SQ_Shortcut_to_ZTH_WEB_RECORD1_1")

# COMMAND ----------
# DBTITLE 1, FILTRANS_2


query_2 = f"""SELECT
  MANDT AS MANDT,
  RECORD_ID AS RECORD_ID,
  AVAIL_ON_WEB AS AVAIL_ON_WEB,
  LIFNR AS LIFNR,
  IDNLF AS IDNLF,
  BRAND AS BRAND,
  BUYER AS BUYER,
  PUR_GRP AS PUR_GRP,
  ART_TYP AS ART_TYP,
  ART_CAT AS ART_CAT,
  SHIPPER AS SHIPPER,
  CORP_BRAND AS CORP_BRAND,
  PACK_TYPE AS PACK_TYPE,
  COUNTRY_OF_ORIGI AS COUNTRY_OF_ORIGI,
  CODE_DATE_IND AS CODE_DATE_IND,
  EXP_MONTH AS EXP_MONTH,
  US_LOC AS US_LOC,
  SITE_SPECIFIC_C AS SITE_SPECIFIC_C,
  COST AS COST,
  CURR_UNIT AS CURR_UNIT,
  COST_PER AS COST_PER,
  ORDER_UNIT AS ORDER_UNIT,
  LEAD_TIME AS LEAD_TIME,
  DIRECT_STORE AS DIRECT_STORE,
  TAX_CLASS AS TAX_CLASS,
  SADDLE AS SADDLE,
  HAZARDOUS AS HAZARDOUS,
  AEROSOL AS AEROSOL,
  DATE_AVAILABLE AS DATE_AVAILABLE,
  IMPORT AS IMPORT,
  NET_CONTENTS AS NET_CONTENTS,
  CONTENT_UNIT AS CONTENT_UNIT,
  SP_HANDLE AS SP_HANDLE,
  LEGAL_IN_CA AS LEGAL_IN_CA,
  CA_STUFFED AS CA_STUFFED,
  INGREDIENTS AS INGREDIENTS,
  EPA AS EPA,
  ALL_STATES AS ALL_STATES,
  MATNR AS MATNR,
  EMAIL AS EMAIL,
  CHANGE_REC AS CHANGE_REC,
  CHANGE_FLAGS AS CHANGE_FLAGS,
  INNER_PACK_TYPE AS INNER_PACK_TYPE,
  ARTILCE_SUB_CAT AS ARTILCE_SUB_CAT,
  DATE_AVAIL AS DATE_AVAIL,
  CREATED_BY AS CREATED_BY,
  CREATED_ON AS CREATED_ON,
  CREATE_TIME AS CREATE_TIME,
  LAST_CHANGED_BY AS LAST_CHANGED_BY,
  LAST_CHANGED_ON AS LAST_CHANGED_ON,
  LAST_CHANGE_TIME AS LAST_CHANGE_TIME,
  DATBI AS DATBI,
  SUB_DATE AS SUB_DATE,
  RTV AS RTV,
  NESTLE_EDI AS NESTLE_EDI,
  Monotonically_Increasing_Id AS Monotonically_Increasing_Id
FROM
  SQ_Shortcut_to_ZTH_WEB_RECORD1_1
WHERE
  MANDT = '100'"""

df_2 = spark.sql(query_2)

df_2.createOrReplaceTempView("FILTRANS_2")

# COMMAND ----------
# DBTITLE 1, EXPTRANS_3


query_3 = f"""SELECT
  IFF(Is_Number(MATNR), TO_INTEGER(MATNR), NULL) AS o_SKU_NBR,
  IFF(
    ISNULL(DATE_AVAIL)
    OR LENGTH(DATE_AVAIL) < 8
    OR DATE_AVAIL = '00000000',
    NULL,
    TO_DATE(DATE_AVAIL, 'YYYYMMDD')
  ) AS o_DATE_AVAIL,
  IFF(
    ISNULL(CREATED_ON)
    OR ISNULL(CREATE_TIME)
    OR LENGTH(CREATED_ON) < 8
    OR LENGTH(CREATE_TIME) < 6
    OR CREATED_ON = '00000000'
    OR CREATE_TIME = '000000',
    NULL,
    CONCAT(CREATED_ON, CREATE_TIME)
  ) AS conct_CREATED,
  IFF(
    ISNULL(
      IFF(
        ISNULL(CREATED_ON)
        OR ISNULL(CREATE_TIME)
        OR LENGTH(CREATED_ON) < 8
        OR LENGTH(CREATE_TIME) < 6
        OR CREATED_ON = '00000000'
        OR CREATE_TIME = '000000',
        NULL,
        CONCAT(CREATED_ON, CREATE_TIME)
      )
    ),
    NULL,
    TO_DATE(
      IFF(
        ISNULL(CREATED_ON)
        OR ISNULL(CREATE_TIME)
        OR LENGTH(CREATED_ON) < 8
        OR LENGTH(CREATE_TIME) < 6
        OR CREATED_ON = '00000000'
        OR CREATE_TIME = '000000',
        NULL,
        CONCAT(CREATED_ON, CREATE_TIME)
      ),
      'YYYYMMDDHH24MISS'
    )
  ) AS dt_CREATED,
  IFF(
    ISNULL(DATBI)
    OR LENGTH(DATBI) < 8
    OR DATBI = '00000000',
    NULL,
    TO_DATE(DATBI, 'YYYYMMDD')
  ) AS o_DATBI,
  IFF(
    SUB_DATE = '00000000',
    NULL,
    TO_DATE(SUB_DATE, 'YYYYMMDD')
  ) AS o_SUB_DATE,
  IFF(
    ISNULL(LAST_CHANGED_ON)
    OR ISNULL(LAST_CHANGE_TIME)
    OR LENGTH(LAST_CHANGED_ON) < 8
    OR LENGTH(LAST_CHANGE_TIME) < 6
    OR LAST_CHANGED_ON = '00000000'
    OR LAST_CHANGE_TIME = '000000',
    NULL,
    CONCAT(LAST_CHANGED_ON, LAST_CHANGE_TIME)
  ) AS conct_LAST,
  IFF(
    ISNULL(
      IFF(
        ISNULL(LAST_CHANGED_ON)
        OR ISNULL(LAST_CHANGE_TIME)
        OR LENGTH(LAST_CHANGED_ON) < 8
        OR LENGTH(LAST_CHANGE_TIME) < 6
        OR LAST_CHANGED_ON = '00000000'
        OR LAST_CHANGE_TIME = '000000',
        NULL,
        CONCAT(LAST_CHANGED_ON, LAST_CHANGE_TIME)
      )
    ),
    NULL,
    TO_DATE(
      IFF(
        ISNULL(LAST_CHANGED_ON)
        OR ISNULL(LAST_CHANGE_TIME)
        OR LENGTH(LAST_CHANGED_ON) < 8
        OR LENGTH(LAST_CHANGE_TIME) < 6
        OR LAST_CHANGED_ON = '00000000'
        OR LAST_CHANGE_TIME = '000000',
        NULL,
        CONCAT(LAST_CHANGED_ON, LAST_CHANGE_TIME)
      ),
      'YYYYMMDDHH24MISS'
    )
  ) AS dt_LAST,
  Monotonically_Increasing_Id AS Monotonically_Increasing_Id
FROM
  FILTRANS_2"""

df_3 = spark.sql(query_3)

df_3.createOrReplaceTempView("EXPTRANS_3")

# COMMAND ----------
# DBTITLE 1, SAP_ZTH_WEB_RECORD_PRE


spark.sql("""INSERT INTO
  SAP_ZTH_WEB_RECORD_PRE
SELECT
  F2.RECORD_ID AS RECORD_ID,
  F2.AVAIL_ON_WEB AS AVAIL_ON_WEB,
  F2.LIFNR AS LIFNR,
  F2.IDNLF AS IDNLF,
  F2.BRAND AS BRAND,
  F2.BUYER AS BUYER,
  F2.PUR_GRP AS PUR_GRP,
  F2.ART_TYP AS ART_TYP,
  F2.ART_CAT AS ART_CAT,
  F2.SHIPPER AS SHIPPER,
  F2.CORP_BRAND AS CORP_BRAND,
  F2.PACK_TYPE AS PACK_TYPE,
  F2.COUNTRY_OF_ORIGI AS COUNTRY_OF_ORIGI,
  F2.CODE_DATE_IND AS CODE_DATE_IND,
  F2.EXP_MONTH AS EXP_MONTH,
  F2.US_LOC AS US_LOC,
  F2.SITE_SPECIFIC_C AS SITE_SPECIFIC_C,
  F2.COST AS COST,
  F2.CURR_UNIT AS CURR_UNIT,
  F2.COST_PER AS COST_PER,
  F2.ORDER_UNIT AS ORDER_UNIT,
  F2.LEAD_TIME AS LEAD_TIME,
  F2.DIRECT_STORE AS DIRECT_STORE,
  F2.TAX_CLASS AS TAX_CLASS,
  F2.SADDLE AS SADDLE,
  F2.HAZARDOUS AS HAZARDOUS,
  F2.AEROSOL AS AEROSOL,
  F2.DATE_AVAILABLE AS DATE_AVAILABLE,
  F2.IMPORT AS IMPORT,
  F2.NET_CONTENTS AS NET_CONTENTS,
  F2.CONTENT_UNIT AS CONTENT_UNIT,
  F2.SP_HANDLE AS SP_HANDLE,
  F2.LEGAL_IN_CA AS LEGAL_IN_CA,
  F2.CA_STUFFED AS CA_STUFFED,
  F2.INGREDIENTS AS INGREDIENTS,
  F2.EPA AS EPA,
  F2.ALL_STATES AS ALL_STATES,
  E3.o_SKU_NBR AS SKU_NBR,
  F2.EMAIL AS EMAIL,
  F2.CHANGE_REC AS CHANGE_REC,
  F2.CHANGE_FLAGS AS CHANGE_FLAGS,
  F2.INNER_PACK_TYPE AS INNER_PACK_TYPE,
  F2.ARTILCE_SUB_CAT AS ARTILCE_SUB_CAT,
  E3.o_DATE_AVAIL AS DATE_AVAIL,
  F2.CREATED_BY AS CREATED_BY,
  E3.dt_CREATED AS CREATED_TSTMP,
  F2.LAST_CHANGED_BY AS LAST_CHANGED_BY,
  E3.dt_LAST AS LAST_CHANGED_TSTMP,
  E3.o_DATBI AS DATBI,
  E3.o_SUB_DATE AS SUB_DATE,
  F2.RTV AS RTV,
  F2.NESTLE_EDI AS NESTLE_EDI
FROM
  EXPTRANS_3 E3
  INNER JOIN FILTRANS_2 F2 ON E3.Monotonically_Increasing_Id = F2.Monotonically_Increasing_Id""")

# COMMAND ----------
#Post session variable updation
updateVariable(postVariableAssignment, variablesTableName, mainWorkflowId, parentName, "m_sap_zth_web_record_pre")

# COMMAND ----------
#Update Mapping Variables in database.
persistVariables(variablesTableName, "m_sap_zth_web_record_pre", mainWorkflowId, parentName)
