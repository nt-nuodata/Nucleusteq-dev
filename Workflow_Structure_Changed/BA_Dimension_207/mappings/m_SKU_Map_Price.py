# Databricks notebook source
# MAGIC %run "./udf_informatica"

# COMMAND ----------


from pyspark.sql.types import *

spark.sql("use DELTA_TRAINING")
spark.sql("set spark.sql.legacy.timeParserPolicy = LEGACY")

# COMMAND ----------
%run ./MappingUtility

# COMMAND ----------
mainWorkflowId = dbutils.widgets.get("mainWorkflowId")
mainWorkflowRunId = dbutils.widgets.get("mainWorkflowRunId")
parentName = dbutils.widgets.get("parentName")
preVariableAssignment = dbutils.widgets.get("preVariableAssignment")
postVariableAssignment = dbutils.widgets.get("postVariableAssignment")
truncTargetTableOptions = dbutils.widgets.get("truncTargetTableOptions")
variablesTableName = dbutils.widgets.get("variablesTableName")

# COMMAND ----------
#Truncate Target Tables
truncateTargetTables(truncTargetTableOptions)

# COMMAND ----------
#Pre presession variable updation
updateVariable(preVariableAssignment, variablesTableName, mainWorkflowId, parentName, "m_SKU_Map_Price")

# COMMAND ----------
fetchAndCreateVariables(parentName,"m_SKU_Map_Price", variablesTableName, mainWorkflowId)

# COMMAND ----------
# DBTITLE 1, Shortcut_to_SKU_MAP_PRICE1_0


query_0 = f"""SELECT
  PRODUCT_ID AS PRODUCT_ID,
  VALID_FROM_DT AS VALID_FROM_DT,
  VALID_TO_DT AS VALID_TO_DT,
  MAP_PRICE_AMT AS MAP_PRICE_AMT,
  DELETE_FLAG AS DELETE_FLAG,
  CREATED_BY AS CREATED_BY,
  LAST_CHANGED_BY AS LAST_CHANGED_BY,
  LAST_CHANGED_DT AS LAST_CHANGED_DT,
  UPDATE_TSTMP AS UPDATE_TSTMP,
  LOAD_TSTMP AS LOAD_TSTMP
FROM
  SKU_MAP_PRICE"""

df_0 = spark.sql(query_0)

df_0.createOrReplaceTempView("Shortcut_to_SKU_MAP_PRICE1_0")

# COMMAND ----------
# DBTITLE 1, SQ_Shortcut_to_SKU_MAP_PRICE_1


query_1 = f"""SELECT
  PRODUCT_ID AS PRODUCT_ID,
  VALID_FROM_DT AS VALID_FROM_DT,
  VALID_TO_DT AS VALID_TO_DT,
  MAP_PRICE_AMT AS MAP_PRICE_AMT,
  DELETE_FLAG AS DELETE_FLAG,
  CREATED_BY AS CREATED_BY,
  LAST_CHANGED_BY AS LAST_CHANGED_BY,
  LAST_CHANGED_DT AS LAST_CHANGED_DT,
  UPDATE_TSTMP AS UPDATE_TSTMP,
  LOAD_TSTMP AS LOAD_TSTMP,
  monotonically_increasing_id() AS Monotonically_Increasing_Id
FROM
  Shortcut_to_SKU_MAP_PRICE1_0"""

df_1 = spark.sql(query_1)

df_1.createOrReplaceTempView("SQ_Shortcut_to_SKU_MAP_PRICE_1")

# COMMAND ----------
# DBTITLE 1, Shortcut_to_SAP_ZTPIM_MAP_PRE_2


query_2 = f"""SELECT
  MANDT AS MANDT,
  ARTICLE AS ARTICLE,
  MAP_PRICE AS MAP_PRICE,
  CREATED_BY AS CREATED_BY,
  LAST_CHANGED_BY AS LAST_CHANGED_BY,
  LAST_CHANGED_DATE AS LAST_CHANGED_DATE,
  DATAB AS DATAB,
  DATBI AS DATBI,
  LOAD_TSTMP AS LOAD_TSTMP
FROM
  SAP_ZTPIM_MAP_PRE"""

df_2 = spark.sql(query_2)

df_2.createOrReplaceTempView("Shortcut_to_SAP_ZTPIM_MAP_PRE_2")

# COMMAND ----------
# DBTITLE 1, SQ_Shortcut_to_SAP_ZTPIM_MAP_PRE_3


query_3 = f"""SELECT
  MANDT AS MANDT,
  ARTICLE AS ARTICLE,
  MAP_PRICE AS MAP_PRICE,
  CREATED_BY AS CREATED_BY,
  LAST_CHANGED_BY AS LAST_CHANGED_BY,
  LAST_CHANGED_DATE AS LAST_CHANGED_DATE,
  DATAB AS DATAB,
  DATBI AS DATBI,
  LOAD_TSTMP AS LOAD_TSTMP,
  monotonically_increasing_id() AS Monotonically_Increasing_Id
FROM
  Shortcut_to_SAP_ZTPIM_MAP_PRE_2"""

df_3 = spark.sql(query_3)

df_3.createOrReplaceTempView("SQ_Shortcut_to_SAP_ZTPIM_MAP_PRE_3")

# COMMAND ----------
# DBTITLE 1, EXP_INT_Conversion_4


query_4 = f"""SELECT
  MANDT AS MANDT,
  TO_INTEGER(ARTICLE) AS o_ARTICLE,
  MAP_PRICE AS MAP_PRICE,
  CREATED_BY AS CREATED_BY,
  LAST_CHANGED_BY AS LAST_CHANGED_BY,
  TRUNC(TO_DATE(LAST_CHANGED_DATE, 'MM/DD/YYYY')) AS o_LAST_CHANGED_DATE,
  TRUNC(to_date(DATAB, 'MM/DD/YYYY')) AS o_DATAB,
  TRUNC(to_date(DATBI, 'MM/DD/YYYY')) AS o_DATBI,
  LOAD_TSTMP AS LOAD_TSTMP,
  Monotonically_Increasing_Id AS Monotonically_Increasing_Id
FROM
  SQ_Shortcut_to_SAP_ZTPIM_MAP_PRE_3"""

df_4 = spark.sql(query_4)

df_4.createOrReplaceTempView("EXP_INT_Conversion_4")

# COMMAND ----------
# DBTITLE 1, Shortcut_To_SKU_PROFILE_5


query_5 = f"""SELECT
  PRODUCT_ID AS PRODUCT_ID,
  SKU_NBR AS SKU_NBR,
  SKU_TYPE AS SKU_TYPE,
  PRIMARY_UPC_ID AS PRIMARY_UPC_ID,
  STATUS_ID AS STATUS_ID,
  SUBS_HIST_FLAG AS SUBS_HIST_FLAG,
  SUBS_CURR_FLAG AS SUBS_CURR_FLAG,
  SKU_DESC AS SKU_DESC,
  ALT_DESC AS ALT_DESC,
  SAP_CATEGORY_ID AS SAP_CATEGORY_ID,
  SAP_CLASS_ID AS SAP_CLASS_ID,
  SAP_DEPT_ID AS SAP_DEPT_ID,
  SAP_DIVISION_ID AS SAP_DIVISION_ID,
  PRIMARY_VENDOR_ID AS PRIMARY_VENDOR_ID,
  PARENT_VENDOR_ID AS PARENT_VENDOR_ID,
  COUNTRY_CD AS COUNTRY_CD,
  IMPORT_FLAG AS IMPORT_FLAG,
  HTS_CODE_ID AS HTS_CODE_ID,
  CONTENTS AS CONTENTS,
  CONTENTS_UNITS AS CONTENTS_UNITS,
  WEIGHT_NET_AMT AS WEIGHT_NET_AMT,
  WEIGHT_UOM_CD AS WEIGHT_UOM_CD,
  SIZE_DESC AS SIZE_DESC,
  BUM_QTY AS BUM_QTY,
  UOM_CD AS UOM_CD,
  UNIT_NUMERATOR AS UNIT_NUMERATOR,
  UNIT_DENOMINATOR AS UNIT_DENOMINATOR,
  BUYER_ID AS BUYER_ID,
  PURCH_GROUP_ID AS PURCH_GROUP_ID,
  PURCH_COST_AMT AS PURCH_COST_AMT,
  NAT_PRICE_US_AMT AS NAT_PRICE_US_AMT,
  TAX_CLASS_ID AS TAX_CLASS_ID,
  VALUATION_CLASS_CD AS VALUATION_CLASS_CD,
  BRAND_CD AS BRAND_CD,
  BRAND_CLASSIFICATION_ID AS BRAND_CLASSIFICATION_ID,
  OWNBRAND_FLAG AS OWNBRAND_FLAG,
  STATELINE_FLAG AS STATELINE_FLAG,
  SIGN_TYPE_CD AS SIGN_TYPE_CD,
  OLD_ARTICLE_NBR AS OLD_ARTICLE_NBR,
  VENDOR_ARTICLE_NBR AS VENDOR_ARTICLE_NBR,
  INIT_MKDN_DT AS INIT_MKDN_DT,
  DISC_START_DT AS DISC_START_DT,
  ADD_DT AS ADD_DT,
  DELETE_DT AS DELETE_DT,
  UPDATE_DT AS UPDATE_DT,
  FIRST_SALE_DT AS FIRST_SALE_DT,
  LAST_SALE_DT AS LAST_SALE_DT,
  FIRST_INV_DT AS FIRST_INV_DT,
  LAST_INV_DT AS LAST_INV_DT,
  LOAD_DT AS LOAD_DT,
  BASE_NBR AS BASE_NBR,
  BP_COLOR_ID AS BP_COLOR_ID,
  BP_SIZE_ID AS BP_SIZE_ID,
  BP_BREED_ID AS BP_BREED_ID,
  BP_ITEM_CONCATENATED AS BP_ITEM_CONCATENATED,
  BP_AEROSOL_FLAG AS BP_AEROSOL_FLAG,
  BP_HAZMAT_FLAG AS BP_HAZMAT_FLAG,
  CANADIAN_HTS_CD AS CANADIAN_HTS_CD,
  NAT_PRICE_CA_AMT AS NAT_PRICE_CA_AMT,
  NAT_PRICE_PR_AMT AS NAT_PRICE_PR_AMT,
  RTV_DEPT_CD AS RTV_DEPT_CD,
  GL_ACCT_NBR AS GL_ACCT_NBR,
  ARTICLE_CATEGORY_ID AS ARTICLE_CATEGORY_ID,
  COMPONENT_FLAG AS COMPONENT_FLAG,
  ZDISCO_SCHED_TYPE_ID AS ZDISCO_SCHED_TYPE_ID,
  ZDISCO_MKDN_SCHED_ID AS ZDISCO_MKDN_SCHED_ID,
  ZDISCO_PID_DT AS ZDISCO_PID_DT,
  ZDISCO_START_DT AS ZDISCO_START_DT,
  ZDISCO_INIT_MKDN_DT AS ZDISCO_INIT_MKDN_DT,
  ZDISCO_DC_DT AS ZDISCO_DC_DT,
  ZDISCO_STR_DT AS ZDISCO_STR_DT,
  ZDISCO_STR_OWNRSHP_DT AS ZDISCO_STR_OWNRSHP_DT,
  ZDISCO_STR_WRT_OFF_DT AS ZDISCO_STR_WRT_OFF_DT
FROM
  SKU_PROFILE"""

df_5 = spark.sql(query_5)

df_5.createOrReplaceTempView("Shortcut_To_SKU_PROFILE_5")

# COMMAND ----------
# DBTITLE 1, SQ_Shortcut_To_SKU_PROFILE_6


query_6 = f"""SELECT
  PRODUCT_ID AS PRODUCT_ID,
  SKU_NBR AS SKU_NBR,
  monotonically_increasing_id() AS Monotonically_Increasing_Id
FROM
  Shortcut_To_SKU_PROFILE_5"""

df_6 = spark.sql(query_6)

df_6.createOrReplaceTempView("SQ_Shortcut_To_SKU_PROFILE_6")

# COMMAND ----------
# DBTITLE 1, JNR_SKU_PROFILE_7


query_7 = f"""SELECT
  DETAIL.MANDT AS MANDT,
  DETAIL.o_ARTICLE AS o_ARTICLE,
  DETAIL.MAP_PRICE AS MAP_PRICE,
  DETAIL.CREATED_BY AS CREATED_BY,
  DETAIL.LAST_CHANGED_BY AS LAST_CHANGED_BY,
  DETAIL.o_LAST_CHANGED_DATE AS o_LAST_CHANGED_DATE,
  DETAIL.o_DATAB AS o_DATAB,
  DETAIL.o_DATBI AS o_DATBI,
  DETAIL.LOAD_TSTMP AS LOAD_TSTMP,
  MASTER.PRODUCT_ID AS PRODUCT_ID,
  MASTER.SKU_NBR AS SKU_NBR,
  MASTER.Monotonically_Increasing_Id AS Monotonically_Increasing_Id
FROM
  SQ_Shortcut_To_SKU_PROFILE_6 MASTER
  INNER JOIN EXP_INT_Conversion_4 DETAIL ON MASTER.SKU_NBR = DETAIL.o_ARTICLE"""

df_7 = spark.sql(query_7)

df_7.createOrReplaceTempView("JNR_SKU_PROFILE_7")

# COMMAND ----------
# DBTITLE 1, JNR_SKU_Map_Price_8


query_8 = f"""SELECT
  DETAIL.MANDT AS in_MANDT,
  DETAIL.MAP_PRICE AS in_MAP_PRICE,
  DETAIL.CREATED_BY AS in_CREATED_BY,
  DETAIL.LAST_CHANGED_BY AS in_LAST_CHANGED_BY,
  DETAIL.o_LAST_CHANGED_DATE AS o_LAST_CHANGED_DATE,
  DETAIL.o_DATAB AS o_DATAB,
  DETAIL.o_DATBI AS o_DATBI,
  DETAIL.LOAD_TSTMP AS in_LOAD_TSTMP,
  DETAIL.PRODUCT_ID AS in_PRODUCT_ID,
  MASTER.PRODUCT_ID AS PRODUCT_ID,
  MASTER.VALID_FROM_DT AS VALID_FROM_DT,
  MASTER.VALID_TO_DT AS VALID_TO_DT,
  MASTER.MAP_PRICE_AMT AS MAP_PRICE_AMT,
  MASTER.DELETE_FLAG AS DELETE_FLAG,
  MASTER.CREATED_BY AS CREATED_BY,
  MASTER.LAST_CHANGED_BY AS LAST_CHANGED_BY,
  MASTER.LAST_CHANGED_DT AS LAST_CHANGED_DT,
  nvl(
    MASTER.Monotonically_Increasing_Id,
    DETAIL.Monotonically_Increasing_Id
  ) AS Monotonically_Increasing_Id
FROM
  SQ_Shortcut_to_SKU_MAP_PRICE_1 MASTER
  FULL OUTER JOIN JNR_SKU_PROFILE_7 DETAIL ON MASTER.PRODUCT_ID = DETAIL.PRODUCT_ID
  AND MASTER.VALID_FROM_DT = DETAIL.o_DATAB"""

df_8 = spark.sql(query_8)

df_8.createOrReplaceTempView("JNR_SKU_Map_Price_8")

# COMMAND ----------
# DBTITLE 1, FTR_No_Changed_Rec_9


query_9 = f"""SELECT
  in_MANDT AS in_MANDT,
  in_MAP_PRICE AS in_MAP_PRICE,
  in_CREATED_BY AS in_CREATED_BY,
  in_LAST_CHANGED_BY AS in_LAST_CHANGED_BY,
  o_LAST_CHANGED_DATE AS o_LAST_CHANGED_DATE,
  o_DATAB AS o_DATAB,
  o_DATBI AS o_DATBI,
  in_LOAD_TSTMP AS in_LOAD_TSTMP,
  in_PRODUCT_ID AS in_PRODUCT_ID,
  PRODUCT_ID AS PRODUCT_ID,
  VALID_FROM_DT AS VALID_FROM_DT,
  VALID_TO_DT AS VALID_TO_DT,
  MAP_PRICE_AMT AS MAP_PRICE_AMT,
  DELETE_FLAG AS DELETE_FLAG,
  CREATED_BY AS CREATED_BY,
  LAST_CHANGED_BY AS LAST_CHANGED_BY,
  LAST_CHANGED_DT AS LAST_CHANGED_DT,
  Monotonically_Increasing_Id AS Monotonically_Increasing_Id
FROM
  JNR_SKU_Map_Price_8
WHERE
  ISNULL(in_PRODUCT_ID)
  OR ISNULL(PRODUCT_ID)
  OR (
    (NOT ISNULL(PRODUCT_ID))
    AND (
      IFF(ISNULL(in_MAP_PRICE), 9, in_MAP_PRICE) <> IFF(ISNULL(MAP_PRICE_AMT), 9, MAP_PRICE_AMT)
      OR IFF(
        ISNULL(LTRIM(RTRIM(in_CREATED_BY))),
        'S',
        LTRIM(RTRIM(in_CREATED_BY))
      ) <> IFF(
        ISNULL(LTRIM(RTRIM(CREATED_BY))),
        'S',
        LTRIM(RTRIM(CREATED_BY))
      )
      OR IFF(
        ISNULL(LTRIM(RTRIM(in_LAST_CHANGED_BY))),
        'S',
        LTRIM(RTRIM(in_LAST_CHANGED_BY))
      ) <> IFF(
        ISNULL(LTRIM(RTRIM(LAST_CHANGED_BY))),
        'S',
        LTRIM(RTRIM(LAST_CHANGED_BY))
      )
      OR IFF (
        ISNULL(o_LAST_CHANGED_DATE),
        TO_DATE('01/01/1900', 'MM/DD/YYYY'),
        o_LAST_CHANGED_DATE
      ) <> IFF (
        ISNULL(LAST_CHANGED_DT),
        TO_DATE('01/01/1900', 'MM/DD/YYYY'),
        LAST_CHANGED_DT
      )
      OR IFF (
        ISNULL(o_DATAB),
        TO_DATE('01/01/1900', 'MM/DD/YYYY'),
        o_DATAB
      ) <> IFF (
        ISNULL(VALID_FROM_DT),
        TO_DATE('01/01/1900', 'MM/DD/YYYY'),
        VALID_FROM_DT
      )
      OR IFF (
        ISNULL(o_DATBI),
        TO_DATE('01/01/1900', 'MM/DD/YYYY'),
        o_DATBI
      ) <> IFF (
        ISNULL(VALID_TO_DT),
        TO_DATE('01/01/1900', 'MM/DD/YYYY'),
        VALID_TO_DT
      )
    )
  )"""

df_9 = spark.sql(query_9)

df_9.createOrReplaceTempView("FTR_No_Changed_Rec_9")

# COMMAND ----------
# DBTITLE 1, EXP_INS_UPD_FLAG_10


query_10 = f"""SELECT
  in_MAP_PRICE AS in_MAP_PRICE,
  in_CREATED_BY AS in_CREATED_BY,
  in_LAST_CHANGED_BY AS in_LAST_CHANGED_BY,
  o_LAST_CHANGED_DATE AS o_LAST_CHANGED_DATE,
  o_DATAB AS o_DATAB,
  o_DATBI AS o_DATBI,
  in_LOAD_TSTMP AS in_LOAD_TSTMP,
  in_PRODUCT_ID AS in_PRODUCT_ID,
  PRODUCT_ID AS PRODUCT_ID,
  VALID_FROM_DT AS VALID_FROM_DT,
  VALID_TO_DT AS VALID_TO_DT,
  MAP_PRICE_AMT AS MAP_PRICE_AMT,
  DELETE_FLAG AS DELETE_FLAG,
  CREATED_BY AS CREATED_BY,
  LAST_CHANGED_BY AS LAST_CHANGED_BY,
  LAST_CHANGED_DT AS LAST_CHANGED_DT,
  IFF(
    ISNULL(in_PRODUCT_ID)
    AND NOT ISNULL(PRODUCT_ID),
    1,
    0
  ) AS exp_DELETE_FLAG,
  IFF(ISNULL(in_LOAD_TSTMP), now(), in_LOAD_TSTMP) AS LOAD_TSTMP,
  now() AS UPDATE_TSTMP,
  IFF(
    ISNULL(PRODUCT_ID)
    AND NOT ISNULL(in_PRODUCT_ID),
    'INSERT',
    IFF(
      ISNULL(in_PRODUCT_ID)
      AND NOT ISNULL(PRODUCT_ID),
      'DELETE',
      IFF(
        (
          NOT ISNULL(PRODUCT_ID)
          AND NOT ISNULL(in_PRODUCT_ID)
        )
        AND (
          IFF(ISNULL(in_MAP_PRICE), 9, in_MAP_PRICE) <> IFF(ISNULL(MAP_PRICE_AMT), 9, MAP_PRICE_AMT)
          OR IFF(
            ISNULL(LTRIM(RTRIM(in_CREATED_BY))),
            'S',
            LTRIM(RTRIM(in_CREATED_BY))
          ) <> IFF(
            ISNULL(LTRIM(RTRIM(CREATED_BY))),
            'S',
            LTRIM(RTRIM(CREATED_BY))
          )
          OR IFF(
            ISNULL(LTRIM(RTRIM(in_LAST_CHANGED_BY))),
            'S',
            LTRIM(RTRIM(in_LAST_CHANGED_BY))
          ) <> IFF(
            ISNULL(LTRIM(RTRIM(LAST_CHANGED_BY))),
            'S',
            LTRIM(RTRIM(LAST_CHANGED_BY))
          )
          OR IFF (
            ISNULL(o_LAST_CHANGED_DATE),
            TO_DATE('01/01/1900', 'MM/DD/YYYY'),
            o_LAST_CHANGED_DATE
          ) <> IFF (
            ISNULL(LAST_CHANGED_DT),
            TO_DATE('01/01/1900', 'MM/DD/YYYY'),
            LAST_CHANGED_DT
          )
          OR IFF (
            ISNULL(o_DATAB),
            TO_DATE('01/01/1900', 'MM/DD/YYYY'),
            o_DATAB
          ) <> IFF (
            ISNULL(VALID_FROM_DT),
            TO_DATE('01/01/1900', 'MM/DD/YYYY'),
            VALID_FROM_DT
          )
          OR IFF (
            ISNULL(o_DATBI),
            TO_DATE('01/01/1900', 'MM/DD/YYYY'),
            o_DATBI
          ) <> IFF (
            ISNULL(VALID_TO_DT),
            TO_DATE('01/01/1900', 'MM/DD/YYYY'),
            VALID_TO_DT
          )
        ),
        'UPDATE'
      )
    )
  ) AS UPD_FLAG,
  Monotonically_Increasing_Id AS Monotonically_Increasing_Id
FROM
  FTR_No_Changed_Rec_9"""

df_10 = spark.sql(query_10)

df_10.createOrReplaceTempView("EXP_INS_UPD_FLAG_10")

# COMMAND ----------
# DBTITLE 1, RTR_UPD_INS_DEL


query_11 = f"""SELECT
  in_CREATED_BY AS in_CREATED_BY1,
  in_LAST_CHANGED_BY AS in_LAST_CHANGED_BY1,
  o_LAST_CHANGED_DATE AS o_LAST_CHANGED_DATE1,
  o_DATAB AS o_DATAB1,
  o_DATBI AS o_DATBI1,
  in_PRODUCT_ID AS in_PRODUCT_ID1,
  LOAD_TSTMP AS LOAD_TSTMP1,
  UPDATE_TSTMP AS UPDATE_TSTMP1,
  UPD_FLAG AS UPD_FLAG1,
  exp_DELETE_FLAG AS exp_DELETE_FLAG1,
  in_MAP_PRICE AS in_MAP_PRICE1,
  PRODUCT_ID AS PRODUCT_ID1,
  VALID_FROM_DT AS VALID_FROM_DT1,
  VALID_TO_DT AS VALID_TO_DT1,
  MAP_PRICE_AMT AS MAP_PRICE_AMT1,
  DELETE_FLAG AS DELETE_FLAG1,
  CREATED_BY AS CREATED_BY1,
  LAST_CHANGED_BY AS LAST_CHANGED_BY1,
  LAST_CHANGED_DT AS LAST_CHANGED_DT1,
  Monotonically_Increasing_Id AS Monotonically_Increasing_Id
FROM
  EXP_INS_UPD_FLAG_10
WHERE
  UPD_FLAG = 'INSERT'
  OR UPD_FLAG = 'UPDATE'"""

df_11 = spark.sql(query_11)

df_11.createOrReplaceTempView("FIL_UPD_INS_DEL_INS_UPD_11")

query_12 = f"""SELECT
  in_CREATED_BY AS in_CREATED_BY3,
  in_LAST_CHANGED_BY AS in_LAST_CHANGED_BY3,
  o_LAST_CHANGED_DATE AS o_LAST_CHANGED_DATE3,
  o_DATAB AS o_DATAB3,
  o_DATBI AS o_DATBI3,
  in_PRODUCT_ID AS in_PRODUCT_ID3,
  LOAD_TSTMP AS LOAD_TSTMP3,
  UPDATE_TSTMP AS UPDATE_TSTMP3,
  UPD_FLAG AS UPD_FLAG3,
  exp_DELETE_FLAG AS exp_DELETE_FLAG3,
  in_MAP_PRICE AS in_MAP_PRICE3,
  PRODUCT_ID AS PRODUCT_ID3,
  VALID_FROM_DT AS VALID_FROM_DT3,
  VALID_TO_DT AS VALID_TO_DT3,
  MAP_PRICE_AMT AS MAP_PRICE_AMT3,
  DELETE_FLAG AS DELETE_FLAG3,
  CREATED_BY AS CREATED_BY3,
  LAST_CHANGED_BY AS LAST_CHANGED_BY3,
  LAST_CHANGED_DT AS LAST_CHANGED_DT3,
  Monotonically_Increasing_Id AS Monotonically_Increasing_Id
FROM
  EXP_INS_UPD_FLAG_10
WHERE
  UPD_FLAG = 'DELETE'"""

df_12 = spark.sql(query_12)

df_12.createOrReplaceTempView("FIL_UPD_INS_DEL_DELETE_12")

# COMMAND ----------
# DBTITLE 1, UPD_DELETE_13


query_13 = f"""SELECT
  CREATED_BY3 AS in_CREATED_BY3,
  LAST_CHANGED_BY3 AS in_LAST_CHANGED_BY3,
  LAST_CHANGED_DT3 AS o_LAST_CHANGED_DATE,
  VALID_FROM_DT3 AS o_DATAB3,
  VALID_TO_DT3 AS o_DATBI3,
  PRODUCT_ID3 AS in_PRODUCT_ID3,
  LOAD_TSTMP3 AS LOAD_TSTMP3,
  UPDATE_TSTMP3 AS UPDATE_TSTMP3,
  exp_DELETE_FLAG3 AS exp_DELETE_FLAG3,
  MAP_PRICE_AMT3 AS in_MAP_PRICE3,
  Monotonically_Increasing_Id AS Monotonically_Increasing_Id
FROM
  FIL_UPD_INS_DEL_DELETE_12"""

df_13 = spark.sql(query_13)

df_13.createOrReplaceTempView("UPD_DELETE_13")

# COMMAND ----------
# DBTITLE 1, UPD_INS_UPD_14


query_14 = f"""SELECT
  in_PRODUCT_ID1 AS in_PRODUCT_ID1,
  o_DATAB1 AS o_DATAB1,
  o_DATBI1 AS o_DATBI1,
  in_CREATED_BY1 AS in_CREATED_BY1,
  in_LAST_CHANGED_BY1 AS in_LAST_CHANGED_BY1,
  o_LAST_CHANGED_DATE1 AS o_LAST_CHANGED_DATE,
  LOAD_TSTMP1 AS LOAD_TSTMP1,
  UPDATE_TSTMP1 AS UPDATE_TSTMP1,
  UPD_FLAG1 AS UPD_FLAG1,
  exp_DELETE_FLAG1 AS exp_DELETE_FLAG1,
  in_MAP_PRICE1 AS in_MAP_PRICE1,
  Monotonically_Increasing_Id AS Monotonically_Increasing_Id,
  IFF(UPD_FLAG1 = 'INSERT', 'DD_INSERT', 'DD_UPDATE') AS UPDATE_STRATEGY_FLAG
FROM
  FIL_UPD_INS_DEL_INS_UPD_11"""

df_14 = spark.sql(query_14)

df_14.createOrReplaceTempView("UPD_INS_UPD_14")

# COMMAND ----------
# DBTITLE 1, SKU_MAP_PRICE


spark.sql("""MERGE INTO SKU_MAP_PRICE AS TARGET
USING
  UPD_DELETE_13 AS SOURCE ON TARGET.PRODUCT_ID = SOURCE.in_PRODUCT_ID3
  AND TARGET.VALID_FROM_DT = SOURCE.o_DATAB3
  WHEN MATCHED THEN
UPDATE
SET
  TARGET.PRODUCT_ID = SOURCE.in_PRODUCT_ID3,
  TARGET.VALID_FROM_DT = SOURCE.o_DATAB3,
  TARGET.VALID_TO_DT = SOURCE.o_DATBI3,
  TARGET.MAP_PRICE_AMT = SOURCE.in_MAP_PRICE3,
  TARGET.DELETE_FLAG = SOURCE.exp_DELETE_FLAG3,
  TARGET.CREATED_BY = SOURCE.in_CREATED_BY3,
  TARGET.LAST_CHANGED_BY = SOURCE.in_LAST_CHANGED_BY3,
  TARGET.LAST_CHANGED_DT = SOURCE.o_LAST_CHANGED_DATE,
  TARGET.UPDATE_TSTMP = SOURCE.UPDATE_TSTMP3,
  TARGET.LOAD_TSTMP = SOURCE.LOAD_TSTMP3""")

# COMMAND ----------
# DBTITLE 1, SKU_MAP_PRICE


spark.sql("""MERGE INTO SKU_MAP_PRICE AS TARGET
USING
  UPD_INS_UPD_14 AS SOURCE ON TARGET.PRODUCT_ID = SOURCE.in_PRODUCT_ID1
  AND TARGET.VALID_FROM_DT = SOURCE.o_DATAB1
  WHEN MATCHED
  AND SOURCE.UPDATE_STRATEGY_FLAG = "DD_UPDATE" THEN
UPDATE
SET
  TARGET.PRODUCT_ID = SOURCE.in_PRODUCT_ID1,
  TARGET.VALID_FROM_DT = SOURCE.o_DATAB1,
  TARGET.VALID_TO_DT = SOURCE.o_DATBI1,
  TARGET.MAP_PRICE_AMT = SOURCE.in_MAP_PRICE1,
  TARGET.DELETE_FLAG = SOURCE.exp_DELETE_FLAG1,
  TARGET.CREATED_BY = SOURCE.in_CREATED_BY1,
  TARGET.LAST_CHANGED_BY = SOURCE.in_LAST_CHANGED_BY1,
  TARGET.LAST_CHANGED_DT = SOURCE.o_LAST_CHANGED_DATE,
  TARGET.UPDATE_TSTMP = SOURCE.UPDATE_TSTMP1,
  TARGET.LOAD_TSTMP = SOURCE.LOAD_TSTMP1
  WHEN MATCHED
  AND SOURCE.UPDATE_STRATEGY_FLAG = "DD_DELETE"
  AND TARGET.VALID_TO_DT = SOURCE.o_DATBI1
  AND TARGET.MAP_PRICE_AMT = SOURCE.in_MAP_PRICE1
  AND TARGET.DELETE_FLAG = SOURCE.exp_DELETE_FLAG1
  AND TARGET.CREATED_BY = SOURCE.in_CREATED_BY1
  AND TARGET.LAST_CHANGED_BY = SOURCE.in_LAST_CHANGED_BY1
  AND TARGET.LAST_CHANGED_DT = SOURCE.o_LAST_CHANGED_DATE
  AND TARGET.UPDATE_TSTMP = SOURCE.UPDATE_TSTMP1
  AND TARGET.LOAD_TSTMP = SOURCE.LOAD_TSTMP1 THEN DELETE
  WHEN NOT MATCHED
  AND SOURCE.UPDATE_STRATEGY_FLAG = "DD_INSERT" THEN
INSERT
  (
    TARGET.PRODUCT_ID,
    TARGET.VALID_FROM_DT,
    TARGET.VALID_TO_DT,
    TARGET.MAP_PRICE_AMT,
    TARGET.DELETE_FLAG,
    TARGET.CREATED_BY,
    TARGET.LAST_CHANGED_BY,
    TARGET.LAST_CHANGED_DT,
    TARGET.UPDATE_TSTMP,
    TARGET.LOAD_TSTMP
  )
VALUES
  (
    SOURCE.in_PRODUCT_ID1,
    SOURCE.o_DATAB1,
    SOURCE.o_DATBI1,
    SOURCE.in_MAP_PRICE1,
    SOURCE.exp_DELETE_FLAG1,
    SOURCE.in_CREATED_BY1,
    SOURCE.in_LAST_CHANGED_BY1,
    SOURCE.o_LAST_CHANGED_DATE,
    SOURCE.UPDATE_TSTMP1,
    SOURCE.LOAD_TSTMP1
  )""")

# COMMAND ----------
#Post session variable updation
updateVariable(postVariableAssignment, variablesTableName, mainWorkflowId, parentName, "m_SKU_Map_Price")

# COMMAND ----------
#Update Mapping Variables in database.
persistVariables(variablesTableName, "m_SKU_Map_Price", mainWorkflowId, parentName)
