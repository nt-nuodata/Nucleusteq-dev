# Databricks notebook source
# MAGIC %run "./udf_informatica"

# COMMAND ----------


from pyspark.sql.types import *

spark.sql("use DELTA_TRAINING")
spark.sql("set spark.sql.legacy.timeParserPolicy = LEGACY")

# COMMAND ----------
%run ./MappingUtility

# COMMAND ----------
mainWorkflowId = dbutils.widgets.get("mainWorkflowId")
mainWorkflowRunId = dbutils.widgets.get("mainWorkflowRunId")
parentName = dbutils.widgets.get("parentName")
preVariableAssignment = dbutils.widgets.get("preVariableAssignment")
postVariableAssignment = dbutils.widgets.get("postVariableAssignment")
truncTargetTableOptions = dbutils.widgets.get("truncTargetTableOptions")
variablesTableName = dbutils.widgets.get("variablesTableName")

# COMMAND ----------
#Truncate Target Tables
truncateTargetTables(truncTargetTableOptions)

# COMMAND ----------
#Pre presession variable updation
updateVariable(preVariableAssignment, variablesTableName, mainWorkflowId, parentName, "m_sku_store_price_day")

# COMMAND ----------
fetchAndCreateVariables(parentName,"m_sku_store_price_day", variablesTableName, mainWorkflowId)

# COMMAND ----------
# DBTITLE 1, Shortcut_to_SKU_STORE_PRICE_PRE_0


query_0 = f"""SELECT
  SKU_NBR AS SKU_NBR,
  STORE_NBR AS STORE_NBR,
  SALES_ORG_CD AS SALES_ORG_CD,
  COND_TYPE_CD AS COND_TYPE_CD,
  COND_END_DT AS COND_END_DT,
  COND_EFF_DT AS COND_EFF_DT,
  COND_RECORD_NBR AS COND_RECORD_NBR,
  DELETE_IND AS DELETE_IND,
  PROMOTION_CD AS PROMOTION_CD,
  COND_AMT AS COND_AMT,
  COND_RT_UNIT AS COND_RT_UNIT,
  COND_PRICE_UNIT AS COND_PRICE_UNIT,
  COND_UNIT AS COND_UNIT,
  UNIT_NUMERATOR AS UNIT_NUMERATOR,
  UNIT_DENOMINATOR AS UNIT_DENOMINATOR,
  PRICING_REASON_CD AS PRICING_REASON_CD
FROM
  SKU_STORE_PRICE_PRE"""

df_0 = spark.sql(query_0)

df_0.createOrReplaceTempView("Shortcut_to_SKU_STORE_PRICE_PRE_0")

# COMMAND ----------
# DBTITLE 1, Shortcut_To_SKU_STORE_PRICE_DAY_1


query_1 = f"""SELECT
  SKU_NBR AS SKU_NBR,
  STORE_NBR AS STORE_NBR,
  SALES_ORG_CD AS SALES_ORG_CD,
  COND_TYPE_CD AS COND_TYPE_CD,
  COND_END_DT AS COND_END_DT,
  COND_EFF_DT AS COND_EFF_DT,
  COND_RECORD_NBR AS COND_RECORD_NBR,
  DELETE_IND AS DELETE_IND,
  PROMOTION_CD AS PROMOTION_CD,
  COND_AMT AS COND_AMT,
  COND_RT_UNIT AS COND_RT_UNIT,
  COND_PRICE_UNIT AS COND_PRICE_UNIT,
  COND_UNIT AS COND_UNIT,
  UNIT_NUMERATOR AS UNIT_NUMERATOR,
  UNIT_DENOMINATOR AS UNIT_DENOMINATOR,
  PRICING_REASON_CD AS PRICING_REASON_CD,
  UPDATE_DT AS UPDATE_DT,
  LOAD_DT AS LOAD_DT
FROM
  SKU_STORE_PRICE_DAY"""

df_1 = spark.sql(query_1)

df_1.createOrReplaceTempView("Shortcut_To_SKU_STORE_PRICE_DAY_1")

# COMMAND ----------
# DBTITLE 1, ASQ_SHORTCUT_TO_SKU_STORE_PRICE_PRE_2


query_2 = f"""SELECT
  SP.SKU_NBR AS SKU_NBR,
  SP.STORE_NBR AS STORE_NBR,
  SP.SALES_ORG_CD AS SALES_ORG_CD,
  SP.COND_TYPE_CD AS COND_TYPE_CD,
  SP.COND_RECORD_NBR AS COND_RECORD_NBR,
  SP.DELETE_IND AS DELETE_IND,
  SP.COND_END_DT AS COND_END_DT,
  SP.COND_EFF_DT AS COND_EFF_DT,
  SP.COND_AMT AS COND_AMT,
  SP.PROMOTION_CD AS PROMOTION_CD,
  SP.COND_RT_UNIT AS COND_RT_UNIT,
  SP.COND_PRICE_UNIT AS COND_PRICE_UNIT,
  SP.COND_UNIT AS COND_UNIT,
  SP.UNIT_NUMERATOR AS UNIT_NUMERATOR,
  SP.UNIT_DENOMINATOR AS UNIT_DENOMINATOR,
  SP.PRICING_REASON_CD AS PRICING_REASON_CD,
  CURRENT_DATE AS UPDATE_DT,
  NVL(SD.LOAD_DT, CURRENT_DATE) AS LOAD_DT,
  CASE
    WHEN SD.SKU_NBR IS NULL THEN 1
    ELSE 2
  END AS ROW_ACTION,
  monotonically_increasing_id() AS Monotonically_Increasing_Id
FROM
  Shortcut_to_SKU_STORE_PRICE_PRE_0 SP
  LEFT OUTER JOIN Shortcut_To_SKU_STORE_PRICE_DAY_1 SD ON SP.SKU_NBR = SD.SKU_NBR
  AND SP.STORE_NBR = SD.STORE_NBR
  AND SP.SALES_ORG_CD = SD.SALES_ORG_CD
  AND SP.COND_TYPE_CD = SD.COND_TYPE_CD
  AND SP.COND_END_DT = SD.COND_END_DT"""

df_2 = spark.sql(query_2)

df_2.createOrReplaceTempView("ASQ_SHORTCUT_TO_SKU_STORE_PRICE_PRE_2")

# COMMAND ----------
# DBTITLE 1, UPDTRANS_3


query_3 = f"""SELECT
  SKU_NBR AS SKU_NBR,
  STORE_NBR AS STORE_NBR,
  SALES_ORG_CD AS SALES_ORG_CD,
  COND_TYPE_CD AS COND_TYPE_CD,
  COND_RECORD_NBR AS COND_RECORD_NBR,
  COND_END_DT AS COND_END_DT,
  COND_EFF_DT AS COND_EFF_DT,
  DELETE_IND AS DELETE_IND,
  COND_AMT AS COND_AMT,
  PROMOTION_CD AS PROMOTION_CD,
  COND_RT_UNIT AS COND_RT_UNIT,
  COND_PRICE_UNIT AS COND_PRICE_UNIT,
  COND_UNIT AS COND_UNIT,
  UNIT_NUMERATOR AS UNIT_NUMERATOR,
  UNIT_DENOMINATOR AS UNIT_DENOMINATOR,
  PRICING_REASON_CD AS PRICING_REASON_CD,
  UPDATE_DT AS UPDATE_DT,
  LOAD_DT AS LOAD_DT,
  ROW_ACTION AS ROWACTION,
  Monotonically_Increasing_Id AS Monotonically_Increasing_Id,
  IFF(ROW_ACTION = 1, dd_insert, dd_update) AS UPDATE_STRATEGY_FLAG
FROM
  ASQ_SHORTCUT_TO_SKU_STORE_PRICE_PRE_2"""

df_3 = spark.sql(query_3)

df_3.createOrReplaceTempView("UPDTRANS_3")

# COMMAND ----------
# DBTITLE 1, SKU_STORE_PRICE_DAY


spark.sql("""MERGE INTO SKU_STORE_PRICE_DAY AS TARGET
USING
  UPDTRANS_3 AS SOURCE ON TARGET.SALES_ORG_CD = SOURCE.SALES_ORG_CD
  AND TARGET.SKU_NBR = SOURCE.SKU_NBR
  AND TARGET.COND_TYPE_CD = SOURCE.COND_TYPE_CD
  AND TARGET.STORE_NBR = SOURCE.STORE_NBR
  AND TARGET.COND_END_DT = SOURCE.COND_END_DT
  WHEN MATCHED
  AND SOURCE.UPDATE_STRATEGY_FLAG = "DD_UPDATE" THEN
UPDATE
SET
  TARGET.SKU_NBR = SOURCE.SKU_NBR,
  TARGET.STORE_NBR = SOURCE.STORE_NBR,
  TARGET.SALES_ORG_CD = SOURCE.SALES_ORG_CD,
  TARGET.COND_TYPE_CD = SOURCE.COND_TYPE_CD,
  TARGET.COND_END_DT = SOURCE.COND_END_DT,
  TARGET.COND_EFF_DT = SOURCE.COND_EFF_DT,
  TARGET.COND_RECORD_NBR = SOURCE.COND_RECORD_NBR,
  TARGET.DELETE_IND = SOURCE.DELETE_IND,
  TARGET.PROMOTION_CD = SOURCE.PROMOTION_CD,
  TARGET.COND_AMT = SOURCE.COND_AMT,
  TARGET.COND_RT_UNIT = SOURCE.COND_RT_UNIT,
  TARGET.COND_PRICE_UNIT = SOURCE.COND_PRICE_UNIT,
  TARGET.COND_UNIT = SOURCE.COND_UNIT,
  TARGET.UNIT_NUMERATOR = SOURCE.UNIT_NUMERATOR,
  TARGET.UNIT_DENOMINATOR = SOURCE.UNIT_DENOMINATOR,
  TARGET.PRICING_REASON_CD = SOURCE.PRICING_REASON_CD,
  TARGET.UPDATE_DT = SOURCE.UPDATE_DT,
  TARGET.LOAD_DT = SOURCE.LOAD_DT
  WHEN MATCHED
  AND SOURCE.UPDATE_STRATEGY_FLAG = "DD_DELETE"
  AND TARGET.COND_EFF_DT = SOURCE.COND_EFF_DT
  AND TARGET.COND_RECORD_NBR = SOURCE.COND_RECORD_NBR
  AND TARGET.DELETE_IND = SOURCE.DELETE_IND
  AND TARGET.PROMOTION_CD = SOURCE.PROMOTION_CD
  AND TARGET.COND_AMT = SOURCE.COND_AMT
  AND TARGET.COND_RT_UNIT = SOURCE.COND_RT_UNIT
  AND TARGET.COND_PRICE_UNIT = SOURCE.COND_PRICE_UNIT
  AND TARGET.COND_UNIT = SOURCE.COND_UNIT
  AND TARGET.UNIT_NUMERATOR = SOURCE.UNIT_NUMERATOR
  AND TARGET.UNIT_DENOMINATOR = SOURCE.UNIT_DENOMINATOR
  AND TARGET.PRICING_REASON_CD = SOURCE.PRICING_REASON_CD
  AND TARGET.UPDATE_DT = SOURCE.UPDATE_DT
  AND TARGET.LOAD_DT = SOURCE.LOAD_DT THEN DELETE
  WHEN NOT MATCHED
  AND SOURCE.UPDATE_STRATEGY_FLAG = "DD_INSERT" THEN
INSERT
  (
    TARGET.SKU_NBR,
    TARGET.STORE_NBR,
    TARGET.SALES_ORG_CD,
    TARGET.COND_TYPE_CD,
    TARGET.COND_END_DT,
    TARGET.COND_EFF_DT,
    TARGET.COND_RECORD_NBR,
    TARGET.DELETE_IND,
    TARGET.PROMOTION_CD,
    TARGET.COND_AMT,
    TARGET.COND_RT_UNIT,
    TARGET.COND_PRICE_UNIT,
    TARGET.COND_UNIT,
    TARGET.UNIT_NUMERATOR,
    TARGET.UNIT_DENOMINATOR,
    TARGET.PRICING_REASON_CD,
    TARGET.UPDATE_DT,
    TARGET.LOAD_DT
  )
VALUES
  (
    SOURCE.SKU_NBR,
    SOURCE.STORE_NBR,
    SOURCE.SALES_ORG_CD,
    SOURCE.COND_TYPE_CD,
    SOURCE.COND_END_DT,
    SOURCE.COND_EFF_DT,
    SOURCE.COND_RECORD_NBR,
    SOURCE.DELETE_IND,
    SOURCE.PROMOTION_CD,
    SOURCE.COND_AMT,
    SOURCE.COND_RT_UNIT,
    SOURCE.COND_PRICE_UNIT,
    SOURCE.COND_UNIT,
    SOURCE.UNIT_NUMERATOR,
    SOURCE.UNIT_DENOMINATOR,
    SOURCE.PRICING_REASON_CD,
    SOURCE.UPDATE_DT,
    SOURCE.LOAD_DT
  )""")

# COMMAND ----------
#Post session variable updation
updateVariable(postVariableAssignment, variablesTableName, mainWorkflowId, parentName, "m_sku_store_price_day")

# COMMAND ----------
#Update Mapping Variables in database.
persistVariables(variablesTableName, "m_sku_store_price_day", mainWorkflowId, parentName)
