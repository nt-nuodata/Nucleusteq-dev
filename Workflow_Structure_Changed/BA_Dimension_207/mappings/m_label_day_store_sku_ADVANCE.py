# Databricks notebook source
# MAGIC %run "./udf_informatica"

# COMMAND ----------


from pyspark.sql.types import *

spark.sql("use DELTA_TRAINING")
spark.sql("set spark.sql.legacy.timeParserPolicy = LEGACY")

# COMMAND ----------
%run ./MappingUtility

# COMMAND ----------
mainWorkflowId = dbutils.widgets.get("mainWorkflowId")
mainWorkflowRunId = dbutils.widgets.get("mainWorkflowRunId")
parentName = dbutils.widgets.get("parentName")
preVariableAssignment = dbutils.widgets.get("preVariableAssignment")
postVariableAssignment = dbutils.widgets.get("postVariableAssignment")
truncTargetTableOptions = dbutils.widgets.get("truncTargetTableOptions")
variablesTableName = dbutils.widgets.get("variablesTableName")

# COMMAND ----------
#Truncate Target Tables
truncateTargetTables(truncTargetTableOptions)

# COMMAND ----------
#Pre presession variable updation
updateVariable(preVariableAssignment, variablesTableName, mainWorkflowId, parentName, "m_label_day_store_sku_ADVANCE")

# COMMAND ----------
fetchAndCreateVariables(parentName,"m_label_day_store_sku_ADVANCE", variablesTableName, mainWorkflowId)

# COMMAND ----------
# DBTITLE 1, Shortcut_to_ZTB_ADV_LBL_CHGS_PRE_0


query_0 = f"""SELECT
  MANDT AS MANDT,
  EFFECTIVE_DATE AS EFFECTIVE_DATE,
  ARTICLE AS ARTICLE,
  SITE AS SITE,
  POG_TYPE AS POG_TYPE,
  LABEL_SIZE AS LABEL_SIZE,
  LABEL_TYPE AS LABEL_TYPE,
  EXP_LABEL_TYPE AS EXP_LABEL_TYPE,
  SUPPRESS_IND AS SUPPRESS_IND,
  NUM_LABELS AS NUM_LABELS,
  CREATE_DATE AS CREATE_DATE,
  ENH_LBL_ID AS ENH_LBL_ID
FROM
  ZTB_ADV_LBL_CHGS_PRE"""

df_0 = spark.sql(query_0)

df_0.createOrReplaceTempView("Shortcut_to_ZTB_ADV_LBL_CHGS_PRE_0")

# COMMAND ----------
# DBTITLE 1, SQ_Shortcut_to_ZTB_ADV_LBL_CHGS_PRE_1


query_1 = f"""SELECT
  MANDT AS MANDT,
  EFFECTIVE_DATE AS EFFECTIVE_DATE,
  ARTICLE AS ARTICLE,
  SITE AS SITE,
  POG_TYPE AS POG_TYPE,
  LABEL_SIZE AS LABEL_SIZE,
  LABEL_TYPE AS LABEL_TYPE,
  EXP_LABEL_TYPE AS EXP_LABEL_TYPE,
  SUPPRESS_IND AS SUPPRESS_IND,
  NUM_LABELS AS NUM_LABELS,
  CREATE_DATE AS CREATE_DATE,
  ENH_LBL_ID AS ENH_LBL_ID,
  monotonically_increasing_id() AS Monotonically_Increasing_Id
FROM
  Shortcut_to_ZTB_ADV_LBL_CHGS_PRE_0"""

df_1 = spark.sql(query_1)

df_1.createOrReplaceTempView("SQ_Shortcut_to_ZTB_ADV_LBL_CHGS_PRE_1")

# COMMAND ----------
# DBTITLE 1, EXP_LBL_FIELDS_CONVERSION_2


query_2 = f"""SELECT
  TO_DATE(EFFECTIVE_DATE, 'YYYYMMDD') AS LABEL_CHANGE_DT,
  TO_INTEGER(SITE) AS STORE_NBR,
  TO_INTEGER(ARTICLE) AS SKU_NBR,
  0 AS ACTUAL_FLAG,
  POG_TYPE AS POG_TYPE,
  LABEL_SIZE AS LABEL_SIZE,
  IFF(
    IS_NUMBER(LTRIM(RTRIM(ENH_LBL_ID))),
    TO_INTEGER(LTRIM(RTRIM(ENH_LBL_ID))),
    TO_INTEGER(LABEL_TYPE)
  ) AS LABEL_TYPE,
  IFF(EXP_LABEL_TYPE = 'X', 1, 0) AS EXPIRATION_FLAG,
  IFF(SUPPRESS_IND = 'X', 1, 0) AS SUPPRESSED_FLAG,
  TO_INTEGER(NUM_LABELS) AS LABEL_CNT,
  Monotonically_Increasing_Id AS Monotonically_Increasing_Id
FROM
  SQ_Shortcut_to_ZTB_ADV_LBL_CHGS_PRE_1"""

df_2 = spark.sql(query_2)

df_2.createOrReplaceTempView("EXP_LBL_FIELDS_CONVERSION_2")

# COMMAND ----------
# DBTITLE 1, LKP_GET_LOCATION_ID_3


query_3 = f"""SELECT
  SP.LOCATION_ID AS LOCATION_ID,
  SP.LOCATION_TYPE_ID AS LOCATION_TYPE_ID,
  SP.STORE_NBR AS STORE_NBR,
  ELFC2.STORE_NBR AS STORE_NBR1,
  ELFC2.Monotonically_Increasing_Id AS Monotonically_Increasing_Id
FROM
  EXP_LBL_FIELDS_CONVERSION_2 ELFC2
  LEFT JOIN SITE_PROFILE SP ON SP.STORE_NBR = ELFC2.STORE_NBR"""

df_3 = spark.sql(query_3)

df_3.createOrReplaceTempView("LKP_GET_LOCATION_ID_3")

# COMMAND ----------
# DBTITLE 1, LKP_GET_PRODUCT_ID_4


query_4 = f"""SELECT
  SP.PRODUCT_ID AS PRODUCT_ID,
  SP.SKU_NBR AS SKU_NBR,
  ELFC2.SKU_NBR AS SKU_NBR1,
  ELFC2.Monotonically_Increasing_Id AS Monotonically_Increasing_Id
FROM
  EXP_LBL_FIELDS_CONVERSION_2 ELFC2
  LEFT JOIN SKU_PROFILE SP ON SP.SKU_NBR = ELFC2.SKU_NBR"""

df_4 = spark.sql(query_4)

df_4.createOrReplaceTempView("LKP_GET_PRODUCT_ID_4")

# COMMAND ----------
# DBTITLE 1, LKP_GET_TIME_DIMENSIONS_5


query_5 = f"""SELECT
  D.DAY_DT AS DAY_DT,
  D.FISCAL_WK AS FISCAL_WK,
  D.FISCAL_MO AS FISCAL_MO,
  D.FISCAL_YR AS FISCAL_YR,
  D.WEEK_DT AS WEEK_DT,
  ELFC2.LABEL_CHANGE_DT AS LABEL_CHANGE_DT,
  ELFC2.Monotonically_Increasing_Id AS Monotonically_Increasing_Id
FROM
  EXP_LBL_FIELDS_CONVERSION_2 ELFC2
  LEFT JOIN DAYS D ON D.DAY_DT = ELFC2.LABEL_CHANGE_DT"""

df_5 = spark.sql(query_5)

df_5.createOrReplaceTempView("LKP_GET_TIME_DIMENSIONS_5")

# COMMAND ----------
# DBTITLE 1, EXP_LOAD_TSTMP_6


query_6 = f"""SELECT
  ELFC2.LABEL_CHANGE_DT AS LABEL_CHANGE_DT,
  LGLI3.LOCATION_ID AS LOCATION_ID,
  LGPI4.PRODUCT_ID AS PRODUCT_ID,
  ELFC2.ACTUAL_FLAG AS ACTUAL_FLAG,
  ELFC2.POG_TYPE AS POG_TYPE,
  ELFC2.LABEL_SIZE AS LABEL_SIZE,
  ELFC2.LABEL_TYPE AS LABEL_TYPE,
  ELFC2.EXPIRATION_FLAG AS EXPIRATION_FLAG,
  ELFC2.SKU_NBR AS SKU_NBR,
  ELFC2.STORE_NBR AS STORE_NBR,
  LGTD5.WEEK_DT AS WEEK_DT,
  LGTD5.FISCAL_WK AS FISCAL_WK,
  LGTD5.FISCAL_MO AS FISCAL_MO,
  LGTD5.FISCAL_YR AS FISCAL_YR,
  ELFC2.SUPPRESSED_FLAG AS SUPPRESSED_FLAG,
  ELFC2.LABEL_CNT AS LABEL_CNT,
  now() AS UPDATE_TSTMP,
  LGTD5.Monotonically_Increasing_Id AS Monotonically_Increasing_Id
FROM
  LKP_GET_TIME_DIMENSIONS_5 LGTD5
  INNER JOIN LKP_GET_PRODUCT_ID_4 LGPI4 ON LGTD5.Monotonically_Increasing_Id = LGPI4.Monotonically_Increasing_Id
  INNER JOIN LKP_GET_LOCATION_ID_3 LGLI3 ON LGPI4.Monotonically_Increasing_Id = LGLI3.Monotonically_Increasing_Id
  INNER JOIN EXP_LBL_FIELDS_CONVERSION_2 ELFC2 ON LGLI3.Monotonically_Increasing_Id = ELFC2.Monotonically_Increasing_Id"""

df_6 = spark.sql(query_6)

df_6.createOrReplaceTempView("EXP_LOAD_TSTMP_6")

# COMMAND ----------
# DBTITLE 1, Shortcut_to_LABEL_DAY_STORE_SKU1_7


query_7 = f"""SELECT
  LABEL_CHANGE_DT AS LABEL_CHANGE_DT,
  LOCATION_ID AS LOCATION_ID,
  PRODUCT_ID AS PRODUCT_ID,
  ACTUAL_FLAG AS ACTUAL_FLAG,
  LABEL_POG_TYPE_CD AS LABEL_POG_TYPE_CD,
  LABEL_SIZE_ID AS LABEL_SIZE_ID,
  LABEL_TYPE_ID AS LABEL_TYPE_ID,
  EXPIRATION_FLAG AS EXPIRATION_FLAG,
  SKU_NBR AS SKU_NBR,
  STORE_NBR AS STORE_NBR,
  WEEK_DT AS WEEK_DT,
  FISCAL_WK AS FISCAL_WK,
  FISCAL_MO AS FISCAL_MO,
  FISCAL_YR AS FISCAL_YR,
  SUPPRESSED_FLAG AS SUPPRESSED_FLAG,
  LABEL_CNT AS LABEL_CNT,
  UPDATE_TSTMP AS UPDATE_TSTMP,
  LOAD_TSTMP AS LOAD_TSTMP
FROM
  LABEL_DAY_STORE_SKU"""

df_7 = spark.sql(query_7)

df_7.createOrReplaceTempView("Shortcut_to_LABEL_DAY_STORE_SKU1_7")

# COMMAND ----------
# DBTITLE 1, SQ_Shortcut_to_LABEL_DAY_STORE_SKU_8


query_8 = f"""SELECT
  LABEL_CHANGE_DT AS LABEL_CHANGE_DT,
  LOCATION_ID AS LOCATION_ID,
  PRODUCT_ID AS PRODUCT_ID,
  ACTUAL_FLAG AS ACTUAL_FLAG,
  LABEL_POG_TYPE_CD AS LABEL_POG_TYPE_CD,
  LABEL_SIZE_ID AS LABEL_SIZE_ID,
  LABEL_TYPE_ID AS LABEL_TYPE_ID,
  EXPIRATION_FLAG AS EXPIRATION_FLAG,
  SKU_NBR AS SKU_NBR,
  STORE_NBR AS STORE_NBR,
  WEEK_DT AS WEEK_DT,
  FISCAL_WK AS FISCAL_WK,
  FISCAL_MO AS FISCAL_MO,
  FISCAL_YR AS FISCAL_YR,
  SUPPRESSED_FLAG AS SUPPRESSED_FLAG,
  LABEL_CNT AS LABEL_CNT,
  LOAD_TSTMP AS LOAD_TSTMP,
  monotonically_increasing_id() AS Monotonically_Increasing_Id
FROM
  Shortcut_to_LABEL_DAY_STORE_SKU1_7
WHERE
  Shortcut_to_LABEL_DAY_STORE_SKU1_7.ACTUAL_FLAG = 0
  AND Shortcut_to_LABEL_DAY_STORE_SKU1_7.LOAD_TSTMP > CURRENT_DATE - 15"""

df_8 = spark.sql(query_8)

df_8.createOrReplaceTempView("SQ_Shortcut_to_LABEL_DAY_STORE_SKU_8")

# COMMAND ----------
# DBTITLE 1, JNR_LABEL_DAY_STORE_SKU__ZTB_9


query_9 = f"""SELECT
  MASTER.LABEL_CHANGE_DT AS LABEL_CHANGE_DT,
  MASTER.LOCATION_ID AS LOCATION_ID,
  MASTER.PRODUCT_ID AS PRODUCT_ID,
  MASTER.ACTUAL_FLAG AS ACTUAL_FLAG,
  MASTER.POG_TYPE AS POG_TYPE,
  MASTER.LABEL_SIZE AS LABEL_SIZE,
  MASTER.LABEL_TYPE AS LABEL_TYPE,
  MASTER.EXPIRATION_FLAG AS EXPIRATION_FLAG,
  MASTER.SKU_NBR AS SKU_NBR,
  MASTER.STORE_NBR AS STORE_NBR,
  MASTER.WEEK_DT AS WEEK_DT,
  MASTER.FISCAL_WK AS FISCAL_WK,
  MASTER.FISCAL_MO AS FISCAL_MO,
  MASTER.FISCAL_YR AS FISCAL_YR,
  MASTER.SUPPRESSED_FLAG AS SUPPRESSED_FLAG,
  MASTER.LABEL_CNT AS LABEL_CNT,
  MASTER.UPDATE_TSTMP AS UPDATE_TSTMP,
  DETAIL.LABEL_CHANGE_DT AS LABEL_CHANGE_DT_OLD,
  DETAIL.LOCATION_ID AS LOCATION_ID_OLD,
  DETAIL.PRODUCT_ID AS PRODUCT_ID_OLD,
  DETAIL.ACTUAL_FLAG AS ACTUAL_FLAG_OLD,
  DETAIL.LABEL_POG_TYPE_CD AS LABEL_POG_TYPE_CD_OLD,
  DETAIL.LABEL_SIZE_ID AS LABEL_SIZE_ID_OLD,
  DETAIL.LABEL_TYPE_ID AS LABEL_TYPE_ID_OLD,
  DETAIL.EXPIRATION_FLAG AS EXPIRATION_FLAG_OLD,
  DETAIL.SKU_NBR AS SKU_NBR_OLD,
  DETAIL.STORE_NBR AS STORE_NBR_OLD,
  DETAIL.WEEK_DT AS WEEK_DT_OLD,
  DETAIL.FISCAL_WK AS FISCAL_WK_OLD,
  DETAIL.FISCAL_MO AS FISCAL_MO_OLD,
  DETAIL.FISCAL_YR AS FISCAL_YR_OLD,
  DETAIL.SUPPRESSED_FLAG AS SUPPRESSED_FLAG_OLD,
  DETAIL.LABEL_CNT AS LABEL_CNT_OLD,
  DETAIL.LOAD_TSTMP AS LOAD_TSTMP_OLD,
  MASTER.Monotonically_Increasing_Id AS Monotonically_Increasing_Id
FROM
  EXP_LOAD_TSTMP_6 MASTER
  LEFT JOIN SQ_Shortcut_to_LABEL_DAY_STORE_SKU_8 DETAIL ON MASTER.LABEL_CHANGE_DT = DETAIL.LABEL_CHANGE_DT
  AND MASTER.LOCATION_ID = DETAIL.LOCATION_ID
  AND MASTER.PRODUCT_ID = DETAIL.PRODUCT_ID
  AND MASTER.ACTUAL_FLAG = DETAIL.ACTUAL_FLAG
  AND MASTER.POG_TYPE = DETAIL.LABEL_POG_TYPE_CD
  AND MASTER.LABEL_SIZE = DETAIL.LABEL_SIZE_ID
  AND MASTER.LABEL_TYPE = DETAIL.LABEL_TYPE_ID
  AND MASTER.EXPIRATION_FLAG = DETAIL.EXPIRATION_FLAG"""

df_9 = spark.sql(query_9)

df_9.createOrReplaceTempView("JNR_LABEL_DAY_STORE_SKU__ZTB_9")

# COMMAND ----------
# DBTITLE 1, EXP_MD5_10


query_10 = f"""SELECT
  LABEL_CHANGE_DT AS LABEL_CHANGE_DT,
  LOCATION_ID AS LOCATION_ID,
  PRODUCT_ID AS PRODUCT_ID,
  ACTUAL_FLAG AS ACTUAL_FLAG,
  POG_TYPE AS POG_TYPE,
  LABEL_SIZE AS LABEL_SIZE,
  LABEL_TYPE AS LABEL_TYPE,
  EXPIRATION_FLAG AS EXPIRATION_FLAG,
  SKU_NBR AS SKU_NBR,
  STORE_NBR AS STORE_NBR,
  WEEK_DT AS WEEK_DT,
  FISCAL_WK AS FISCAL_WK,
  FISCAL_MO AS FISCAL_MO,
  FISCAL_YR AS FISCAL_YR,
  SUPPRESSED_FLAG AS SUPPRESSED_FLAG,
  LABEL_CNT AS LABEL_CNT,
  UPDATE_TSTMP AS UPDATE_TSTMP,
  IFF(
    ISNULL(LABEL_CHANGE_DT_OLD),
    now(),
    LOAD_TSTMP_OLD
  ) AS LOAD_TSTMP,
  MD5(
    TO_CHAR(SKU_NBR) || TO_CHAR(STORE_NBR) || TO_CHAR(WEEK_DT) || TO_CHAR(FISCAL_WK) || TO_CHAR(FISCAL_MO) || TO_CHAR(FISCAL_YR) || TO_CHAR(SUPPRESSED_FLAG) || TO_CHAR(LABEL_CNT)
  ) AS MD5_PRE,
  MD5(
    TO_CHAR(SKU_NBR_OLD) || TO_CHAR(STORE_NBR_OLD) || TO_CHAR(WEEK_DT_OLD) || TO_CHAR(FISCAL_WK_OLD) || TO_CHAR(FISCAL_MO_OLD) || TO_CHAR(FISCAL_YR_OLD) || TO_CHAR(SUPPRESSED_FLAG_OLD) || TO_CHAR(LABEL_CNT_OLD)
  ) AS MD5_OLD,
  IFF(
    ISNULL(LABEL_CHANGE_DT_OLD),
    'DD_INSERT',
    IFF(
      MD5(
        TO_CHAR(SKU_NBR) || TO_CHAR(STORE_NBR) || TO_CHAR(WEEK_DT) || TO_CHAR(FISCAL_WK) || TO_CHAR(FISCAL_MO) || TO_CHAR(FISCAL_YR) || TO_CHAR(SUPPRESSED_FLAG) || TO_CHAR(LABEL_CNT)
      ) <> MD5(
        TO_CHAR(SKU_NBR_OLD) || TO_CHAR(STORE_NBR_OLD) || TO_CHAR(WEEK_DT_OLD) || TO_CHAR(FISCAL_WK_OLD) || TO_CHAR(FISCAL_MO_OLD) || TO_CHAR(FISCAL_YR_OLD) || TO_CHAR(SUPPRESSED_FLAG_OLD) || TO_CHAR(LABEL_CNT_OLD)
      ),
      'DD_UPDATE',
      'DD_REJECT'
    )
  ) AS UPDATE_STRATEGY,
  Monotonically_Increasing_Id AS Monotonically_Increasing_Id
FROM
  JNR_LABEL_DAY_STORE_SKU__ZTB_9"""

df_10 = spark.sql(query_10)

df_10.createOrReplaceTempView("EXP_MD5_10")

# COMMAND ----------
# DBTITLE 1, FIL_INS_UPD_11


query_11 = f"""SELECT
  LABEL_CHANGE_DT AS LABEL_CHANGE_DT,
  LOCATION_ID AS LOCATION_ID,
  PRODUCT_ID AS PRODUCT_ID,
  ACTUAL_FLAG AS ACTUAL_FLAG,
  POG_TYPE AS POG_TYPE,
  LABEL_SIZE AS LABEL_SIZE,
  LABEL_TYPE AS LABEL_TYPE,
  EXPIRATION_FLAG AS EXPIRATION_FLAG,
  SKU_NBR AS SKU_NBR,
  STORE_NBR AS STORE_NBR,
  WEEK_DT AS WEEK_DT,
  FISCAL_WK AS FISCAL_WK,
  FISCAL_MO AS FISCAL_MO,
  FISCAL_YR AS FISCAL_YR,
  SUPPRESSED_FLAG AS SUPPRESSED_FLAG,
  LABEL_CNT AS LABEL_CNT,
  UPDATE_TSTMP AS UPDATE_TSTMP,
  LOAD_TSTMP AS LOAD_TSTMP,
  UPDATE_STRATEGY AS UPDATE_STRATEGY,
  Monotonically_Increasing_Id AS Monotonically_Increasing_Id
FROM
  EXP_MD5_10
WHERE
  UPDATE_STRATEGY <> 'DD_REJECT'"""

df_11 = spark.sql(query_11)

df_11.createOrReplaceTempView("FIL_INS_UPD_11")

# COMMAND ----------
# DBTITLE 1, UPS_LABEL_DAY_STORE_SKU_12


query_12 = f"""SELECT
  LABEL_CHANGE_DT AS LABEL_CHANGE_DT,
  LOCATION_ID AS LOCATION_ID,
  PRODUCT_ID AS PRODUCT_ID,
  ACTUAL_FLAG AS ACTUAL_FLAG,
  POG_TYPE AS POG_TYPE,
  LABEL_SIZE AS LABEL_SIZE,
  LABEL_TYPE AS LABEL_TYPE,
  EXPIRATION_FLAG AS EXPIRATION_FLAG,
  SKU_NBR AS SKU_NBR,
  STORE_NBR AS STORE_NBR,
  WEEK_DT AS WEEK_DT,
  FISCAL_WK AS FISCAL_WK,
  FISCAL_MO AS FISCAL_MO,
  FISCAL_YR AS FISCAL_YR,
  SUPPRESSED_FLAG AS SUPPRESSED_FLAG,
  LABEL_CNT AS LABEL_CNT,
  UPDATE_TSTMP AS UPDATE_TSTMP,
  LOAD_TSTMP AS LOAD_TSTMP,
  UPDATE_STRATEGY AS UPDATE_STRATEGY,
  Monotonically_Increasing_Id AS Monotonically_Increasing_Id,
  UPDATE_STRATEGY AS UPDATE_STRATEGY_FLAG
FROM
  FIL_INS_UPD_11"""

df_12 = spark.sql(query_12)

df_12.createOrReplaceTempView("UPS_LABEL_DAY_STORE_SKU_12")

# COMMAND ----------
# DBTITLE 1, LABEL_DAY_STORE_SKU


spark.sql("""MERGE INTO LABEL_DAY_STORE_SKU AS TARGET
USING
  UPS_LABEL_DAY_STORE_SKU_12 AS SOURCE ON TARGET.PRODUCT_ID = SOURCE.PRODUCT_ID
  AND TARGET.LABEL_CHANGE_DT = SOURCE.LABEL_CHANGE_DT
  AND TARGET.LOCATION_ID = SOURCE.LOCATION_ID
  AND TARGET.LABEL_POG_TYPE_CD = SOURCE.POG_TYPE
  AND TARGET.LABEL_SIZE_ID = SOURCE.LABEL_SIZE
  AND TARGET.LABEL_TYPE_ID = SOURCE.LABEL_TYPE
  AND TARGET.EXPIRATION_FLAG = SOURCE.EXPIRATION_FLAG
  AND TARGET.ACTUAL_FLAG = SOURCE.ACTUAL_FLAG
  WHEN MATCHED
  AND SOURCE.UPDATE_STRATEGY_FLAG = "DD_UPDATE" THEN
UPDATE
SET
  TARGET.LABEL_CHANGE_DT = SOURCE.LABEL_CHANGE_DT,
  TARGET.LOCATION_ID = SOURCE.LOCATION_ID,
  TARGET.PRODUCT_ID = SOURCE.PRODUCT_ID,
  TARGET.ACTUAL_FLAG = SOURCE.ACTUAL_FLAG,
  TARGET.LABEL_POG_TYPE_CD = SOURCE.POG_TYPE,
  TARGET.LABEL_SIZE_ID = SOURCE.LABEL_SIZE,
  TARGET.LABEL_TYPE_ID = SOURCE.LABEL_TYPE,
  TARGET.EXPIRATION_FLAG = SOURCE.EXPIRATION_FLAG,
  TARGET.SKU_NBR = SOURCE.SKU_NBR,
  TARGET.STORE_NBR = SOURCE.STORE_NBR,
  TARGET.WEEK_DT = SOURCE.WEEK_DT,
  TARGET.FISCAL_WK = SOURCE.FISCAL_WK,
  TARGET.FISCAL_MO = SOURCE.FISCAL_MO,
  TARGET.FISCAL_YR = SOURCE.FISCAL_YR,
  TARGET.SUPPRESSED_FLAG = SOURCE.SUPPRESSED_FLAG,
  TARGET.LABEL_CNT = SOURCE.LABEL_CNT,
  TARGET.UPDATE_TSTMP = SOURCE.UPDATE_TSTMP,
  TARGET.LOAD_TSTMP = SOURCE.LOAD_TSTMP
  WHEN MATCHED
  AND SOURCE.UPDATE_STRATEGY_FLAG = "DD_DELETE"
  AND TARGET.SKU_NBR = SOURCE.SKU_NBR
  AND TARGET.STORE_NBR = SOURCE.STORE_NBR
  AND TARGET.WEEK_DT = SOURCE.WEEK_DT
  AND TARGET.FISCAL_WK = SOURCE.FISCAL_WK
  AND TARGET.FISCAL_MO = SOURCE.FISCAL_MO
  AND TARGET.FISCAL_YR = SOURCE.FISCAL_YR
  AND TARGET.SUPPRESSED_FLAG = SOURCE.SUPPRESSED_FLAG
  AND TARGET.LABEL_CNT = SOURCE.LABEL_CNT
  AND TARGET.UPDATE_TSTMP = SOURCE.UPDATE_TSTMP
  AND TARGET.LOAD_TSTMP = SOURCE.LOAD_TSTMP THEN DELETE
  WHEN NOT MATCHED
  AND SOURCE.UPDATE_STRATEGY_FLAG = "DD_INSERT" THEN
INSERT
  (
    TARGET.LABEL_CHANGE_DT,
    TARGET.LOCATION_ID,
    TARGET.PRODUCT_ID,
    TARGET.ACTUAL_FLAG,
    TARGET.LABEL_POG_TYPE_CD,
    TARGET.LABEL_SIZE_ID,
    TARGET.LABEL_TYPE_ID,
    TARGET.EXPIRATION_FLAG,
    TARGET.SKU_NBR,
    TARGET.STORE_NBR,
    TARGET.WEEK_DT,
    TARGET.FISCAL_WK,
    TARGET.FISCAL_MO,
    TARGET.FISCAL_YR,
    TARGET.SUPPRESSED_FLAG,
    TARGET.LABEL_CNT,
    TARGET.UPDATE_TSTMP,
    TARGET.LOAD_TSTMP
  )
VALUES
  (
    SOURCE.LABEL_CHANGE_DT,
    SOURCE.LOCATION_ID,
    SOURCE.PRODUCT_ID,
    SOURCE.ACTUAL_FLAG,
    SOURCE.POG_TYPE,
    SOURCE.LABEL_SIZE,
    SOURCE.LABEL_TYPE,
    SOURCE.EXPIRATION_FLAG,
    SOURCE.SKU_NBR,
    SOURCE.STORE_NBR,
    SOURCE.WEEK_DT,
    SOURCE.FISCAL_WK,
    SOURCE.FISCAL_MO,
    SOURCE.FISCAL_YR,
    SOURCE.SUPPRESSED_FLAG,
    SOURCE.LABEL_CNT,
    SOURCE.UPDATE_TSTMP,
    SOURCE.LOAD_TSTMP
  )""")

# COMMAND ----------
#Post session variable updation
updateVariable(postVariableAssignment, variablesTableName, mainWorkflowId, parentName, "m_label_day_store_sku_ADVANCE")

# COMMAND ----------
#Update Mapping Variables in database.
persistVariables(variablesTableName, "m_label_day_store_sku_ADVANCE", mainWorkflowId, parentName)
