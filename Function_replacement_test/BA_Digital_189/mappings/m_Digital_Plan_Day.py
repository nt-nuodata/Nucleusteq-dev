# Databricks notebook source
# MAGIC %run "./udf_informatica"

# COMMAND ----------


from pyspark.sql.types import *

spark.sql("use DELTA_TRAINING")
spark.sql("set spark.sql.legacy.timeParserPolicy = LEGACY")

# COMMAND ----------
%run ../WorkflowUtility

# COMMAND ----------
mainWorkflowId = dbutils.widgets.get("mainWorkflowId")
mainWorkflowRunId = dbutils.widgets.get("mainWorkflowRunId")
parentName = dbutils.widgets.get("parentName")
preVariableAssignment = dbutils.widgets.get("preVariableAssignment")
postVariableAssignment = dbutils.widgets.get("postVariableAssignment")
truncTargetTableOptions = dbutils.widgets.get("truncTargetTableOptions")
variablesTableName = dbutils.widgets.get("variablesTableName")

# COMMAND ----------
#Truncate Target Tables
truncateTargetTables(truncTargetTableOptions)

# COMMAND ----------
#Pre presession variable updation
updateVariable(preVariableAssignment, variablesTableName, mainWorkflowId, parentName, "m_Digital_Plan_Day")

# COMMAND ----------
fetchAndCreateVariables(parentName,"m_Digital_Plan_Day", variablesTableName, mainWorkflowId)

# COMMAND ----------
# DBTITLE 1, Shortcut_to_DIGITAL_PLAN_FORECAST_DOW_REF_0


query_0 = f"""SELECT
  FISCAL_YR AS FISCAL_YR,
  DIGITAL_CHANNEL AS DIGITAL_CHANNEL,
  MON_SALES_PCT AS MON_SALES_PCT,
  TUE_SALES_PCT AS TUE_SALES_PCT,
  WED_SALES_PCT AS WED_SALES_PCT,
  THU_SALES_PCT AS THU_SALES_PCT,
  FRI_SALES_PCT AS FRI_SALES_PCT,
  SAT_SALES_PCT AS SAT_SALES_PCT,
  SUN_SALES_PCT AS SUN_SALES_PCT,
  MON_MARGIN_PCT AS MON_MARGIN_PCT,
  TUE_MARGIN_PCT AS TUE_MARGIN_PCT,
  WED_MARGIN_PCT AS WED_MARGIN_PCT,
  THU_MARGIN_PCT AS THU_MARGIN_PCT,
  FRI_MARGIN_PCT AS FRI_MARGIN_PCT,
  SAT_MARGIN_PCT AS SAT_MARGIN_PCT,
  SUN_MARGIN_PCT AS SUN_MARGIN_PCT,
  MON_ORDER_PCT AS MON_ORDER_PCT,
  TUE_ORDER_PCT AS TUE_ORDER_PCT,
  WED_ORDER_PCT AS WED_ORDER_PCT,
  THU_ORDER_PCT AS THU_ORDER_PCT,
  FRI_ORDER_PCT AS FRI_ORDER_PCT,
  SAT_ORDER_PCT AS SAT_ORDER_PCT,
  SUN_ORDER_PCT AS SUN_ORDER_PCT,
  UPDATE_TSTMP AS UPDATE_TSTMP,
  LOAD_TSTMP AS LOAD_TSTMP
FROM
  DIGITAL_PLAN_FORECAST_DOW_REF"""

df_0 = spark.sql(query_0)

df_0.createOrReplaceTempView("Shortcut_to_DIGITAL_PLAN_FORECAST_DOW_REF_0")

# COMMAND ----------
# DBTITLE 1, SQ_Shortcut_to_DIGITAL_PLAN_FORECAST_DOW_REF_1


query_1 = f"""SELECT
  FISCAL_YR AS FISCAL_YR,
  DIGITAL_CHANNEL AS DIGITAL_CHANNEL,
  MON_SALES_PCT AS MON_SALES_PCT,
  TUE_SALES_PCT AS TUE_SALES_PCT,
  WED_SALES_PCT AS WED_SALES_PCT,
  THU_SALES_PCT AS THU_SALES_PCT,
  FRI_SALES_PCT AS FRI_SALES_PCT,
  SAT_SALES_PCT AS SAT_SALES_PCT,
  SUN_SALES_PCT AS SUN_SALES_PCT,
  MON_MARGIN_PCT AS MON_MARGIN_PCT,
  TUE_MARGIN_PCT AS TUE_MARGIN_PCT,
  WED_MARGIN_PCT AS WED_MARGIN_PCT,
  THU_MARGIN_PCT AS THU_MARGIN_PCT,
  FRI_MARGIN_PCT AS FRI_MARGIN_PCT,
  SAT_MARGIN_PCT AS SAT_MARGIN_PCT,
  SUN_MARGIN_PCT AS SUN_MARGIN_PCT,
  MON_ORDER_PCT AS MON_ORDER_PCT,
  TUE_ORDER_PCT AS TUE_ORDER_PCT,
  WED_ORDER_PCT AS WED_ORDER_PCT,
  THU_ORDER_PCT AS THU_ORDER_PCT,
  FRI_ORDER_PCT AS FRI_ORDER_PCT,
  SAT_ORDER_PCT AS SAT_ORDER_PCT,
  SUN_ORDER_PCT AS SUN_ORDER_PCT,
  UPDATE_TSTMP AS UPDATE_TSTMP,
  LOAD_TSTMP AS LOAD_TSTMP,
  monotonically_increasing_id() AS Monotonically_Increasing_Id
FROM
  Shortcut_to_DIGITAL_PLAN_FORECAST_DOW_REF_0"""

df_1 = spark.sql(query_1)

df_1.createOrReplaceTempView("SQ_Shortcut_to_DIGITAL_PLAN_FORECAST_DOW_REF_1")

# COMMAND ----------
# DBTITLE 1, FIL_Prev_Year_2


query_2 = f"""SELECT
  FISCAL_YR AS FISCAL_YR,
  DIGITAL_CHANNEL AS DIGITAL_CHANNEL,
  MON_SALES_PCT AS MON_SALES_PCT,
  TUE_SALES_PCT AS TUE_SALES_PCT,
  WED_SALES_PCT AS WED_SALES_PCT,
  THU_SALES_PCT AS THU_SALES_PCT,
  FRI_SALES_PCT AS FRI_SALES_PCT,
  SAT_SALES_PCT AS SAT_SALES_PCT,
  SUN_SALES_PCT AS SUN_SALES_PCT,
  MON_MARGIN_PCT AS MON_MARGIN_PCT,
  TUE_MARGIN_PCT AS TUE_MARGIN_PCT,
  WED_MARGIN_PCT AS WED_MARGIN_PCT,
  THU_MARGIN_PCT AS THU_MARGIN_PCT,
  FRI_MARGIN_PCT AS FRI_MARGIN_PCT,
  SAT_MARGIN_PCT AS SAT_MARGIN_PCT,
  SUN_MARGIN_PCT AS SUN_MARGIN_PCT,
  MON_ORDER_PCT AS MON_ORDER_PCT,
  TUE_ORDER_PCT AS TUE_ORDER_PCT,
  WED_ORDER_PCT AS WED_ORDER_PCT,
  THU_ORDER_PCT AS THU_ORDER_PCT,
  FRI_ORDER_PCT AS FRI_ORDER_PCT,
  SAT_ORDER_PCT AS SAT_ORDER_PCT,
  SUN_ORDER_PCT AS SUN_ORDER_PCT,
  UPDATE_TSTMP AS UPDATE_TSTMP,
  LOAD_TSTMP AS LOAD_TSTMP,
  Monotonically_Increasing_Id AS Monotonically_Increasing_Id
FROM
  SQ_Shortcut_to_DIGITAL_PLAN_FORECAST_DOW_REF_1
WHERE
  FISCAL_YR = GET_DATE_PART(now(), 'YYYY') -1"""

df_2 = spark.sql(query_2)

df_2.createOrReplaceTempView("FIL_Prev_Year_2")

# COMMAND ----------
# DBTITLE 1, EXP_DOW_3


query_3 = f"""SELECT
  FISCAL_YR + 1 AS o_FISCAL_YR,
  UPPER(DIGITAL_CHANNEL) AS DIGITAL_CHANNEL,
  MON_SALES_PCT AS MON_SALES_PCT,
  TUE_SALES_PCT AS TUE_SALES_PCT,
  WED_SALES_PCT AS WED_SALES_PCT,
  THU_SALES_PCT AS THU_SALES_PCT,
  FRI_SALES_PCT AS FRI_SALES_PCT,
  SAT_SALES_PCT AS SAT_SALES_PCT,
  SUN_SALES_PCT AS SUN_SALES_PCT,
  MON_MARGIN_PCT AS MON_MARGIN_PCT,
  TUE_MARGIN_PCT AS TUE_MARGIN_PCT,
  WED_MARGIN_PCT AS WED_MARGIN_PCT,
  THU_MARGIN_PCT AS THU_MARGIN_PCT,
  FRI_MARGIN_PCT AS FRI_MARGIN_PCT,
  SAT_MARGIN_PCT AS SAT_MARGIN_PCT,
  SUN_MARGIN_PCT AS SUN_MARGIN_PCT,
  MON_ORDER_PCT AS MON_ORDER_PCT,
  TUE_ORDER_PCT AS TUE_ORDER_PCT,
  WED_ORDER_PCT AS WED_ORDER_PCT,
  THU_ORDER_PCT AS THU_ORDER_PCT,
  FRI_ORDER_PCT AS FRI_ORDER_PCT,
  SAT_ORDER_PCT AS SAT_ORDER_PCT,
  SUN_ORDER_PCT AS SUN_ORDER_PCT,
  UPDATE_TSTMP AS UPDATE_TSTMP,
  LOAD_TSTMP AS LOAD_TSTMP,
  Monotonically_Increasing_Id AS Monotonically_Increasing_Id
FROM
  FIL_Prev_Year_2"""

df_3 = spark.sql(query_3)

df_3.createOrReplaceTempView("EXP_DOW_3")

# COMMAND ----------
# DBTITLE 1, Shortcut_to_DIGITAL_PLAN_DAY_4


query_4 = f"""SELECT
  DAY_DT AS DAY_DT,
  DIGITAL_CHANNEL AS DIGITAL_CHANNEL,
  FISCAL_YR AS FISCAL_YR,
  FISCAL_WK AS FISCAL_WK,
  PLAN_SALES_AMT_USD AS PLAN_SALES_AMT_USD,
  PLAN_MARGIN_AMT_USD AS PLAN_MARGIN_AMT_USD,
  PLAN_ORDER_CNT AS PLAN_ORDER_CNT,
  UPDATE_TSTMP AS UPDATE_TSTMP,
  LOAD_TSTMP AS LOAD_TSTMP
FROM
  DIGITAL_PLAN_DAY"""

df_4 = spark.sql(query_4)

df_4.createOrReplaceTempView("Shortcut_to_DIGITAL_PLAN_DAY_4")

# COMMAND ----------
# DBTITLE 1, SQ_Shortcut_to_DIGITAL_PLAN_DAY_5


query_5 = f"""SELECT
  DAY_DT AS DAY_DT,
  DIGITAL_CHANNEL AS DIGITAL_CHANNEL,
  FISCAL_YR AS FISCAL_YR,
  FISCAL_WK AS FISCAL_WK,
  PLAN_SALES_AMT_USD AS PLAN_SALES_AMT_USD,
  PLAN_MARGIN_AMT_USD AS PLAN_MARGIN_AMT_USD,
  PLAN_ORDER_CNT AS PLAN_ORDER_CNT,
  UPDATE_TSTMP AS UPDATE_TSTMP,
  LOAD_TSTMP AS LOAD_TSTMP,
  monotonically_increasing_id() AS Monotonically_Increasing_Id
FROM
  Shortcut_to_DIGITAL_PLAN_DAY_4"""

df_5 = spark.sql(query_5)

df_5.createOrReplaceTempView("SQ_Shortcut_to_DIGITAL_PLAN_DAY_5")

# COMMAND ----------
# DBTITLE 1, Shortcut_to_DIGITAL_PLAN_WEEK_6


query_6 = f"""SELECT
  FISCAL_YR AS FISCAL_YR,
  FISCAL_WK AS FISCAL_WK,
  DIGITAL_CHANNEL AS DIGITAL_CHANNEL,
  PLAN_SALES_AMT_USD AS PLAN_SALES_AMT_USD,
  PLAN_MARGIN_AMT_USD AS PLAN_MARGIN_AMT_USD,
  PLAN_ORDER_CNT AS PLAN_ORDER_CNT,
  UPDATE_TSTMP AS UPDATE_TSTMP,
  LOAD_TSTMP AS LOAD_TSTMP
FROM
  DIGITAL_PLAN_WEEK"""

df_6 = spark.sql(query_6)

df_6.createOrReplaceTempView("Shortcut_to_DIGITAL_PLAN_WEEK_6")

# COMMAND ----------
# DBTITLE 1, SQ_Shortcut_to_DIGITAL_PLAN_WEEK_7


query_7 = f"""SELECT
  FISCAL_YR AS FISCAL_YR,
  FISCAL_WK AS FISCAL_WK,
  DIGITAL_CHANNEL AS DIGITAL_CHANNEL,
  PLAN_SALES_AMT_USD AS PLAN_SALES_AMT_USD,
  PLAN_MARGIN_AMT_USD AS PLAN_MARGIN_AMT_USD,
  PLAN_ORDER_CNT AS PLAN_ORDER_CNT,
  UPDATE_TSTMP AS UPDATE_TSTMP,
  LOAD_TSTMP AS LOAD_TSTMP,
  monotonically_increasing_id() AS Monotonically_Increasing_Id
FROM
  Shortcut_to_DIGITAL_PLAN_WEEK_6"""

df_7 = spark.sql(query_7)

df_7.createOrReplaceTempView("SQ_Shortcut_to_DIGITAL_PLAN_WEEK_7")

# COMMAND ----------
# DBTITLE 1, FIL_Curr_Year_8


query_8 = f"""SELECT
  FISCAL_YR AS FISCAL_YR,
  FISCAL_WK AS FISCAL_WK,
  DIGITAL_CHANNEL AS DIGITAL_CHANNEL,
  PLAN_SALES_AMT_USD AS PLAN_SALES_AMT_USD,
  PLAN_MARGIN_AMT_USD AS PLAN_MARGIN_AMT_USD,
  PLAN_ORDER_CNT AS PLAN_ORDER_CNT,
  Monotonically_Increasing_Id AS Monotonically_Increasing_Id
FROM
  SQ_Shortcut_to_DIGITAL_PLAN_WEEK_7
WHERE
  FISCAL_YR = GET_DATE_PART(now(), 'YYYY')"""

df_8 = spark.sql(query_8)

df_8.createOrReplaceTempView("FIL_Curr_Year_8")

# COMMAND ----------
# DBTITLE 1, Shortcut_To_DAYS_9


query_9 = f"""SELECT
  DAY_DT AS DAY_DT,
  BUSINESS_DAY_FLAG AS BUSINESS_DAY_FLAG,
  HOLIDAY_FLAG AS HOLIDAY_FLAG,
  DAY_OF_WK_NAME AS DAY_OF_WK_NAME,
  DAY_OF_WK_NAME_ABBR AS DAY_OF_WK_NAME_ABBR,
  DAY_OF_WK_NBR AS DAY_OF_WK_NBR,
  CAL_DAY_OF_MO_NBR AS CAL_DAY_OF_MO_NBR,
  CAL_DAY_OF_YR_NBR AS CAL_DAY_OF_YR_NBR,
  CAL_WK AS CAL_WK,
  CAL_WK_NBR AS CAL_WK_NBR,
  CAL_MO AS CAL_MO,
  CAL_MO_NBR AS CAL_MO_NBR,
  CAL_MO_NAME AS CAL_MO_NAME,
  CAL_MO_NAME_ABBR AS CAL_MO_NAME_ABBR,
  CAL_QTR AS CAL_QTR,
  CAL_QTR_NBR AS CAL_QTR_NBR,
  CAL_HALF AS CAL_HALF,
  CAL_YR AS CAL_YR,
  FISCAL_DAY_OF_MO_NBR AS FISCAL_DAY_OF_MO_NBR,
  FISCAL_DAY_OF_YR_NBR AS FISCAL_DAY_OF_YR_NBR,
  FISCAL_WK AS FISCAL_WK,
  FISCAL_WK_NBR AS FISCAL_WK_NBR,
  FISCAL_MO AS FISCAL_MO,
  FISCAL_MO_NBR AS FISCAL_MO_NBR,
  FISCAL_MO_NAME AS FISCAL_MO_NAME,
  FISCAL_MO_NAME_ABBR AS FISCAL_MO_NAME_ABBR,
  FISCAL_QTR AS FISCAL_QTR,
  FISCAL_QTR_NBR AS FISCAL_QTR_NBR,
  FISCAL_HALF AS FISCAL_HALF,
  FISCAL_YR AS FISCAL_YR,
  LYR_WEEK_DT AS LYR_WEEK_DT,
  LWK_WEEK_DT AS LWK_WEEK_DT,
  WEEK_DT AS WEEK_DT,
  EST_TIME_CONV_AMT AS EST_TIME_CONV_AMT,
  EST_TIME_CONV_HRS AS EST_TIME_CONV_HRS,
  ES0_TIME_CONV_AMT AS ES0_TIME_CONV_AMT,
  ES0_TIME_CONV_HRS AS ES0_TIME_CONV_HRS,
  CST_TIME_CONV_AMT AS CST_TIME_CONV_AMT,
  CST_TIME_CONV_HRS AS CST_TIME_CONV_HRS,
  CS0_TIME_CONV_AMT AS CS0_TIME_CONV_AMT,
  CS0_TIME_CONV_HRS AS CS0_TIME_CONV_HRS,
  MST_TIME_CONV_AMT AS MST_TIME_CONV_AMT,
  MST_TIME_CONV_HRS AS MST_TIME_CONV_HRS,
  MS0_TIME_CONV_AMT AS MS0_TIME_CONV_AMT,
  MS0_TIME_CONV_HRS AS MS0_TIME_CONV_HRS,
  PST_TIME_CONV_AMT AS PST_TIME_CONV_AMT,
  PST_TIME_CONV_HRS AS PST_TIME_CONV_HRS
FROM
  DAYS"""

df_9 = spark.sql(query_9)

df_9.createOrReplaceTempView("Shortcut_To_DAYS_9")

# COMMAND ----------
# DBTITLE 1, SQ_Shortcut_To_DAYS_10


query_10 = f"""SELECT
  DAY_DT AS DAY_DT,
  BUSINESS_DAY_FLAG AS BUSINESS_DAY_FLAG,
  HOLIDAY_FLAG AS HOLIDAY_FLAG,
  DAY_OF_WK_NAME AS DAY_OF_WK_NAME,
  DAY_OF_WK_NAME_ABBR AS DAY_OF_WK_NAME_ABBR,
  DAY_OF_WK_NBR AS DAY_OF_WK_NBR,
  CAL_DAY_OF_MO_NBR AS CAL_DAY_OF_MO_NBR,
  CAL_DAY_OF_YR_NBR AS CAL_DAY_OF_YR_NBR,
  CAL_WK AS CAL_WK,
  CAL_WK_NBR AS CAL_WK_NBR,
  CAL_MO AS CAL_MO,
  CAL_MO_NBR AS CAL_MO_NBR,
  CAL_MO_NAME AS CAL_MO_NAME,
  CAL_MO_NAME_ABBR AS CAL_MO_NAME_ABBR,
  CAL_QTR AS CAL_QTR,
  CAL_QTR_NBR AS CAL_QTR_NBR,
  CAL_HALF AS CAL_HALF,
  CAL_YR AS CAL_YR,
  FISCAL_DAY_OF_MO_NBR AS FISCAL_DAY_OF_MO_NBR,
  FISCAL_DAY_OF_YR_NBR AS FISCAL_DAY_OF_YR_NBR,
  FISCAL_WK AS FISCAL_WK,
  FISCAL_WK_NBR AS FISCAL_WK_NBR,
  FISCAL_MO AS FISCAL_MO,
  FISCAL_MO_NBR AS FISCAL_MO_NBR,
  FISCAL_MO_NAME AS FISCAL_MO_NAME,
  FISCAL_MO_NAME_ABBR AS FISCAL_MO_NAME_ABBR,
  FISCAL_QTR AS FISCAL_QTR,
  FISCAL_QTR_NBR AS FISCAL_QTR_NBR,
  FISCAL_HALF AS FISCAL_HALF,
  FISCAL_YR AS FISCAL_YR,
  LYR_WEEK_DT AS LYR_WEEK_DT,
  LWK_WEEK_DT AS LWK_WEEK_DT,
  WEEK_DT AS WEEK_DT,
  EST_TIME_CONV_AMT AS EST_TIME_CONV_AMT,
  EST_TIME_CONV_HRS AS EST_TIME_CONV_HRS,
  ES0_TIME_CONV_AMT AS ES0_TIME_CONV_AMT,
  ES0_TIME_CONV_HRS AS ES0_TIME_CONV_HRS,
  CST_TIME_CONV_AMT AS CST_TIME_CONV_AMT,
  CST_TIME_CONV_HRS AS CST_TIME_CONV_HRS,
  CS0_TIME_CONV_AMT AS CS0_TIME_CONV_AMT,
  CS0_TIME_CONV_HRS AS CS0_TIME_CONV_HRS,
  MST_TIME_CONV_AMT AS MST_TIME_CONV_AMT,
  MST_TIME_CONV_HRS AS MST_TIME_CONV_HRS,
  MS0_TIME_CONV_AMT AS MS0_TIME_CONV_AMT,
  MS0_TIME_CONV_HRS AS MS0_TIME_CONV_HRS,
  PST_TIME_CONV_AMT AS PST_TIME_CONV_AMT,
  PST_TIME_CONV_HRS AS PST_TIME_CONV_HRS,
  monotonically_increasing_id() AS Monotonically_Increasing_Id
FROM
  Shortcut_To_DAYS_9"""

df_10 = spark.sql(query_10)

df_10.createOrReplaceTempView("SQ_Shortcut_To_DAYS_10")

# COMMAND ----------
# DBTITLE 1, JNR_DAY_11


query_11 = f"""SELECT
  MASTER.FISCAL_YR AS FISCAL_YR,
  MASTER.FISCAL_WK AS FISCAL_WK,
  MASTER.DIGITAL_CHANNEL AS DIGITAL_CHANNEL,
  MASTER.PLAN_SALES_AMT_USD AS PLAN_SALES_AMT_USD,
  MASTER.PLAN_MARGIN_AMT_USD AS PLAN_MARGIN_AMT_USD,
  MASTER.PLAN_ORDER_CNT AS PLAN_ORDER_CNT,
  DETAIL.DAY_DT AS lkp_DAY_DT,
  DETAIL.DAY_OF_WK_NBR AS lkp_DAY_OF_WK_NBR,
  DETAIL.FISCAL_WK AS lkp_FISCAL_WK,
  MASTER.Monotonically_Increasing_Id AS Monotonically_Increasing_Id
FROM
  FIL_Curr_Year_8 MASTER
  INNER JOIN SQ_Shortcut_To_DAYS_10 DETAIL ON MASTER.FISCAL_WK = DETAIL.FISCAL_WK"""

df_11 = spark.sql(query_11)

df_11.createOrReplaceTempView("JNR_DAY_11")

# COMMAND ----------
# DBTITLE 1, EXP_JNR_DAY_12


query_12 = f"""SELECT
  FISCAL_YR AS FISCAL_YR,
  FISCAL_WK AS FISCAL_WK,
  UPPER(DIGITAL_CHANNEL) AS o_DIGITAL_CHANNEL,
  IFF(
    INSTR(UPPER(DIGITAL_CHANNEL), 'BOPIS') > 0,
    'BOPIS',
    IFF(
      INSTR(UPPER(DIGITAL_CHANNEL), 'AUTOSHIP') > 0,
      'AUTOSHIP',
      IFF(
        INSTR(UPPER(DIGITAL_CHANNEL), 'DOORDASH') > 0,
        'DOORDASH',
        UPPER(DIGITAL_CHANNEL)
      )
    )
  ) AS DIGITAL_CHANNEL,
  PLAN_SALES_AMT_USD AS PLAN_SALES_AMT_USD,
  PLAN_MARGIN_AMT_USD AS PLAN_MARGIN_AMT_USD,
  PLAN_ORDER_CNT AS PLAN_ORDER_CNT,
  lkp_DAY_DT AS lkp_DAY_DT,
  lkp_DAY_OF_WK_NBR AS lkp_DAY_OF_WK_NBR,
  Monotonically_Increasing_Id AS Monotonically_Increasing_Id
FROM
  JNR_DAY_11"""

df_12 = spark.sql(query_12)

df_12.createOrReplaceTempView("EXP_JNR_DAY_12")

# COMMAND ----------
# DBTITLE 1, JNR_DOW_13


query_13 = f"""SELECT
  DETAIL.FISCAL_YR AS FISCAL_YR,
  DETAIL.FISCAL_WK AS FISCAL_WK,
  DETAIL.o_DIGITAL_CHANNEL AS in_DIGITAL_CHANNEL,
  DETAIL.DIGITAL_CHANNEL AS DIGITAL_CHANNEL1,
  DETAIL.PLAN_SALES_AMT_USD AS PLAN_SALES_AMT_USD,
  DETAIL.PLAN_MARGIN_AMT_USD AS PLAN_MARGIN_AMT_USD,
  DETAIL.PLAN_ORDER_CNT AS PLAN_ORDER_CNT,
  DETAIL.lkp_DAY_DT AS lkp_DAY_DT,
  DETAIL.lkp_DAY_OF_WK_NBR AS lkp_DAY_OF_WK_NBR,
  MASTER.o_FISCAL_YR AS o_FISCAL_YR,
  MASTER.DIGITAL_CHANNEL AS DIGITAL_CHANNEL,
  MASTER.MON_SALES_PCT AS MON_SALES_PCT,
  MASTER.TUE_SALES_PCT AS TUE_SALES_PCT,
  MASTER.WED_SALES_PCT AS WED_SALES_PCT,
  MASTER.THU_SALES_PCT AS THU_SALES_PCT,
  MASTER.FRI_SALES_PCT AS FRI_SALES_PCT,
  MASTER.SAT_SALES_PCT AS SAT_SALES_PCT,
  MASTER.SUN_SALES_PCT AS SUN_SALES_PCT,
  MASTER.MON_MARGIN_PCT AS MON_MARGIN_PCT,
  MASTER.TUE_MARGIN_PCT AS TUE_MARGIN_PCT,
  MASTER.WED_MARGIN_PCT AS WED_MARGIN_PCT,
  MASTER.THU_MARGIN_PCT AS THU_MARGIN_PCT,
  MASTER.FRI_MARGIN_PCT AS FRI_MARGIN_PCT,
  MASTER.SAT_MARGIN_PCT AS SAT_MARGIN_PCT,
  MASTER.SUN_MARGIN_PCT AS SUN_MARGIN_PCT,
  MASTER.MON_ORDER_PCT AS MON_ORDER_PCT,
  MASTER.TUE_ORDER_PCT AS TUE_ORDER_PCT,
  MASTER.WED_ORDER_PCT AS WED_ORDER_PCT,
  MASTER.THU_ORDER_PCT AS THU_ORDER_PCT,
  MASTER.FRI_ORDER_PCT AS FRI_ORDER_PCT,
  MASTER.SAT_ORDER_PCT AS SAT_ORDER_PCT,
  MASTER.SUN_ORDER_PCT AS SUN_ORDER_PCT,
  MASTER.UPDATE_TSTMP AS UPDATE_TSTMP1,
  MASTER.LOAD_TSTMP AS LOAD_TSTMP1,
  MASTER.Monotonically_Increasing_Id AS Monotonically_Increasing_Id
FROM
  EXP_DOW_3 MASTER
  INNER JOIN EXP_JNR_DAY_12 DETAIL ON MASTER.o_FISCAL_YR = DETAIL.FISCAL_YR
  AND MASTER.DIGITAL_CHANNEL = DETAIL.DIGITAL_CHANNEL"""

df_13 = spark.sql(query_13)

df_13.createOrReplaceTempView("JNR_DOW_13")

# COMMAND ----------
# DBTITLE 1, AGG_DOW_Plan_14


query_14 = f"""SELECT
  FISCAL_YR AS FISCAL_YR,
  FISCAL_WK AS FISCAL_WK,
  in_DIGITAL_CHANNEL AS DIGITAL_CHANNEL,
  MAX(
    DECODE (
      lkp_DAY_OF_WK_NBR,
      1,
      MON_SALES_PCT * PLAN_SALES_AMT_USD,
      2,
      TUE_SALES_PCT * PLAN_SALES_AMT_USD,
      3,
      WED_SALES_PCT * PLAN_SALES_AMT_USD,
      4,
      THU_SALES_PCT * PLAN_SALES_AMT_USD,
      5,
      FRI_SALES_PCT * PLAN_SALES_AMT_USD,
      6,
      SAT_SALES_PCT * PLAN_SALES_AMT_USD,
      7,
      SUN_SALES_PCT * PLAN_SALES_AMT_USD
    )
  ) AS o_PLAN_SALES_AMT_USD,
  MAX(
    DECODE (
      lkp_DAY_OF_WK_NBR,
      1,
      MON_MARGIN_PCT * PLAN_MARGIN_AMT_USD,
      2,
      TUE_MARGIN_PCT * PLAN_MARGIN_AMT_USD,
      3,
      WED_MARGIN_PCT * PLAN_MARGIN_AMT_USD,
      4,
      THU_MARGIN_PCT * PLAN_MARGIN_AMT_USD,
      5,
      FRI_MARGIN_PCT * PLAN_MARGIN_AMT_USD,
      6,
      SAT_MARGIN_PCT * PLAN_MARGIN_AMT_USD,
      7,
      SUN_MARGIN_PCT * PLAN_MARGIN_AMT_USD
    )
  ) AS o_PLAN_MARGIN_AMT_USD,
  MAX(
    DECODE (
      lkp_DAY_OF_WK_NBR,
      1,
      MON_ORDER_PCT * PLAN_ORDER_CNT,
      2,
      TUE_ORDER_PCT * PLAN_ORDER_CNT,
      3,
      WED_ORDER_PCT * PLAN_ORDER_CNT,
      4,
      THU_ORDER_PCT * PLAN_ORDER_CNT,
      5,
      FRI_ORDER_PCT * PLAN_ORDER_CNT,
      6,
      SAT_ORDER_PCT * PLAN_ORDER_CNT,
      7,
      SUN_ORDER_PCT * PLAN_ORDER_CNT
    )
  ) AS o_PLAN_ORDER_CNT,
  lkp_DAY_DT AS lkp_DAY_DT,
  last(Monotonically_Increasing_Id) AS Monotonically_Increasing_Id
FROM
  JNR_DOW_13
GROUP BY
  FISCAL_YR,
  FISCAL_WK,
  in_DIGITAL_CHANNEL,
  lkp_DAY_DT"""

df_14 = spark.sql(query_14)

df_14.createOrReplaceTempView("AGG_DOW_Plan_14")

# COMMAND ----------
# DBTITLE 1, JNR_Target_Lookup_15


query_15 = f"""SELECT
  DETAIL.lkp_DAY_DT AS DAY_DT,
  DETAIL.DIGITAL_CHANNEL AS DIGITAL_CHANNEL,
  DETAIL.FISCAL_YR AS FISCAL_YR,
  DETAIL.FISCAL_WK AS FISCAL_WK,
  DETAIL.o_PLAN_SALES_AMT_USD AS o_PLAN_SALES_AMT_USD,
  DETAIL.o_PLAN_MARGIN_AMT_USD AS o_PLAN_MARGIN_AMT_USD,
  DETAIL.o_PLAN_ORDER_CNT AS o_PLAN_ORDER_CNT,
  MASTER.DAY_DT AS lkp_DAY_DT,
  MASTER.DIGITAL_CHANNEL AS lkp_DIGITAL_CHANNEL,
  MASTER.FISCAL_YR AS lkp_FISCAL_YR,
  MASTER.FISCAL_WK AS lkp_FISCAL_WK,
  MASTER.PLAN_SALES_AMT_USD AS lkp_PLAN_SALES_AMT_USD,
  MASTER.PLAN_MARGIN_AMT_USD AS lkp_PLAN_MARGIN_AMT_USD,
  MASTER.PLAN_ORDER_CNT AS lkp_PLAN_ORDER_CNT,
  MASTER.UPDATE_TSTMP AS lkp_UPDATE_TSTMP,
  MASTER.LOAD_TSTMP AS lkp_LOAD_TSTMP,
  DETAIL.Monotonically_Increasing_Id AS Monotonically_Increasing_Id
FROM
  SQ_Shortcut_to_DIGITAL_PLAN_DAY_5 MASTER
  RIGHT JOIN AGG_DOW_Plan_14 DETAIL ON MASTER.DAY_DT = DETAIL.lkp_DAY_DT
  AND MASTER.DIGITAL_CHANNEL = DETAIL.DIGITAL_CHANNEL"""

df_15 = spark.sql(query_15)

df_15.createOrReplaceTempView("JNR_Target_Lookup_15")

# COMMAND ----------
# DBTITLE 1, EXP_Before_Filter_16


query_16 = f"""SELECT
  DAY_DT AS DAY_DT,
  DIGITAL_CHANNEL AS DIGITAL_CHANNEL,
  FISCAL_YR AS FISCAL_YR,
  FISCAL_WK AS FISCAL_WK,
  o_PLAN_SALES_AMT_USD AS o_PLAN_SALES_AMT_USD,
  o_PLAN_MARGIN_AMT_USD AS o_PLAN_MARGIN_AMT_USD,
  o_PLAN_ORDER_CNT AS o_PLAN_ORDER_CNT,
  lkp_DAY_DT AS lkp_DAY_DT,
  lkp_DIGITAL_CHANNEL AS lkp_DIGITAL_CHANNEL,
  lkp_FISCAL_YR AS lkp_FISCAL_YR,
  lkp_FISCAL_WK AS lkp_FISCAL_WK,
  lkp_PLAN_SALES_AMT_USD AS lkp_PLAN_SALES_AMT_USD,
  lkp_PLAN_MARGIN_AMT_USD AS lkp_PLAN_MARGIN_AMT_USD,
  lkp_PLAN_ORDER_CNT AS lkp_PLAN_ORDER_CNT,
  lkp_UPDATE_TSTMP AS lkp_UPDATE_TSTMP,
  lkp_LOAD_TSTMP AS lkp_LOAD_TSTMP,
  IFF(
    (ISNULL(lkp_DIGITAL_CHANNEL)),
    1,
    (
      IFF (
        NOT (ISNULL(lkp_DIGITAL_CHANNEL))
        AND (
          IFF (
            ISNULL(o_PLAN_SALES_AMT_USD),
            99999999999.99,
            o_PLAN_SALES_AMT_USD
          ) <> IFF (
            ISNULL(lkp_PLAN_SALES_AMT_USD),
            99999999999.99,
            lkp_PLAN_SALES_AMT_USD
          )
          OR IFF (
            ISNULL(o_PLAN_MARGIN_AMT_USD),
            99999999999.99,
            o_PLAN_MARGIN_AMT_USD
          ) <> IFF (
            ISNULL(lkp_PLAN_MARGIN_AMT_USD),
            99999999999.99,
            lkp_PLAN_MARGIN_AMT_USD
          )
          OR IFF (
            ISNULL(o_PLAN_ORDER_CNT),
            99999999999.99,
            o_PLAN_ORDER_CNT
          ) <> IFF (
            ISNULL(lkp_PLAN_ORDER_CNT),
            99999999999.99,
            lkp_PLAN_ORDER_CNT
          )
        ),
        2
      )
    )
  ) AS o_Flag,
  Monotonically_Increasing_Id AS Monotonically_Increasing_Id
FROM
  JNR_Target_Lookup_15"""

df_16 = spark.sql(query_16)

df_16.createOrReplaceTempView("EXP_Before_Filter_16")

# COMMAND ----------
# DBTITLE 1, FIL_Logic_17


query_17 = f"""SELECT
  DAY_DT AS DAY_DT,
  DIGITAL_CHANNEL AS DIGITAL_CHANNEL,
  FISCAL_YR AS FISCAL_YR,
  FISCAL_WK AS FISCAL_WK,
  o_PLAN_SALES_AMT_USD AS o_PLAN_SALES_AMT_USD,
  o_PLAN_MARGIN_AMT_USD AS o_PLAN_MARGIN_AMT_USD,
  o_PLAN_ORDER_CNT AS o_PLAN_ORDER_CNT,
  lkp_DAY_DT AS lkp_DAY_DT,
  lkp_DIGITAL_CHANNEL AS lkp_DIGITAL_CHANNEL,
  lkp_FISCAL_YR AS lkp_FISCAL_YR,
  lkp_LOAD_TSTMP AS lkp_LOAD_TSTMP,
  o_Flag AS o_Flag,
  Monotonically_Increasing_Id AS Monotonically_Increasing_Id
FROM
  EXP_Before_Filter_16
WHERE
  o_Flag = 1
  OR o_Flag = 2"""

df_17 = spark.sql(query_17)

df_17.createOrReplaceTempView("FIL_Logic_17")

# COMMAND ----------
# DBTITLE 1, EXP_VALID_FLAG_18


query_18 = f"""SELECT
  DAY_DT AS DAY_DT,
  DIGITAL_CHANNEL AS DIGITAL_CHANNEL,
  FISCAL_YR AS FISCAL_YR,
  FISCAL_WK AS FISCAL_WK,
  o_PLAN_SALES_AMT_USD AS o_PLAN_SALES_AMT_USD,
  o_PLAN_MARGIN_AMT_USD AS o_PLAN_MARGIN_AMT_USD,
  o_PLAN_ORDER_CNT AS o_PLAN_ORDER_CNT,
  lkp_DAY_DT AS lkp_DAY_DT,
  lkp_DIGITAL_CHANNEL AS lkp_DIGITAL_CHANNEL,
  lkp_FISCAL_YR AS lkp_FISCAL_YR,
  lkp_LOAD_TSTMP AS lkp_LOAD_TSTMP,
  now() AS UPDATE_TSTMP,
  IFF(ISNULL(lkp_LOAD_TSTMP), now(), lkp_LOAD_TSTMP) AS o_LOAD_TSTMP,
  o_Flag AS o_FLAG,
  Monotonically_Increasing_Id AS Monotonically_Increasing_Id
FROM
  FIL_Logic_17"""

df_18 = spark.sql(query_18)

df_18.createOrReplaceTempView("EXP_VALID_FLAG_18")

# COMMAND ----------
# DBTITLE 1, UPD_INS_UPD_19


query_19 = f"""SELECT
  DAY_DT AS DAY_DT,
  DIGITAL_CHANNEL AS DIGITAL_CHANNEL,
  FISCAL_YR AS FISCAL_YR,
  FISCAL_WK AS FISCAL_WK,
  o_PLAN_SALES_AMT_USD AS o_PLAN_SALES_AMT_USD,
  o_PLAN_MARGIN_AMT_USD AS o_PLAN_MARGIN_AMT_USD,
  o_PLAN_ORDER_CNT AS o_PLAN_ORDER_CNT,
  UPDATE_TSTMP AS UPDATE_TSTMP,
  o_LOAD_TSTMP AS o_LOAD_TSTMP,
  o_FLAG AS o_FLAG,
  Monotonically_Increasing_Id AS Monotonically_Increasing_Id,
  DECODE(o_FLAG, 1, 'DD_INSERT', 2, 'DD_UPDATE') AS UPDATE_STRATEGY_FLAG
FROM
  EXP_VALID_FLAG_18"""

df_19 = spark.sql(query_19)

df_19.createOrReplaceTempView("UPD_INS_UPD_19")

# COMMAND ----------
# DBTITLE 1, DIGITAL_PLAN_DAY


spark.sql("""MERGE INTO DIGITAL_PLAN_DAY AS TARGET
USING
  UPD_INS_UPD_19 AS SOURCE ON TARGET.DIGITAL_CHANNEL = SOURCE.DIGITAL_CHANNEL
  AND TARGET.DAY_DT = SOURCE.DAY_DT
  WHEN MATCHED
  AND SOURCE.UPDATE_STRATEGY_FLAG = "DD_UPDATE" THEN
UPDATE
SET
  TARGET.DAY_DT = SOURCE.DAY_DT,
  TARGET.DIGITAL_CHANNEL = SOURCE.DIGITAL_CHANNEL,
  TARGET.FISCAL_YR = SOURCE.FISCAL_YR,
  TARGET.FISCAL_WK = SOURCE.FISCAL_WK,
  TARGET.PLAN_SALES_AMT_USD = SOURCE.o_PLAN_SALES_AMT_USD,
  TARGET.PLAN_MARGIN_AMT_USD = SOURCE.o_PLAN_MARGIN_AMT_USD,
  TARGET.PLAN_ORDER_CNT = SOURCE.o_PLAN_ORDER_CNT,
  TARGET.UPDATE_TSTMP = SOURCE.UPDATE_TSTMP,
  TARGET.LOAD_TSTMP = SOURCE.o_LOAD_TSTMP
  WHEN MATCHED
  AND SOURCE.UPDATE_STRATEGY_FLAG = "DD_DELETE"
  AND TARGET.FISCAL_YR = SOURCE.FISCAL_YR
  AND TARGET.FISCAL_WK = SOURCE.FISCAL_WK
  AND TARGET.PLAN_SALES_AMT_USD = SOURCE.o_PLAN_SALES_AMT_USD
  AND TARGET.PLAN_MARGIN_AMT_USD = SOURCE.o_PLAN_MARGIN_AMT_USD
  AND TARGET.PLAN_ORDER_CNT = SOURCE.o_PLAN_ORDER_CNT
  AND TARGET.UPDATE_TSTMP = SOURCE.UPDATE_TSTMP
  AND TARGET.LOAD_TSTMP = SOURCE.o_LOAD_TSTMP THEN DELETE
  WHEN NOT MATCHED
  AND SOURCE.UPDATE_STRATEGY_FLAG = "DD_INSERT" THEN
INSERT
  (
    TARGET.DAY_DT,
    TARGET.DIGITAL_CHANNEL,
    TARGET.FISCAL_YR,
    TARGET.FISCAL_WK,
    TARGET.PLAN_SALES_AMT_USD,
    TARGET.PLAN_MARGIN_AMT_USD,
    TARGET.PLAN_ORDER_CNT,
    TARGET.UPDATE_TSTMP,
    TARGET.LOAD_TSTMP
  )
VALUES
  (
    SOURCE.DAY_DT,
    SOURCE.DIGITAL_CHANNEL,
    SOURCE.FISCAL_YR,
    SOURCE.FISCAL_WK,
    SOURCE.o_PLAN_SALES_AMT_USD,
    SOURCE.o_PLAN_MARGIN_AMT_USD,
    SOURCE.o_PLAN_ORDER_CNT,
    SOURCE.UPDATE_TSTMP,
    SOURCE.o_LOAD_TSTMP
  )""")

# COMMAND ----------
#Post session variable updation
updateVariable(postVariableAssignment, variablesTableName, mainWorkflowId, parentName, "m_Digital_Plan_Day")

# COMMAND ----------
#Update Mapping Variables in database.
persistVariables(variablesTableName, "m_Digital_Plan_Day", mainWorkflowId, parentName)
