# Databricks notebook source
# MAGIC %run "./udf_informatica"

# COMMAND ----------


from pyspark.sql.types import *

spark.sql("use DELTA_TRAINING")
spark.sql("set spark.sql.legacy.timeParserPolicy = LEGACY")

# COMMAND ----------
%run ../WorkflowUtility

# COMMAND ----------
mainWorkflowId = dbutils.widgets.get("mainWorkflowId")
mainWorkflowRunId = dbutils.widgets.get("mainWorkflowRunId")
parentName = dbutils.widgets.get("parentName")
preVariableAssignment = dbutils.widgets.get("preVariableAssignment")
postVariableAssignment = dbutils.widgets.get("postVariableAssignment")
truncTargetTableOptions = dbutils.widgets.get("truncTargetTableOptions")
variablesTableName = dbutils.widgets.get("variablesTableName")

# COMMAND ----------
#Truncate Target Tables
truncateTargetTables(truncTargetTableOptions)

# COMMAND ----------
#Pre presession variable updation
updateVariable(preVariableAssignment, variablesTableName, mainWorkflowId, parentName, "m_OMS_Dist_Order_LN_SLA_TIME_ZONE_UPD")

# COMMAND ----------
fetchAndCreateVariables(parentName,"m_OMS_Dist_Order_LN_SLA_TIME_ZONE_UPD", variablesTableName, mainWorkflowId)

# COMMAND ----------
# DBTITLE 1, Shortcut_to_OMS_DIST_ORDER_LN_SLA_0


query_0 = f"""SELECT
  OMS_DIST_ORDER_ID AS OMS_DIST_ORDER_ID,
  OMS_DIST_ORDER_LN_ID AS OMS_DIST_ORDER_LN_ID,
  OMS_ORDER_ID AS OMS_ORDER_ID,
  OMS_ORDER_LN_ID AS OMS_ORDER_LN_ID,
  OMS_DO_CREATED_ORIG_TSTMP AS OMS_DO_CREATED_ORIG_TSTMP,
  EV_RELEASED_ORIG_TSTMP AS EV_RELEASED_ORIG_TSTMP,
  EV_SHIPPED_ORIG_TSTMP AS EV_SHIPPED_ORIG_TSTMP,
  OMS_DO_SLA_TSTMP AS OMS_DO_SLA_TSTMP,
  OMS_DO_SLA_FLAG AS OMS_DO_SLA_FLAG,
  OMS_DO_AGE_1_TSTMP AS OMS_DO_AGE_1_TSTMP,
  OMS_DO_AGE_2_TSTMP AS OMS_DO_AGE_2_TSTMP,
  OMS_DO_AGE_3_TSTMP AS OMS_DO_AGE_3_TSTMP,
  OMS_DO_AGE_4_TSTMP AS OMS_DO_AGE_4_TSTMP,
  OMS_DO_AGE_5_TSTMP AS OMS_DO_AGE_5_TSTMP,
  TIME_ZONE AS TIME_ZONE,
  UPDATE_TSTMP AS UPDATE_TSTMP,
  LOAD_TSTMP AS LOAD_TSTMP
FROM
  OMS_DIST_ORDER_LN_SLA"""

df_0 = spark.sql(query_0)

df_0.createOrReplaceTempView("Shortcut_to_OMS_DIST_ORDER_LN_SLA_0")

# COMMAND ----------
# DBTITLE 1, SQ_Shortcut_to_OMS_DIST_ORDER_LN_SLA_1


query_1 = f"""SELECT
  OMS_DIST_ORDER_ID AS OMS_DIST_ORDER_ID,
  OMS_DIST_ORDER_LN_ID AS OMS_DIST_ORDER_LN_ID,
  TIME_ZONE AS TIME_ZONE,
  monotonically_increasing_id() AS Monotonically_Increasing_Id
FROM
  Shortcut_to_OMS_DIST_ORDER_LN_SLA_0"""

df_1 = spark.sql(query_1)

df_1.createOrReplaceTempView("SQ_Shortcut_to_OMS_DIST_ORDER_LN_SLA_1")

# COMMAND ----------
# DBTITLE 1, Shortcut_to_OMS_DIST_ORDER_LN_2


query_2 = f"""SELECT
  OMS_DIST_ORDER_ID AS OMS_DIST_ORDER_ID,
  OMS_DIST_ORDER_LN_ID AS OMS_DIST_ORDER_LN_ID,
  TOTAL_MONETARY_VALUE_AMT AS TOTAL_MONETARY_VALUE_AMT,
  UNIT_MONETARY_VALUE_AMT AS UNIT_MONETARY_VALUE_AMT,
  UNIT_TAX_AMT AS UNIT_TAX_AMT,
  MV_CURRENCY_CD AS MV_CURRENCY_CD,
  SHIPPED_QTY AS SHIPPED_QTY,
  RECEIVED_QTY AS RECEIVED_QTY,
  CREATED_SOURCE AS CREATED_SOURCE,
  CREATED_TSTMP AS CREATED_TSTMP,
  LAST_UPDATED_TSTMP AS LAST_UPDATED_TSTMP,
  OMS_DIST_ORDER_LN_STATUS_ID AS OMS_DIST_ORDER_LN_STATUS_ID,
  ALLOCATED_QTY AS ALLOCATED_QTY,
  UNIT_COST_AMT AS UNIT_COST_AMT,
  UNIT_PRICE_AMT AS UNIT_PRICE_AMT,
  USER_CANCELED_QTY AS USER_CANCELED_QTY,
  DELIVERY_END_DT AS DELIVERY_END_DT,
  DELIVERY_START_DT AS DELIVERY_START_DT,
  EVENT_CD AS EVENT_CD,
  REASON_CODE AS REASON_CODE,
  PARTL_FILL_FLG AS PARTL_FILL_FLG,
  ORDER_QTY AS ORDER_QTY,
  ORIG_ORDER_QTY AS ORIG_ORDER_QTY,
  RETAIL_PRICE AS RETAIL_PRICE,
  OMS_DIST_ORDER_LN_NBR AS OMS_DIST_ORDER_LN_NBR,
  PICKUP_END_DTTM AS PICKUP_END_DTTM,
  OMS_ORDER_LN_NBR AS OMS_ORDER_LN_NBR,
  PICKUP_START_DTTM AS PICKUP_START_DTTM,
  CANCELLED_FLG AS CANCELLED_FLG,
  PRODUCT_ID AS PRODUCT_ID,
  OMS_ORDER_NBR AS OMS_ORDER_NBR,
  FREIGHT_REVENUE_CURRENCY_CD AS FREIGHT_REVENUE_CURRENCY_CD,
  FREIGHT_REVENUE AS FREIGHT_REVENUE,
  ADJUSTED_ORDER_QTY AS ADJUSTED_ORDER_QTY,
  EV_RELEASED_TSTMP AS EV_RELEASED_TSTMP,
  EV_ALLOCATED_TSTMP AS EV_ALLOCATED_TSTMP,
  EV_SHIPPED_TSTMP AS EV_SHIPPED_TSTMP,
  EV_PICKEDUP_TSTMP AS EV_PICKEDUP_TSTMP,
  OMS_ORDER_ID AS OMS_ORDER_ID,
  OMS_ORDER_LN_ID AS OMS_ORDER_LN_ID,
  OMS_DO_CREATED_TSTMP AS OMS_DO_CREATED_TSTMP,
  ORDER_NBR AS ORDER_NBR,
  OMS_ORDER_CREATED_TSTMP AS OMS_ORDER_CREATED_TSTMP,
  ORIG_LOCATION_ID AS ORIG_LOCATION_ID,
  ORDER_CREATION_CHANNEL AS ORDER_CREATION_CHANNEL,
  ORDER_FULFILLMENT_CHANNEL AS ORDER_FULFILLMENT_CHANNEL,
  ORDER_CHANNEL AS ORDER_CHANNEL,
  SCHED_DELIVERY_FLG AS SCHED_DELIVERY_FLG,
  SUBSCRIPTION_ORDER_FLG AS SUBSCRIPTION_ORDER_FLG,
  ADD_ON_FLAG AS ADD_ON_FLAG,
  ISPU_PXY_FIRST_NAME AS ISPU_PXY_FIRST_NAME,
  ISPU_PXY_LAST_NAME AS ISPU_PXY_LAST_NAME,
  ISPU_PXY_ADD_LINE1 AS ISPU_PXY_ADD_LINE1,
  ISPU_PXY_ADD_LINE2 AS ISPU_PXY_ADD_LINE2,
  ISPU_PXY_ADD_LINE3 AS ISPU_PXY_ADD_LINE3,
  ISPU_PXY_CITY AS ISPU_PXY_CITY,
  ISPU_PXY_STATE AS ISPU_PXY_STATE,
  ISPU_PXY_POSTAL_CD AS ISPU_PXY_POSTAL_CD,
  ISPU_PXY_COUNTRY AS ISPU_PXY_COUNTRY,
  ISPU_PXY_EMAIL AS ISPU_PXY_EMAIL,
  ISUP_PXY_PHONE AS ISUP_PXY_PHONE,
  OMS_COMPANY_ID AS OMS_COMPANY_ID,
  EXCHANGE_RATE_PCNT AS EXCHANGE_RATE_PCNT,
  RX_ORDER_FLG AS RX_ORDER_FLG,
  CANCEL_TSTMP AS CANCEL_TSTMP,
  UPDATE_TSTMP AS UPDATE_TSTMP,
  LOAD_TSTMP AS LOAD_TSTMP
FROM
  OMS_DIST_ORDER_LN"""

df_2 = spark.sql(query_2)

df_2.createOrReplaceTempView("Shortcut_to_OMS_DIST_ORDER_LN_2")

# COMMAND ----------
# DBTITLE 1, SQ_Shortcut_to_OMS_DIST_ORDER_LN_3


query_3 = f"""SELECT
  OMS_DIST_ORDER_ID AS OMS_DIST_ORDER_ID,
  OMS_DIST_ORDER_LN_ID AS OMS_DIST_ORDER_LN_ID,
  ORIG_LOCATION_ID AS ORIG_LOCATION_ID,
  monotonically_increasing_id() AS Monotonically_Increasing_Id
FROM
  Shortcut_to_OMS_DIST_ORDER_LN_2"""

df_3 = spark.sql(query_3)

df_3.createOrReplaceTempView("SQ_Shortcut_to_OMS_DIST_ORDER_LN_3")

# COMMAND ----------
# DBTITLE 1, exp_Orig_Loc_To_Integer_4


query_4 = f"""SELECT
  TO_INTEGER(ORIG_LOCATION_ID) AS ORIG_LOCATION_ID1,
  OMS_DIST_ORDER_ID AS OMS_DIST_ORDER_ID,
  OMS_DIST_ORDER_LN_ID AS OMS_DIST_ORDER_LN_ID,
  Monotonically_Increasing_Id AS Monotonically_Increasing_Id
FROM
  SQ_Shortcut_to_OMS_DIST_ORDER_LN_3"""

df_4 = spark.sql(query_4)

df_4.createOrReplaceTempView("exp_Orig_Loc_To_Integer_4")

# COMMAND ----------
# DBTITLE 1, jnr_Oms_Dist_Order_LN_5


query_5 = f"""SELECT
  DETAIL.OMS_DIST_ORDER_ID AS OMS_DIST_ORDER_ID,
  DETAIL.OMS_DIST_ORDER_LN_ID AS OMS_DIST_ORDER_LN_ID,
  DETAIL.TIME_ZONE AS TIME_ZONE,
  MASTER.ORIG_LOCATION_ID1 AS ORIG_LOCATION_ID1,
  MASTER.Monotonically_Increasing_Id AS Monotonically_Increasing_Id
FROM
  exp_Orig_Loc_To_Integer_4 MASTER
  INNER JOIN SQ_Shortcut_to_OMS_DIST_ORDER_LN_SLA_1 DETAIL ON MASTER.OMS_DIST_ORDER_ID = DETAIL.OMS_DIST_ORDER_ID
  AND MASTER.OMS_DIST_ORDER_LN_ID = DETAIL.OMS_DIST_ORDER_LN_ID"""

df_5 = spark.sql(query_5)

df_5.createOrReplaceTempView("jnr_Oms_Dist_Order_LN_5")

# COMMAND ----------
# DBTITLE 1, Shortcut_to_SITE_PROFILE_RPT_6


query_6 = f"""SELECT
  LOCATION_ID AS LOCATION_ID,
  LOCATION_TYPE_ID AS LOCATION_TYPE_ID,
  LOCATION_TYPE_DESC AS LOCATION_TYPE_DESC,
  STORE_NBR AS STORE_NBR,
  STORE_NAME AS STORE_NAME,
  STORE_TYPE_ID AS STORE_TYPE_ID,
  STORE_TYPE_DESC AS STORE_TYPE_DESC,
  PARENT_LOCATION_ID AS PARENT_LOCATION_ID,
  LOCATION_NBR AS LOCATION_NBR,
  COMPANY_ID AS COMPANY_ID,
  COMPANY_DESC AS COMPANY_DESC,
  SUPER_REGION_ID AS SUPER_REGION_ID,
  SUPER_REGION_DESC AS SUPER_REGION_DESC,
  REGION_ID AS REGION_ID,
  REGION_DESC AS REGION_DESC,
  DISTRICT_ID AS DISTRICT_ID,
  DISTRICT_DESC AS DISTRICT_DESC,
  SITE_ADDRESS AS SITE_ADDRESS,
  SITE_CITY AS SITE_CITY,
  SITE_COUNTY AS SITE_COUNTY,
  STATE_CD AS STATE_CD,
  STATE_NAME AS STATE_NAME,
  POSTAL_CD AS POSTAL_CD,
  COUNTRY_CD AS COUNTRY_CD,
  COUNTRY_NAME AS COUNTRY_NAME,
  GEO_LATITUDE_NBR AS GEO_LATITUDE_NBR,
  GEO_LONGITUDE_NBR AS GEO_LONGITUDE_NBR,
  PETSMART_DMA_CD AS PETSMART_DMA_CD,
  PETSMART_DMA_DESC AS PETSMART_DMA_DESC,
  SITE_MAIN_TELE_NO AS SITE_MAIN_TELE_NO,
  SITE_GROOM_TELE_NO AS SITE_GROOM_TELE_NO,
  SITE_FAX_NO AS SITE_FAX_NO,
  SITE_EMAIL_ADDRESS AS SITE_EMAIL_ADDRESS,
  STORE_OPEN_CLOSE_FLAG AS STORE_OPEN_CLOSE_FLAG,
  SFT_OPEN_DT AS SFT_OPEN_DT,
  OPEN_DT AS OPEN_DT,
  GR_OPEN_DT AS GR_OPEN_DT,
  CLOSE_DT AS CLOSE_DT,
  SITE_SALES_FLAG AS SITE_SALES_FLAG,
  SALES_CURR_FLAG AS SALES_CURR_FLAG,
  SITE_OPEN_YRS_AMT AS SITE_OPEN_YRS_AMT,
  FIRST_SALE_DT AS FIRST_SALE_DT,
  FIRST_MEASURED_SALE_DT AS FIRST_MEASURED_SALE_DT,
  LAST_SALE_DT AS LAST_SALE_DT,
  COMP_CURR_FLAG AS COMP_CURR_FLAG,
  COMP_EFF_DT AS COMP_EFF_DT,
  COMP_END_DT AS COMP_END_DT,
  TP_LOC_FLAG AS TP_LOC_FLAG,
  TP_ACTIVE_CNT AS TP_ACTIVE_CNT,
  TP_START_DT AS TP_START_DT,
  HOTEL_FLAG AS HOTEL_FLAG,
  HOTEL_OPEN_DT AS HOTEL_OPEN_DT,
  DAYCAMP_FLAG AS DAYCAMP_FLAG,
  VET_FLAG AS VET_FLAG,
  TIME_ZONE_ID AS TIME_ZONE_ID,
  TIME_ZONE AS TIME_ZONE,
  SQ_FEET_RETAIL AS SQ_FEET_RETAIL,
  SQ_FEET_TOTAL AS SQ_FEET_TOTAL,
  TRADE_AREA AS TRADE_AREA,
  DELV_SERVICE_CLASS_ID AS DELV_SERVICE_CLASS_ID,
  PICK_SERVICE_CLASS_ID AS PICK_SERVICE_CLASS_ID,
  REPL_DC_NBR AS REPL_DC_NBR,
  REPL_FISH_DC_NBR AS REPL_FISH_DC_NBR,
  REPL_FWD_DC_NBR AS REPL_FWD_DC_NBR,
  PROMO_LABEL_CD AS PROMO_LABEL_CD,
  PRICE_ZONE_ID AS PRICE_ZONE_ID,
  PRICE_ZONE_DESC AS PRICE_ZONE_DESC,
  PRICE_AD_ZONE_ID AS PRICE_AD_ZONE_ID,
  PRICE_AD_ZONE_DESC AS PRICE_AD_ZONE_DESC,
  EQUINE_MERCH_ID AS EQUINE_MERCH_ID,
  EQUINE_MERCH_DESC AS EQUINE_MERCH_DESC,
  EQUINE_SITE_ID AS EQUINE_SITE_ID,
  EQUINE_SITE_DESC AS EQUINE_SITE_DESC,
  EQUINE_SITE_OPEN_DT AS EQUINE_SITE_OPEN_DT,
  LOYALTY_PGM_TYPE_ID AS LOYALTY_PGM_TYPE_ID,
  LOYALTY_PGM_TYPE_DESC AS LOYALTY_PGM_TYPE_DESC,
  LOYALTY_PGM_STATUS_ID AS LOYALTY_PGM_STATUS_ID,
  LOYALTY_PGM_STATUS_DESC AS LOYALTY_PGM_STATUS_DESC,
  LOYALTY_PGM_START_DT AS LOYALTY_PGM_START_DT,
  LOYALTY_PGM_CHANGE_DT AS LOYALTY_PGM_CHANGE_DT,
  BP_COMPANY_NBR AS BP_COMPANY_NBR,
  BP_GL_ACCT AS BP_GL_ACCT,
  SITE_LOGIN_ID AS SITE_LOGIN_ID,
  SITE_MANAGER_ID AS SITE_MANAGER_ID,
  SITE_MANAGER_NAME AS SITE_MANAGER_NAME,
  MGR_ID AS MGR_ID,
  MGR_DESC AS MGR_DESC,
  DVL_ID AS DVL_ID,
  DVL_DESC AS DVL_DESC,
  PURCH_GROUP_ID AS PURCH_GROUP_ID,
  PURCH_GROUP_NAME AS PURCH_GROUP_NAME,
  DIST_MGR_NAME AS DIST_MGR_NAME,
  DM_EMAIL_ADDRESS AS DM_EMAIL_ADDRESS,
  DC_AREA_DIRECTOR_NAME AS DC_AREA_DIRECTOR_NAME,
  DC_AREA_DIRECTOR_EMAIL AS DC_AREA_DIRECTOR_EMAIL,
  DIST_SVC_MGR_NAME AS DIST_SVC_MGR_NAME,
  DSM_EMAIL_ADDRESS AS DSM_EMAIL_ADDRESS,
  REGION_VP_NAME AS REGION_VP_NAME,
  RVP_EMAIL_ADDRESS AS RVP_EMAIL_ADDRESS,
  REGION_TRAINER_NAME AS REGION_TRAINER_NAME,
  ASSET_PROTECT_NAME AS ASSET_PROTECT_NAME,
  ASSET_PROTECT_EMAIL AS ASSET_PROTECT_EMAIL,
  LP_SAFETY_DIRECTOR_NAME AS LP_SAFETY_DIRECTOR_NAME,
  LP_SAFETY_DIRECTOR_EMAIL AS LP_SAFETY_DIRECTOR_EMAIL,
  SR_LP_SAFETY_MGR_NAME AS SR_LP_SAFETY_MGR_NAME,
  SR_LP_SAFETY_MGR_EMAIL AS SR_LP_SAFETY_MGR_EMAIL,
  REGIONAL_LP_SAFETY_MGR_NAME AS REGIONAL_LP_SAFETY_MGR_NAME,
  REGIONAL_LP_SAFETY_MGR_EMAIL AS REGIONAL_LP_SAFETY_MGR_EMAIL,
  RETAIL_MANAGER_SAFETY_NAME AS RETAIL_MANAGER_SAFETY_NAME,
  RETAIL_MANAGER_SAFETY_EMAIL AS RETAIL_MANAGER_SAFETY_EMAIL,
  DC_GENERAL_MANAGER_NAME AS DC_GENERAL_MANAGER_NAME,
  DC_GENERAL_MANAGER_EMAIL AS DC_GENERAL_MANAGER_EMAIL,
  ASST_DC_GENERAL_MANAGER_NAME1 AS ASST_DC_GENERAL_MANAGER_NAME1,
  ASST_DC_GENERAL_MANAGER_EMAIL1 AS ASST_DC_GENERAL_MANAGER_EMAIL1,
  ASST_DC_GENERAL_MANAGER_NAME2 AS ASST_DC_GENERAL_MANAGER_NAME2,
  ASST_DC_GENERAL_MANAGER_EMAIL2 AS ASST_DC_GENERAL_MANAGER_EMAIL2,
  HR_MANAGER_NAME AS HR_MANAGER_NAME,
  HR_MANAGER_EMAIL AS HR_MANAGER_EMAIL,
  HR_SUPERVISOR_NAME1 AS HR_SUPERVISOR_NAME1,
  HR_SUPERVISOR_EMAIL1 AS HR_SUPERVISOR_EMAIL1,
  HR_SUPERVISOR_NAME2 AS HR_SUPERVISOR_NAME2,
  HR_SUPERVISOR_EMAIL2 AS HR_SUPERVISOR_EMAIL2,
  LEARN_SOLUTION_MGR_NAME AS LEARN_SOLUTION_MGR_NAME,
  LEARN_SOLUTION_MGR_EMAIL AS LEARN_SOLUTION_MGR_EMAIL,
  ADD_DT AS ADD_DT,
  DELETE_DT AS DELETE_DT,
  UPDATE_DT AS UPDATE_DT,
  LOAD_DT AS LOAD_DT
FROM
  SITE_PROFILE_RPT"""

df_6 = spark.sql(query_6)

df_6.createOrReplaceTempView("Shortcut_to_SITE_PROFILE_RPT_6")

# COMMAND ----------
# DBTITLE 1, SQ_Shortcut_to_SITE_PROFILE_RPT_7


query_7 = f"""SELECT
  LOCATION_ID AS LOCATION_ID,
  TIME_ZONE AS TIME_ZONE,
  monotonically_increasing_id() AS Monotonically_Increasing_Id
FROM
  Shortcut_to_SITE_PROFILE_RPT_6"""

df_7 = spark.sql(query_7)

df_7.createOrReplaceTempView("SQ_Shortcut_to_SITE_PROFILE_RPT_7")

# COMMAND ----------
# DBTITLE 1, jnr_Site_Profile_Rpt_8


query_8 = f"""SELECT
  DETAIL.OMS_DIST_ORDER_ID AS OMS_DIST_ORDER_ID,
  DETAIL.OMS_DIST_ORDER_LN_ID AS OMS_DIST_ORDER_LN_ID,
  DETAIL.TIME_ZONE AS TIME_ZONE,
  DETAIL.ORIG_LOCATION_ID1 AS ORIG_LOCATION_ID,
  MASTER.LOCATION_ID AS LOCATION_ID,
  MASTER.TIME_ZONE AS TIME_ZONE1,
  MASTER.Monotonically_Increasing_Id AS Monotonically_Increasing_Id
FROM
  SQ_Shortcut_to_SITE_PROFILE_RPT_7 MASTER
  INNER JOIN jnr_Oms_Dist_Order_LN_5 DETAIL ON MASTER.LOCATION_ID = DETAIL.ORIG_LOCATION_ID1"""

df_8 = spark.sql(query_8)

df_8.createOrReplaceTempView("jnr_Site_Profile_Rpt_8")

# COMMAND ----------
# DBTITLE 1, exp_Check_Time_Zone_Upd_9


query_9 = f"""SELECT
  OMS_DIST_ORDER_ID AS OMS_DIST_ORDER_ID,
  OMS_DIST_ORDER_LN_ID AS OMS_DIST_ORDER_LN_ID,
  TIME_ZONE AS TIME_ZONE,
  SYSTIMESTAMP() AS UPDATE_TSTMP,
  TIME_ZONE1 AS TIME_ZONE1,
  IFF(
    IFF(ISNULL(TIME_ZONE), ' ', TIME_ZONE) <> IFF(ISNULL(TIME_ZONE1), ' ', TIME_ZONE1),
    'U',
    'R'
  ) AS UPD_FLG,
  Monotonically_Increasing_Id AS Monotonically_Increasing_Id
FROM
  jnr_Site_Profile_Rpt_8"""

df_9 = spark.sql(query_9)

df_9.createOrReplaceTempView("exp_Check_Time_Zone_Upd_9")

# COMMAND ----------
# DBTITLE 1, fil_Upd_10


query_10 = f"""SELECT
  OMS_DIST_ORDER_ID AS OMS_DIST_ORDER_ID,
  OMS_DIST_ORDER_LN_ID AS OMS_DIST_ORDER_LN_ID,
  TIME_ZONE1 AS TIME_ZONE1,
  UPD_FLG AS UPD_FLG,
  UPDATE_TSTMP AS UPDATE_TSTMP,
  Monotonically_Increasing_Id AS Monotonically_Increasing_Id
FROM
  exp_Check_Time_Zone_Upd_9
WHERE
  UPD_FLG = 'U'"""

df_10 = spark.sql(query_10)

df_10.createOrReplaceTempView("fil_Upd_10")

# COMMAND ----------
# DBTITLE 1, upd_Time_Zone_11


query_11 = f"""SELECT
  OMS_DIST_ORDER_ID AS OMS_DIST_ORDER_ID,
  OMS_DIST_ORDER_LN_ID AS OMS_DIST_ORDER_LN_ID,
  TIME_ZONE1 AS TIME_ZONE1,
  UPD_FLG AS UPD_FLG,
  UPDATE_TSTMP AS UPDATE_TSTMP,
  Monotonically_Increasing_Id AS Monotonically_Increasing_Id,
  IFF(UPD_FLG = 'U', 'DD_UPDATE') AS UPDATE_STRATEGY_FLAG
FROM
  fil_Upd_10"""

df_11 = spark.sql(query_11)

df_11.createOrReplaceTempView("upd_Time_Zone_11")

# COMMAND ----------
# DBTITLE 1, OMS_DIST_ORDER_LN_SLA


spark.sql("""MERGE INTO OMS_DIST_ORDER_LN_SLA AS TARGET
USING
  upd_Time_Zone_11 AS SOURCE ON TARGET.OMS_DIST_ORDER_LN_ID = SOURCE.OMS_DIST_ORDER_LN_ID
  AND TARGET.OMS_DIST_ORDER_ID = SOURCE.OMS_DIST_ORDER_ID
  WHEN MATCHED
  AND SOURCE.UPDATE_STRATEGY_FLAG = "DD_UPDATE" THEN
UPDATE
SET
  TARGET.OMS_DIST_ORDER_ID = SOURCE.OMS_DIST_ORDER_ID,
  TARGET.OMS_DIST_ORDER_LN_ID = SOURCE.OMS_DIST_ORDER_LN_ID,
  TARGET.TIME_ZONE = SOURCE.TIME_ZONE1,
  TARGET.UPDATE_TSTMP = SOURCE.UPDATE_TSTMP
  WHEN MATCHED
  AND SOURCE.UPDATE_STRATEGY_FLAG = "DD_DELETE"
  AND TARGET.TIME_ZONE = SOURCE.TIME_ZONE1
  AND TARGET.UPDATE_TSTMP = SOURCE.UPDATE_TSTMP THEN DELETE
  WHEN NOT MATCHED
  AND SOURCE.UPDATE_STRATEGY_FLAG = "DD_INSERT" THEN
INSERT
  (
    TARGET.OMS_DIST_ORDER_ID,
    TARGET.OMS_DIST_ORDER_LN_ID,
    TARGET.TIME_ZONE,
    TARGET.UPDATE_TSTMP
  )
VALUES
  (
    SOURCE.OMS_DIST_ORDER_ID,
    SOURCE.OMS_DIST_ORDER_LN_ID,
    SOURCE.TIME_ZONE1,
    SOURCE.UPDATE_TSTMP
  )""")

# COMMAND ----------
#Post session variable updation
updateVariable(postVariableAssignment, variablesTableName, mainWorkflowId, parentName, "m_OMS_Dist_Order_LN_SLA_TIME_ZONE_UPD")

# COMMAND ----------
#Update Mapping Variables in database.
persistVariables(variablesTableName, "m_OMS_Dist_Order_LN_SLA_TIME_ZONE_UPD", mainWorkflowId, parentName)
