# Databricks notebook source
# MAGIC %run "./udf_informatica"

# COMMAND ----------


from pyspark.sql.types import *

spark.sql("use DELTA_TRAINING")
spark.sql("set spark.sql.legacy.timeParserPolicy = LEGACY")

# COMMAND ----------
%run ../WorkflowUtility

# COMMAND ----------
mainWorkflowId = dbutils.widgets.get("mainWorkflowId")
mainWorkflowRunId = dbutils.widgets.get("mainWorkflowRunId")
parentName = dbutils.widgets.get("parentName")
preVariableAssignment = dbutils.widgets.get("preVariableAssignment")
postVariableAssignment = dbutils.widgets.get("postVariableAssignment")
truncTargetTableOptions = dbutils.widgets.get("truncTargetTableOptions")
variablesTableName = dbutils.widgets.get("variablesTableName")

# COMMAND ----------
#Truncate Target Tables
truncateTargetTables(truncTargetTableOptions)

# COMMAND ----------
#Pre presession variable updation
updateVariable(preVariableAssignment, variablesTableName, mainWorkflowId, parentName, "m_Site_Order_SLA_Day_Restore")

# COMMAND ----------
fetchAndCreateVariables(parentName,"m_Site_Order_SLA_Day_Restore", variablesTableName, mainWorkflowId)

# COMMAND ----------
# DBTITLE 1, Shortcut_to_SITE_HOURS_DAY1_0


query_0 = f"""SELECT
  DAY_DT AS DAY_DT,
  LOCATION_ID AS LOCATION_ID,
  BUSINESS_AREA AS BUSINESS_AREA,
  LOCATION_TYPE_ID AS LOCATION_TYPE_ID,
  STORE_NBR AS STORE_NBR,
  CLOSE_FLAG AS CLOSE_FLAG,
  TIME_ZONE AS TIME_ZONE,
  OPEN_TSTMP AS OPEN_TSTMP,
  CLOSE_TSTMP AS CLOSE_TSTMP,
  UPDATE_TSTMP AS UPDATE_TSTMP,
  LOAD_TSTMP AS LOAD_TSTMP
FROM
  SITE_HOURS_DAY"""

df_0 = spark.sql(query_0)

df_0.createOrReplaceTempView("Shortcut_to_SITE_HOURS_DAY1_0")

# COMMAND ----------
# DBTITLE 1, SQ_Shortcut_to_SITE_HOURS_DAY_1


query_1 = f"""SELECT
  DAY_DT AS DAY_DT,
  LOCATION_ID AS LOCATION_ID,
  BUSINESS_AREA AS BUSINESS_AREA,
  LOCATION_TYPE_ID AS LOCATION_TYPE_ID,
  STORE_NBR AS STORE_NBR,
  CLOSE_FLAG AS CLOSE_FLAG,
  TIME_ZONE AS TIME_ZONE,
  OPEN_TSTMP AS OPEN_TSTMP,
  CLOSE_TSTMP AS CLOSE_TSTMP,
  UPDATE_TSTMP AS UPDATE_TSTMP,
  LOAD_TSTMP AS LOAD_TSTMP,
  monotonically_increasing_id() AS Monotonically_Increasing_Id
FROM
  Shortcut_to_SITE_HOURS_DAY1_0"""

df_1 = spark.sql(query_1)

df_1.createOrReplaceTempView("SQ_Shortcut_to_SITE_HOURS_DAY_1")

# COMMAND ----------
# DBTITLE 1, Shortcut_to_SITE_HOURS_DAY_2


query_2 = f"""SELECT
  DAY_DT AS DAY_DT,
  LOCATION_ID AS LOCATION_ID,
  BUSINESS_AREA AS BUSINESS_AREA,
  LOCATION_TYPE_ID AS LOCATION_TYPE_ID,
  STORE_NBR AS STORE_NBR,
  CLOSE_FLAG AS CLOSE_FLAG,
  TIME_ZONE AS TIME_ZONE,
  OPEN_TSTMP AS OPEN_TSTMP,
  CLOSE_TSTMP AS CLOSE_TSTMP,
  UPDATE_TSTMP AS UPDATE_TSTMP,
  LOAD_TSTMP AS LOAD_TSTMP
FROM
  SITE_HOURS_DAY"""

df_2 = spark.sql(query_2)

df_2.createOrReplaceTempView("Shortcut_to_SITE_HOURS_DAY_2")

# COMMAND ----------
# DBTITLE 1, SQ_Shortcut_to_SITE_HOURS_DAY3_3


query_3 = f"""SELECT
  DAY_DT AS DAY_DT,
  LOCATION_ID AS LOCATION_ID,
  BUSINESS_AREA AS BUSINESS_AREA,
  LOCATION_TYPE_ID AS LOCATION_TYPE_ID,
  STORE_NBR AS STORE_NBR,
  CLOSE_FLAG AS CLOSE_FLAG,
  OPEN_TSTMP AS OPEN_TSTMP,
  CLOSE_TSTMP AS CLOSE_TSTMP,
  UPDATE_TSTMP AS UPDATE_TSTMP,
  monotonically_increasing_id() AS Monotonically_Increasing_Id
FROM
  Shortcut_to_SITE_HOURS_DAY_2"""

df_3 = spark.sql(query_3)

df_3.createOrReplaceTempView("SQ_Shortcut_to_SITE_HOURS_DAY3_3")

# COMMAND ----------
# DBTITLE 1, Shortcut_to_SITE_HOURS_DAY2_4


query_4 = f"""SELECT
  DAY_DT AS DAY_DT,
  LOCATION_ID AS LOCATION_ID,
  BUSINESS_AREA AS BUSINESS_AREA,
  LOCATION_TYPE_ID AS LOCATION_TYPE_ID,
  STORE_NBR AS STORE_NBR,
  CLOSE_FLAG AS CLOSE_FLAG,
  TIME_ZONE AS TIME_ZONE,
  OPEN_TSTMP AS OPEN_TSTMP,
  CLOSE_TSTMP AS CLOSE_TSTMP,
  UPDATE_TSTMP AS UPDATE_TSTMP,
  LOAD_TSTMP AS LOAD_TSTMP
FROM
  SITE_HOURS_DAY"""

df_4 = spark.sql(query_4)

df_4.createOrReplaceTempView("Shortcut_to_SITE_HOURS_DAY2_4")

# COMMAND ----------
# DBTITLE 1, SQ_Shortcut_to_SITE_HOURS_DAY1_5


query_5 = f"""SELECT
  DAY_DT AS DAY_DT,
  LOCATION_ID AS LOCATION_ID,
  BUSINESS_AREA AS BUSINESS_AREA,
  LOCATION_TYPE_ID AS LOCATION_TYPE_ID,
  STORE_NBR AS STORE_NBR,
  CLOSE_FLAG AS CLOSE_FLAG,
  TIME_ZONE AS TIME_ZONE,
  OPEN_TSTMP AS OPEN_TSTMP,
  CLOSE_TSTMP AS CLOSE_TSTMP,
  UPDATE_TSTMP AS UPDATE_TSTMP,
  LOAD_TSTMP AS LOAD_TSTMP,
  monotonically_increasing_id() AS Monotonically_Increasing_Id
FROM
  Shortcut_to_SITE_HOURS_DAY2_4"""

df_5 = spark.sql(query_5)

df_5.createOrReplaceTempView("SQ_Shortcut_to_SITE_HOURS_DAY1_5")

# COMMAND ----------
# DBTITLE 1, Jnr_Site_Hours_Day_For_Next_Day_6


query_6 = f"""SELECT
  DETAIL.DAY_DT AS DAY_DT,
  DETAIL.LOCATION_ID AS LOCATION_ID,
  DETAIL.BUSINESS_AREA AS BUSINESS_AREA,
  MASTER.DAY_DT AS DAY_DT1,
  MASTER.LOCATION_ID AS LOCATION_ID1,
  MASTER.BUSINESS_AREA AS BUSINESS_AREA1,
  MASTER.CLOSE_FLAG AS CLOSE_FLAG,
  MASTER.OPEN_TSTMP AS OPEN_TSTMP,
  MASTER.CLOSE_TSTMP AS CLOSE_TSTMP,
  MASTER.Monotonically_Increasing_Id AS Monotonically_Increasing_Id
FROM
  SQ_Shortcut_to_SITE_HOURS_DAY1_5 MASTER
  INNER JOIN SQ_Shortcut_to_SITE_HOURS_DAY_1 DETAIL ON MASTER.LOCATION_ID = DETAIL.LOCATION_ID
  AND MASTER.BUSINESS_AREA = DETAIL.BUSINESS_AREA"""

df_6 = spark.sql(query_6)

df_6.createOrReplaceTempView("Jnr_Site_Hours_Day_For_Next_Day_6")

# COMMAND ----------
# DBTITLE 1, Srt_Distinct_7


query_7 = f"""SELECT
  DAY_DT AS DAY_DT,
  LOCATION_ID AS LOCATION_ID,
  BUSINESS_AREA AS BUSINESS_AREA,
  DAY_DT1 AS DAY_DT1,
  CLOSE_FLAG AS CLOSE_FLAG,
  OPEN_TSTMP AS OPEN_TSTMP,
  CLOSE_TSTMP AS CLOSE_TSTMP,
  BUSINESS_AREA1 AS BUSINESS_AREA1,
  Monotonically_Increasing_Id AS Monotonically_Increasing_Id
FROM
  Jnr_Site_Hours_Day_For_Next_Day_6
ORDER BY
  DAY_DT ASC,
  LOCATION_ID ASC,
  BUSINESS_AREA ASC,
  DAY_DT1 ASC,
  CLOSE_FLAG ASC,
  OPEN_TSTMP ASC,
  CLOSE_TSTMP ASC,
  BUSINESS_AREA1 ASC"""

df_7 = spark.sql(query_7)

df_7.createOrReplaceTempView("Srt_Distinct_7")

# COMMAND ----------
# DBTITLE 1, Fil_Close_Flag_8


query_8 = f"""SELECT
  DAY_DT AS DAY_DT,
  LOCATION_ID AS LOCATION_ID,
  DAY_DT1 AS DAY_DT1,
  CLOSE_FLAG AS CLOSE_FLAG,
  OPEN_TSTMP AS OPEN_TSTMP,
  CLOSE_TSTMP AS CLOSE_TSTMP,
  BUSINESS_AREA AS BUSINESS_AREA,
  BUSINESS_AREA1 AS BUSINESS_AREA1,
  Monotonically_Increasing_Id AS Monotonically_Increasing_Id
FROM
  Srt_Distinct_7
WHERE
  CLOSE_FLAG = 0
  and DAY_DT < DAY_DT1
  AND DAY_DT >= TO_DATE({RestoreStartDate}, 'YYYY-MM-DD') --AND DAY_DT <= TO_DATE('2017-12-26', 'YYYY-MM-DD')
  --AND DAY_DT >= ADD_TO_DATE(TRUNC(now()), 'DD', -1)
  --AND DAY_DT >=TRUNC(now())
  AND (
    BUSINESS_AREA = 'Store'
    OR BUSINESS_AREA = 'DC'
    OR BUSINESS_AREA = 'Vendor'
  )
  AND (
    BUSINESS_AREA1 = 'Store'
    OR BUSINESS_AREA1 = 'DC'
    OR BUSINESS_AREA1 = 'Vendor'
  )"""

df_8 = spark.sql(query_8)

df_8.createOrReplaceTempView("Fil_Close_Flag_8")

# COMMAND ----------
# DBTITLE 1, Agg_Next_Day_9


query_9 = f"""SELECT
  DAY_DT AS DAY_DT,
  LOCATION_ID AS LOCATION_ID,
  MIN(DAY_DT1) AS Next_Day_DAY_DT,
  MIN(OPEN_TSTMP) AS Next_Day_OPEN_TSTMP,
  MIN(CLOSE_TSTMP) AS Next_day_CLOSE_TSTMP,
  last(Monotonically_Increasing_Id) AS Monotonically_Increasing_Id
FROM
  Fil_Close_Flag_8
GROUP BY
  DAY_DT,
  LOCATION_ID"""

df_9 = spark.sql(query_9)

df_9.createOrReplaceTempView("Agg_Next_Day_9")

# COMMAND ----------
# DBTITLE 1, Shortcut_to_SITE_ORDER_SLA_10


query_10 = f"""SELECT
  START_DT AS START_DT,
  LOCATION_TYPE_ID AS LOCATION_TYPE_ID,
  RULE_NBR AS RULE_NBR,
  END_DT AS END_DT,
  RULE_DESC AS RULE_DESC,
  HOLIDAY_FLAG AS HOLIDAY_FLAG,
  WEEKEND_FLAG AS WEEKEND_FLAG,
  CLOSE_FLAG AS CLOSE_FLAG,
  START_ORDER_CREATE_TSTMP AS START_ORDER_CREATE_TSTMP,
  END_ORDER_CREATE_TSTMP AS END_ORDER_CREATE_TSTMP,
  START_LOCATION_OPEN_TSTMP_FLAG AS START_LOCATION_OPEN_TSTMP_FLAG,
  START_LOCATION_CLOSE_TSTMP_FLAG AS START_LOCATION_CLOSE_TSTMP_FLAG,
  START_TSTMP_ADJ_HOUR AS START_TSTMP_ADJ_HOUR,
  END_LOCATION_OPEN_TSTMP_FLAG AS END_LOCATION_OPEN_TSTMP_FLAG,
  END_LOCATION_CLOSE_TSTMP_FLAG AS END_LOCATION_CLOSE_TSTMP_FLAG,
  END_TSTMP_ADJ_HOUR AS END_TSTMP_ADJ_HOUR,
  SLA_SAME_DAY_FLAG AS SLA_SAME_DAY_FLAG,
  SLA_NEXT_OPEN_DAY_FLAG AS SLA_NEXT_OPEN_DAY_FLAG,
  SLA_TSTMP AS SLA_TSTMP,
  SLA_TIME_HOUR AS SLA_TIME_HOUR,
  SLA_LOCATION_OPEN_TSTMP_FLAG AS SLA_LOCATION_OPEN_TSTMP_FLAG,
  SLA_TSTMP_ADJ_HOUR AS SLA_TSTMP_ADJ_HOUR,
  UPDATE_USER AS UPDATE_USER,
  UPDATE_TSTMP AS UPDATE_TSTMP,
  LOAD_TSTMP AS LOAD_TSTMP
FROM
  SITE_ORDER_SLA"""

df_10 = spark.sql(query_10)

df_10.createOrReplaceTempView("Shortcut_to_SITE_ORDER_SLA_10")

# COMMAND ----------
# DBTITLE 1, SQ_Shortcut_SITE_ORDER_SLA_11


query_11 = f"""SELECT
  START_DT AS START_DT,
  LOCATION_TYPE_ID AS LOCATION_TYPE_ID,
  RULE_NBR AS RULE_NBR,
  END_DT AS END_DT,
  RULE_DESC AS RULE_DESC,
  HOLIDAY_FLAG AS HOLIDAY_FLAG,
  WEEKEND_FLAG AS WEEKEND_FLAG,
  CLOSE_FLAG AS CLOSE_FLAG,
  START_ORDER_CREATE_TSTMP AS START_ORDER_CREATE_TSTMP,
  END_ORDER_CREATE_TSTMP AS END_ORDER_CREATE_TSTMP,
  START_LOCATION_OPEN_TSTMP_FLAG AS START_LOCATION_OPEN_TSTMP_FLAG,
  START_LOCATION_CLOSE_TSTMP_FLAG AS START_LOCATION_CLOSE_TSTMP_FLAG,
  START_TSTMP_ADJ_HOUR AS START_TSTMP_ADJ_HOUR,
  END_LOCATION_OPEN_TSTMP_FLAG AS END_LOCATION_OPEN_TSTMP_FLAG,
  END_LOCATION_CLOSE_TSTMP_FLAG AS END_LOCATION_CLOSE_TSTMP_FLAG,
  END_TSTMP_ADJ_HOUR AS END_TSTMP_ADJ_HOUR,
  SLA_SAME_DAY_FLAG AS SLA_SAME_DAY_FLAG,
  SLA_NEXT_OPEN_DAY_FLAG AS SLA_NEXT_OPEN_DAY_FLAG,
  SLA_TSTMP AS SLA_TSTMP,
  SLA_TIME_HOUR AS SLA_TIME_HOUR,
  SLA_LOCATION_OPEN_TSTMP_FLAG AS SLA_LOCATION_OPEN_TSTMP_FLAG,
  SLA_TSTMP_ADJ_HOUR AS SLA_TSTMP_ADJ_HOUR,
  UPDATE_USER AS UPDATE_USER,
  UPDATE_TSTMP AS UPDATE_TSTMP,
  LOAD_TSTMP AS LOAD_TSTMP,
  monotonically_increasing_id() AS Monotonically_Increasing_Id
FROM
  Shortcut_to_SITE_ORDER_SLA_10"""

df_11 = spark.sql(query_11)

df_11.createOrReplaceTempView("SQ_Shortcut_SITE_ORDER_SLA_11")

# COMMAND ----------
# DBTITLE 1, Jnr_Site_Order_SLA__Site_Hours_Day_12


query_12 = f"""SELECT
  DETAIL.START_DT AS START_DT,
  DETAIL.LOCATION_TYPE_ID AS LOCATION_TYPE_ID,
  DETAIL.RULE_NBR AS RULE_NBR,
  DETAIL.END_DT AS END_DT,
  DETAIL.RULE_DESC AS RULE_DESC,
  DETAIL.HOLIDAY_FLAG AS HOLIDAY_FLAG,
  DETAIL.WEEKEND_FLAG AS WEEKEND_FLAG,
  DETAIL.CLOSE_FLAG AS CLOSE_FLAG,
  DETAIL.START_ORDER_CREATE_TSTMP AS START_ORDER_CREATE_TSTMP,
  DETAIL.END_ORDER_CREATE_TSTMP AS END_ORDER_CREATE_TSTMP,
  DETAIL.START_LOCATION_OPEN_TSTMP_FLAG AS START_LOCATION_OPEN_TSTMP_FLAG,
  DETAIL.START_LOCATION_CLOSE_TSTMP_FLAG AS START_LOCATION_CLOSE_TSTMP_FLAG,
  DETAIL.START_TSTMP_ADJ_HOUR AS START_TSTMP_ADJ_HOUR,
  DETAIL.END_LOCATION_OPEN_TSTMP_FLAG AS END_LOCATION_OPEN_TSTMP_FLAG,
  DETAIL.END_LOCATION_CLOSE_TSTMP_FLAG AS END_LOCATION_CLOSE_TSTMP_FLAG,
  DETAIL.END_TSTMP_ADJ_HOUR AS END_TSTMP_ADJ_HOUR,
  DETAIL.SLA_SAME_DAY_FLAG AS SLA_SAME_DAY_FLAG,
  DETAIL.SLA_NEXT_OPEN_DAY_FLAG AS SLA_NEXT_OPEN_DAY_FLAG,
  DETAIL.SLA_TSTMP AS SLA_TSTMP,
  DETAIL.SLA_TIME_HOUR AS SLA_TIME_HOUR,
  DETAIL.SLA_LOCATION_OPEN_TSTMP_FLAG AS SLA_LOCATION_OPEN_TSTMP_FLAG,
  DETAIL.SLA_TSTMP_ADJ_HOUR AS SLA_TSTMP_ADJ_HOUR,
  DETAIL.UPDATE_USER AS UPDATE_USER,
  DETAIL.UPDATE_TSTMP AS UPDATE_TSTMP,
  DETAIL.LOAD_TSTMP AS LOAD_TSTMP,
  MASTER.DAY_DT AS DAY_DT1,
  MASTER.LOCATION_ID AS LOCATION_ID1,
  MASTER.STORE_NBR AS STORE_NBR,
  MASTER.OPEN_TSTMP AS OPEN_TSTMP1,
  MASTER.CLOSE_TSTMP AS CLOSE_TSTMP1,
  MASTER.LOCATION_TYPE_ID AS LOCATION_TYPE_ID1,
  MASTER.CLOSE_FLAG AS CLOSE_FLAG1,
  MASTER.BUSINESS_AREA AS BUSINESS_AREA,
  MASTER.UPDATE_TSTMP AS UPDATE_TSTMP1,
  MASTER.Monotonically_Increasing_Id AS Monotonically_Increasing_Id
FROM
  SQ_Shortcut_to_SITE_HOURS_DAY3_3 MASTER
  INNER JOIN SQ_Shortcut_SITE_ORDER_SLA_11 DETAIL ON MASTER.LOCATION_TYPE_ID = DETAIL.LOCATION_TYPE_ID
  AND MASTER.CLOSE_FLAG = DETAIL.CLOSE_FLAG"""

df_12 = spark.sql(query_12)

df_12.createOrReplaceTempView("Jnr_Site_Order_SLA__Site_Hours_Day_12")

# COMMAND ----------
# DBTITLE 1, Fil_Site_Hours_Day__Site_Order_SLA_13


query_13 = f"""SELECT
  START_DT AS START_DT,
  LOCATION_TYPE_ID AS LOCATION_TYPE_ID,
  RULE_NBR AS RULE_NBR,
  END_DT AS END_DT,
  RULE_DESC AS RULE_DESC,
  HOLIDAY_FLAG AS HOLIDAY_FLAG,
  WEEKEND_FLAG AS WEEKEND_FLAG,
  CLOSE_FLAG AS CLOSE_FLAG,
  START_ORDER_CREATE_TSTMP AS START_ORDER_CREATE_TSTMP,
  END_ORDER_CREATE_TSTMP AS END_ORDER_CREATE_TSTMP,
  START_LOCATION_OPEN_TSTMP_FLAG AS START_LOCATION_OPEN_TSTMP_FLAG,
  START_LOCATION_CLOSE_TSTMP_FLAG AS START_LOCATION_CLOSE_TSTMP_FLAG,
  START_TSTMP_ADJ_HOUR AS START_TSTMP_ADJ_HOUR,
  END_LOCATION_OPEN_TSTMP_FLAG AS END_LOCATION_OPEN_TSTMP_FLAG,
  END_LOCATION_CLOSE_TSTMP_FLAG AS END_LOCATION_CLOSE_TSTMP_FLAG,
  END_TSTMP_ADJ_HOUR AS END_TSTMP_ADJ_HOUR,
  SLA_SAME_DAY_FLAG AS SLA_SAME_DAY_FLAG,
  SLA_NEXT_OPEN_DAY_FLAG AS SLA_NEXT_OPEN_DAY_FLAG,
  SLA_TSTMP AS SLA_TSTMP,
  SLA_TIME_HOUR AS SLA_TIME_HOUR,
  SLA_LOCATION_OPEN_TSTMP_FLAG AS SLA_LOCATION_OPEN_TSTMP_FLAG,
  SLA_TSTMP_ADJ_HOUR AS SLA_TSTMP_ADJ_HOUR,
  UPDATE_USER AS UPDATE_USER,
  UPDATE_TSTMP AS UPDATE_TSTMP,
  LOAD_TSTMP AS LOAD_TSTMP,
  DAY_DT1 AS DAY_DT1,
  LOCATION_ID1 AS LOCATION_ID1,
  STORE_NBR AS STORE_NBR,
  OPEN_TSTMP1 AS OPEN_TSTMP1,
  CLOSE_TSTMP1 AS CLOSE_TSTMP1,
  LOCATION_TYPE_ID1 AS LOCATION_TYPE_ID1,
  CLOSE_FLAG1 AS CLOSE_FLAG1,
  BUSINESS_AREA AS BUSINESS_AREA,
  UPDATE_TSTMP1 AS UPDATE_TSTMP1,
  Monotonically_Increasing_Id AS Monotonically_Increasing_Id
FROM
  Jnr_Site_Order_SLA__Site_Hours_Day_12
WHERE
  DAY_DT1 >= START_DT
  AND DAY_DT1 <= END_DT
  AND (
    BUSINESS_AREA = 'Store'
    OR BUSINESS_AREA = 'DC'
    OR BUSINESS_AREA = 'Vendor'
  ) --AND (UPDATE_TSTMP >= ADD_TO_DATE(TRUNC(now()), 'DD', -1)
  --OR UPDATE_TSTMP1 >= ADD_TO_DATE(TRUNC(now()),  'DD', -1)
  --)"""

df_13 = spark.sql(query_13)

df_13.createOrReplaceTempView("Fil_Site_Hours_Day__Site_Order_SLA_13")

# COMMAND ----------
# DBTITLE 1, exp_PASS_THRU_14


query_14 = f"""SELECT
  START_DT AS DAY_DT2,
  LOCATION_TYPE_ID AS LOCATION_TYPE_ID,
  RULE_NBR AS RULE_NBR,
  END_DT AS END_DT,
  RULE_DESC AS RULE_DESC,
  HOLIDAY_FLAG AS HOLIDAY_FLAG,
  WEEKEND_FLAG AS WEEKEND_FLAG,
  CLOSE_FLAG AS CLOSE_FLAG,
  START_ORDER_CREATE_TSTMP AS START_ORDER_CREATE_TSTMP,
  END_ORDER_CREATE_TSTMP AS END_ORDER_CREATE_TSTMP,
  START_LOCATION_OPEN_TSTMP_FLAG AS START_LOCATION_OPEN_TSTMP_FLAG,
  START_LOCATION_CLOSE_TSTMP_FLAG AS START_LOCATION_CLOSE_TSTMP_FLAG,
  START_TSTMP_ADJ_HOUR AS START_TSTMP_ADJ_HOUR,
  END_LOCATION_OPEN_TSTMP_FLAG AS END_LOCATION_OPEN_TSTMP_FLAG,
  END_LOCATION_CLOSE_TSTMP_FLAG AS END_LOCATION_CLOSE_TSTMP_FLAG,
  END_TSTMP_ADJ_HOUR AS END_TSTMP_ADJ_HOUR,
  SLA_SAME_DAY_FLAG AS SLA_SAME_DAY_FLAG,
  SLA_NEXT_OPEN_DAY_FLAG AS SLA_NEXT_OPEN_DAY_FLAG,
  SLA_TSTMP AS SLA_TSTMP,
  SLA_TIME_HOUR AS SLA_TIME_HOUR,
  SLA_LOCATION_OPEN_TSTMP_FLAG AS SLA_LOCATION_OPEN_TSTMP_FLAG,
  SLA_TSTMP_ADJ_HOUR AS SLA_TSTMP_ADJ_HOUR,
  UPDATE_USER AS UPDATE_USER,
  UPDATE_TSTMP AS UPDATE_TSTMP,
  LOAD_TSTMP AS LOAD_TSTMP,
  DAY_DT1 AS DAY_DT1,
  LOCATION_ID1 AS LOCATION_ID,
  OPEN_TSTMP1 AS OPEN_TSTMP,
  CLOSE_TSTMP1 AS CLOSE_TSTMP,
  STORE_NBR AS STORE_NBR,
  Monotonically_Increasing_Id AS Monotonically_Increasing_Id
FROM
  Fil_Site_Hours_Day__Site_Order_SLA_13"""

df_14 = spark.sql(query_14)

df_14.createOrReplaceTempView("exp_PASS_THRU_14")

# COMMAND ----------
# DBTITLE 1, jnr_NEXT_OPEN_DATE_15


query_15 = f"""SELECT
  DETAIL.DAY_DT2 AS DAY_DT2,
  DETAIL.LOCATION_TYPE_ID AS LOCATION_TYPE_ID,
  DETAIL.RULE_NBR AS RULE_NBR,
  DETAIL.END_DT AS END_DT,
  DETAIL.RULE_DESC AS RULE_DESC,
  DETAIL.HOLIDAY_FLAG AS HOLIDAY_FLAG,
  DETAIL.WEEKEND_FLAG AS WEEKEND_FLAG,
  DETAIL.CLOSE_FLAG AS CLOSE_FLAG,
  DETAIL.START_ORDER_CREATE_TSTMP AS START_ORDER_CREATE_TSTMP,
  DETAIL.END_ORDER_CREATE_TSTMP AS END_ORDER_CREATE_TSTMP,
  DETAIL.START_LOCATION_OPEN_TSTMP_FLAG AS START_LOCATION_OPEN_TSTMP_FLAG,
  DETAIL.START_LOCATION_CLOSE_TSTMP_FLAG AS START_LOCATION_CLOSE_TSTMP_FLAG,
  DETAIL.START_TSTMP_ADJ_HOUR AS START_TSTMP_ADJ_HOUR,
  DETAIL.END_LOCATION_OPEN_TSTMP_FLAG AS END_LOCATION_OPEN_TSTMP_FLAG,
  DETAIL.END_LOCATION_CLOSE_TSTMP_FLAG AS END_LOCATION_CLOSE_TSTMP_FLAG,
  DETAIL.END_TSTMP_ADJ_HOUR AS END_TSTMP_ADJ_HOUR,
  DETAIL.SLA_SAME_DAY_FLAG AS SLA_SAME_DAY_FLAG,
  DETAIL.SLA_NEXT_OPEN_DAY_FLAG AS SLA_NEXT_OPEN_DAY_FLAG,
  DETAIL.SLA_TSTMP AS SLA_TSTMP,
  DETAIL.SLA_TIME_HOUR AS SLA_TIME_HOUR,
  DETAIL.SLA_LOCATION_OPEN_TSTMP_FLAG AS SLA_LOCATION_OPEN_TSTMP_FLAG,
  DETAIL.SLA_TSTMP_ADJ_HOUR AS SLA_TSTMP_ADJ_HOUR,
  DETAIL.UPDATE_USER AS UPDATE_USER,
  DETAIL.UPDATE_TSTMP AS UPDATE_TSTMP,
  DETAIL.LOAD_TSTMP AS LOAD_TSTMP,
  DETAIL.DAY_DT1 AS DAY_DT1,
  DETAIL.LOCATION_ID AS LOCATION_ID,
  DETAIL.OPEN_TSTMP AS OPEN_TSTMP,
  DETAIL.CLOSE_TSTMP AS CLOSE_TSTMP,
  DETAIL.STORE_NBR AS STORE_NBR,
  MASTER.DAY_DT AS DAY_DT,
  MASTER.Next_Day_DAY_DT AS MIN_DAY_DT,
  MASTER.Next_Day_OPEN_TSTMP AS OPEN_TSTMP1,
  MASTER.Next_day_CLOSE_TSTMP AS CLOSE_TSTMP1,
  MASTER.LOCATION_ID AS LOCATION_ID1,
  MASTER.Monotonically_Increasing_Id AS Monotonically_Increasing_Id
FROM
  Agg_Next_Day_9 MASTER
  INNER JOIN exp_PASS_THRU_14 DETAIL ON MASTER.LOCATION_ID = DETAIL.LOCATION_ID
  AND MASTER.DAY_DT = DETAIL.DAY_DT1"""

df_15 = spark.sql(query_15)

df_15.createOrReplaceTempView("jnr_NEXT_OPEN_DATE_15")

# COMMAND ----------
# DBTITLE 1, exp_CALC_16


query_16 = f"""SELECT
  LOCATION_ID AS LOCATION_ID,
  OPEN_TSTMP AS OPEN_TSTMP,
  LOCATION_TYPE_ID AS LOCATION_TYPE_ID,
  DECODE(TRUE, LOCATION_TYPE_ID = 8, 1, LOCATION_TYPE_ID = 6, 2) AS v_LOCATION_TYPE_ID,
  OPEN_TSTMP AS OPEN_HOUR,
  CLOSE_TSTMP AS CLOSE_TSTMP,
  CLOSE_TSTMP AS CLOSE_HOUR,
  DAY_DT1 AS DAY_DT,
  START_LOCATION_OPEN_TSTMP_FLAG AS START_LOCATION_OPEN_TSTMP_FLAG,
  START_LOCATION_CLOSE_TSTMP_FLAG AS START_LOCATION_CLOSE_TSTMP_FLAG,
  START_TSTMP_ADJ_HOUR AS START_TSTMP_ADJ_HOUR,
  IFF(
    isnull(START_TSTMP_ADJ_HOUR),
    0,
    START_TSTMP_ADJ_HOUR
  ) AS v_START_TSTMP_ADJ_HOUR,
  END_LOCATION_OPEN_TSTMP_FLAG AS END_LOCATION_OPEN_TSTMP_FLAG,
  END_LOCATION_CLOSE_TSTMP_FLAG AS END_LOCATION_CLOSE_TSTMP_FLAG,
  END_TSTMP_ADJ_HOUR AS END_TSTMP_ADJ_HOUR,
  IFF(isnull(END_TSTMP_ADJ_HOUR), 0, END_TSTMP_ADJ_HOUR) AS v_END_TSTMP_ADJ_HOUR,
  IFF(isnull(SLA_TSTMP_ADJ_HOUR), 0, SLA_TSTMP_ADJ_HOUR) AS v_SLA_TSTMP_ADJ_HOUR,
  SLA_SAME_DAY_FLAG AS SLA_SAME_DAY_FLAG,
  SLA_NEXT_OPEN_DAY_FLAG AS SLA_NEXT_OPEN_DAY_FLAG,
  IFF(
    SLA_SAME_DAY_FLAG = 1,
    DAY_DT,
    IFF (SLA_NEXT_OPEN_DAY_FLAG = 1, Next_DAY_OPEN_DT)
  ) AS v_SLA_DAY_DT,
  START_ORDER_CREATE_TSTMP AS START_ORDER_CREATE_TSTMP_SRC,
  END_ORDER_CREATE_TSTMP AS END_ORDER_CREATE_TSTMP_SRC,
  SLA_LOCATION_OPEN_TSTMP_FLAG AS SLA_LOCATION_OPEN_TSTMP_FLAG,
  SLA_TSTMP_ADJ_HOUR AS SLA_TSTMP_ADJ_HOUR,
  SLA_TSTMP AS SLA_TSTMP1,
  SLA_TIME_HOUR AS SLA_TIME_HOUR,
  MIN_DAY_DT AS Next_DAY_OPEN_DT,
  OPEN_TSTMP1 AS Next_day_OPEN_TSTMP1,
  CLOSE_TSTMP1 AS Next_Day_CLOSE_TSTMP1,
  Decode(
    TRUE,
    (START_LOCATION_OPEN_TSTMP_FLAG = 1),
    ADD_TO_DATE(
      OPEN_TSTMP,
      'HH',
      IFF(
        isnull(START_TSTMP_ADJ_HOUR),
        0,
        START_TSTMP_ADJ_HOUR
      )
    ),
    (START_LOCATION_CLOSE_TSTMP_FLAG = 1),
    ADD_TO_DATE(
      CLOSE_TSTMP,
      'HH',
      IFF(
        isnull(START_TSTMP_ADJ_HOUR),
        0,
        START_TSTMP_ADJ_HOUR
      )
    ),
    (NOT ISNULL(START_ORDER_CREATE_TSTMP)),
    to_date(
      to_char(DAY_DT1, 'yyyy-mm-dd') || ' ' || to_char(get_date_part(START_ORDER_CREATE_TSTMP, 'HH24')) || ':' || to_char(get_date_part(START_ORDER_CREATE_TSTMP, 'MI')) || ':' || to_char(get_date_part(START_ORDER_CREATE_TSTMP, 'SS')),
      'yyyy-mm-dd hh24:mi:ss'
    )
  ) AS START_ORDER_CREATE_TS,
  Decode(
    TRUE,
    (END_LOCATION_CLOSE_TSTMP_FLAG = 1),
    ADD_TO_DATE(
      ADD_TO_DATE(
        CLOSE_TSTMP,
        'SS',
        IFF(isnull(END_TSTMP_ADJ_HOUR), 0, END_TSTMP_ADJ_HOUR)
      ),
      'HH',
      IFF(isnull(END_TSTMP_ADJ_HOUR), 0, END_TSTMP_ADJ_HOUR)
    ),
    (NOT ISNULL (END_ORDER_CREATE_TSTMP)),
    to_date(
      to_char(DAY_DT1, 'yyyy-mm-dd') || ' ' || to_char(get_date_part(END_ORDER_CREATE_TSTMP, 'HH24')) || ':' || to_char(get_date_part(END_ORDER_CREATE_TSTMP, 'MI')) || ':' || to_char(get_date_part(END_ORDER_CREATE_TSTMP, 'SS')),
      'yyyy-mm-dd hh24:mi:ss'
    ),
    END_LOCATION_OPEN_TSTMP_FLAG = 1,
    ADD_TO_DATE(
      ADD_TO_DATE(
        OPEN_TSTMP,
        'SS',
        IFF(isnull(END_TSTMP_ADJ_HOUR), 0, END_TSTMP_ADJ_HOUR)
      ),
      'HH',
      IFF(isnull(END_TSTMP_ADJ_HOUR), 0, END_TSTMP_ADJ_HOUR)
    )
  ) AS END_ORDER_CREATE_TSTMP,
  TO_Date (
    TO_CHAR (
      IFF(
        SLA_SAME_DAY_FLAG = 1,
        DAY_DT1,
        IFF (SLA_NEXT_OPEN_DAY_FLAG = 1, MIN_DAY_DT)
      ),
      'yyyy-mm-dd'
    ),
    'yyyy-mm-dd'
  ) AS SLA_DAY_DT,
  IFF(
    LOCATION_TYPE_ID = 8,
    Decode(
      TRUE,
      (
        SLA_SAME_DAY_FLAG = 1
        and SLA_LOCATION_OPEN_TSTMP_FLAG = 1
      ),
      ADD_TO_DATE(
        OPEN_TSTMP,
        'HH',
        IFF(isnull(SLA_TSTMP_ADJ_HOUR), 0, SLA_TSTMP_ADJ_HOUR)
      ),
      (
        SLA_NEXT_OPEN_DAY_FLAG = 1
        and SLA_LOCATION_OPEN_TSTMP_FLAG = 1
      ),
      to_date(
        to_char(MIN_DAY_DT, 'yyyy-mm-dd') || ' ' || to_char(get_date_part(OPEN_TSTMP1, 'HH24')) || ':' || to_char(get_date_part(OPEN_TSTMP1, 'MI')) || ':' || to_char(get_date_part(OPEN_TSTMP1, 'SS')),
        'yyyy-mm-dd hh24:mi:ss'
      )
    ),
    IFF(
      LOCATION_TYPE_ID = 6,
      Decode(
        TRUE,
        NOT ISNULL(SLA_TSTMP)
        and SLA_SAME_DAY_FLAG = 1,
        to_date(
          to_char(DAY_DT1, 'yyyy-mm-dd') || ' ' || to_char(get_date_part(SLA_TSTMP, 'HH24')) || ':' || to_char(get_date_part(SLA_TSTMP, 'MI')) || ':' || to_char(get_date_part(SLA_TSTMP, 'SS')),
          'yyyy-mm-dd hh24:mi:ss'
        ),
        NOT ISNULL(SLA_TSTMP)
        and SLA_NEXT_OPEN_DAY_FLAG = 1,
        to_date(
          to_char(MIN_DAY_DT, 'yyyy-mm-dd') || ' ' || to_char(get_date_part(SLA_TSTMP, 'HH24')) || ':' || to_char(get_date_part(SLA_TSTMP, 'MI')) || ':' || to_char(get_date_part(SLA_TSTMP, 'SS')),
          'yyyy-mm-dd hh24:mi:ss'
        )
      )
    )
  ) AS SLA_TSTMP,
  sysdate AS UPDATE_TSTMP,
  sysdate AS LOAD_TSTMP,
  Monotonically_Increasing_Id AS Monotonically_Increasing_Id
FROM
  jnr_NEXT_OPEN_DATE_15"""

df_16 = spark.sql(query_16)

df_16.createOrReplaceTempView("exp_CALC_16")

# COMMAND ----------
# DBTITLE 1, SITE_ORDER_SLA_DAY


spark.sql("""INSERT INTO
  SITE_ORDER_SLA_DAY
SELECT
  DAY_DT AS DAY_DT,
  LOCATION_ID AS LOCATION_ID,
  START_ORDER_CREATE_TS AS START_ORDER_CREATE_TSTMP,
  END_ORDER_CREATE_TSTMP AS END_ORDER_CREATE_TSTMP,
  LOCATION_TYPE_ID AS LOCATION_TYPE_ID,
  SLA_DAY_DT AS SLA_DAY_DT,
  SLA_TSTMP AS SLA_TSTMP,
  SLA_TIME_HOUR AS SLA_TIME_HOUR,
  UPDATE_TSTMP AS UPDATE_TSTMP,
  LOAD_TSTMP AS LOAD_TSTMP
FROM
  exp_CALC_16""")

# COMMAND ----------
#Post session variable updation
updateVariable(postVariableAssignment, variablesTableName, mainWorkflowId, parentName, "m_Site_Order_SLA_Day_Restore")

# COMMAND ----------
#Update Mapping Variables in database.
persistVariables(variablesTableName, "m_Site_Order_SLA_Day_Restore", mainWorkflowId, parentName)
